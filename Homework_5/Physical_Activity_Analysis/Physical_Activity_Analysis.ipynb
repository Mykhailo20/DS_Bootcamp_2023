{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641968-9595-458a-b449-e9028c13ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import locale\n",
    "import pytz\n",
    "import dateutil.tz\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90e5f1-ff70-4a9e-b65e-1e9d7a2fe1a7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbc252-8614-427b-8559-226bd8c2387b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a dataframe for each type of activity by connecting smaller dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57510dc6-fcbf-4f2e-aa70-d1eb1353d001",
   "metadata": {},
   "source": [
    "### Implement the necessary columns in smaller dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab123620-c2e3-4e3b-8058-4194182417a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_column(df, timestamp_col_name, local_timezone=datetime.timezone.utc, reordering=False):\n",
    "    \"\"\" A function to add a 'datetime' column that contains information about the date and time of the recording\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the required data\n",
    "        2) timestamp_col_name - the name of the df dataframe column that contains the timestamp information\n",
    "        3) local_timezone - the time zone in which the measurements were made (object of class 'dateutil.tz.tz.tzlocal')\n",
    "        4) reordering - rearrange the dataframe columns so that the 'datetime' column is next to the 'timestamp' column\n",
    "    Returns:\n",
    "        A dataframe that contains a 'datetime' column\n",
    "    \"\"\"\n",
    "    df['datetime'] = df[timestamp_col_name].apply(lambda timestamp:\n",
    "        datetime.datetime.fromtimestamp(timestamp / 1000.0, tz=local_timezone).strftime(\"%d.%m.%Y, %H:%M:%S.%f\")[:-3])\n",
    "    df['datetime'] = df['datetime'].apply(lambda timestamp_str: \n",
    "        datetime.datetime.strptime(timestamp_str, \"%d.%m.%Y, %H:%M:%S.%f\"))\n",
    "    \n",
    "    if reordering:\n",
    "        # Reorder the columns\n",
    "        new_column_order = [timestamp_col_name, 'datetime'] + [col for col in df.columns if col != timestamp_col_name and col != 'datetime']\n",
    "        df = df.reindex(columns=new_column_order)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7072c87-8e1d-44b9-af32-db16bc4e6735",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create activity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b7b99-5f61-45b9-bca3-b0551e501d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_activities_df(path):\n",
    "    \"\"\" A function for creating a dataframe containing information about the beginning, end and name of each physical activity\n",
    "    Args:\n",
    "        1) path - the path to the Label Studio file that contains the labeled signals\n",
    "    Returns:\n",
    "        Dataframe containing information about the beginning, end and name of each physical activity\n",
    "    \"\"\"\n",
    "    labeled_activities = pd.read_csv(path)\n",
    "    labels = labeled_activities['label']\n",
    "    labels = np.array(labels)[0]    # the original type of labels is pd.Series\n",
    "    labels = labels.split('},')\n",
    "    \n",
    "    activities_dict = {'start_time': [], 'end_time': [], 'activity': []}\n",
    "    for label in labels:\n",
    "        start_time, end_time, _, activity = label.split(',')\n",
    "        activities_dict['start_time'].append(float(start_time.split(':')[1]))\n",
    "        activities_dict['end_time'].append(float(end_time.split(':')[1]))\n",
    "        activities_dict['activity'].append(activity.split(':')[1].strip('[]}\"'))\n",
    "    \n",
    "    activities_df = pd.DataFrame.from_dict(activities_dict)\n",
    "    activities_df = activities_df.sort_values(by='start_time').reset_index(drop=True)\n",
    "    return activities_df\n",
    "\n",
    "def add_activity_column(path, df, df_merge_col):\n",
    "    \"\"\" Function to add 'activity' column to dataframe df\n",
    "    Args:\n",
    "        1) path - the path to the Label Studio file that contains the labeled signals\n",
    "        2) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        3) df_merge_col - the name of the column of the dataframe df, which contains data about the measurement time ('time' column)\n",
    "    \"\"\"\n",
    "    activities_df_local = create_activities_df(path)\n",
    "    merged_df = pd.merge_asof(df, activities_df_local, left_on=df_merge_col, right_on='start_time', direction='backward')\n",
    "    df['activity'] = merged_df['activity']\n",
    "    \n",
    "    \n",
    "def display_activity_freq_spectrum_one_axes(df, activity_name, axes_name, sampling_rate, is_divided_by_g=False, x_lim=10, color='blue'):\n",
    "    \"\"\" Function to display the frequency spectrum of the specified type of activity on the OX, OY and OZ axes for the specified device \n",
    "    (accelerometer or gyroscope)\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        2) activity_name - selected activity type (among the values of the 'activity' column of df)\n",
    "        3) axes_name - the column name of the dataframe df that contain the measurement results for the OX, OY, or OZ axes\n",
    "        4) sampling_rate - actual sampling rate of your dataset (samples per second)\n",
    "        5) is_divided_by_g - True if the content of the column was divided by the free fall acceleration g (g=9.81 m/s^2)\n",
    "        6) x_lim - the limits of the graph along the OX axis are [-x_lim; x_lim]\n",
    "        7) color - the color of the graph\n",
    "    \"\"\"\n",
    "    activity_data = df[df['activity'] == activity_name]\n",
    "    \n",
    "    signal = np.array(activity_data[axes_name])\n",
    "    \n",
    "    if is_divided_by_g:\n",
    "        signal *= 9.81\n",
    "        \n",
    "    fft_result = fft(signal)\n",
    "\n",
    "    fft_freqs = fftfreq(len(activity_data), 1/sampling_rate)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    axes = fig.add_axes([0.1, 0.1, 1, 1])\n",
    "    axes.plot(fft_freqs, np.abs(fft_result), color=color)\n",
    "    axes.set_title(f'{activity_name} {axes_name}')\n",
    "\n",
    "    axes.set_xlabel('Frequency (Hz)')\n",
    "    axes.set_xlim(-x_lim, x_lim)\n",
    "    axes.set_ylabel('Amplitude')\n",
    "    axes.grid(alpha=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def display_activity_freq_spectrum(df, activity_name, axes_names, sampling_rate, is_divided_by_g=False, x_lim=10):\n",
    "    \"\"\" Function to display the frequency spectrum of the specified type of activity on the OX, OY and OZ axes for the specified device \n",
    "    (accelerometer or gyroscope)\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        2) activity_name - selected activity type (among the values of the 'activity' column of df)\n",
    "        3) axes_names - an array containing the column names of the dataframe df that contain the measurement results for the OX, OY, and OZ axes, \n",
    "        respectively\n",
    "        4) sampling_rate - actual sampling rate of your dataset (samples per second)\n",
    "        5) is_divided_by_g - True if the content of the column was divided by the free fall acceleration g (g=9.81 m/s^2)\n",
    "        6) x_lim - the limits of the graph along the OX axis are [-x_lim; x_lim]\n",
    "    \"\"\"\n",
    "    activity_data = df[df['activity'] == activity_name]\n",
    "    \n",
    "    signal_x = np.array(activity_data[axes_names[0]])\n",
    "    signal_y = np.array(activity_data[axes_names[1]])\n",
    "    signal_z = np.array(activity_data[axes_names[2]])\n",
    "    \n",
    "    if is_divided_by_g:\n",
    "        signal_x *= 9.81\n",
    "        signal_y *= 9.81\n",
    "        signal_z *= 9.81\n",
    "        \n",
    "    fft_x = fft(signal_x)\n",
    "    fft_y = fft(signal_y)\n",
    "    fft_z = fft(signal_z)\n",
    "\n",
    "    fft_freqs = fftfreq(len(activity_data), 1/sampling_rate)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].plot(fft_freqs, np.abs(fft_x), label='X', color='blue')\n",
    "    axes[0].set_title(f'{activity_name} {axes_names[0]}')\n",
    "\n",
    "    axes[1].plot(fft_freqs, np.abs(fft_y), label='Y', color='yellow')\n",
    "    axes[1].set_title(f'{activity_name} {axes_names[1]}')\n",
    "\n",
    "    axes[2].plot(fft_freqs, np.abs(fft_z), label='Z', color='green')\n",
    "    axes[2].set_title(f'{activity_name} {axes_names[2]}')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Frequency (Hz)')\n",
    "        ax.set_xlim(-x_lim, x_lim)\n",
    "        ax.set_xticks([i for i in range(-x_lim, x_lim+1, 2)])\n",
    "        ax.set_ylabel('Amplitude')\n",
    "        ax.grid(alpha=0.5)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56c5f5-4402-4004-a4c6-7323fcc39510",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploring measurement time and frequency stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724409a-63f5-44c4-b48a-ede3fbfe93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_time_df(df):\n",
    "    \"\"\" A function for building a dataframe that contains information about the time of measurement of each reading of the device\n",
    "    Args:\n",
    "        1) df - a dataframe that contains a 'time' column\n",
    "    Returns:\n",
    "        time_measurement_df - dataframe that contains information about the time of measurement of each reading of the device\n",
    "    \"\"\"\n",
    "    period_dict = {'start_time': [], 'end_time': [], 'measurement_time': []}\n",
    "    prev_time = None\n",
    "    curr_time = None\n",
    "    for index, row in df.iterrows():\n",
    "        if(index == len(df)):\n",
    "            break\n",
    "            \n",
    "        prev_time = curr_time\n",
    "        curr_time = row['time']\n",
    "\n",
    "        if prev_time != None:\n",
    "            period_dict['start_time'].append(prev_time)\n",
    "            period_dict['end_time'].append(curr_time)\n",
    "            period_dict['measurement_time'].append(curr_time - prev_time)\n",
    "    \n",
    "    time_measurement_df = pd.DataFrame.from_dict(period_dict)\n",
    "    return time_measurement_df\n",
    "\n",
    "\n",
    "def display_time_distribution(df, x):\n",
    "    \"\"\" A function that is designed to display the measurement time distribution using a histogram\n",
    "    Args:\n",
    "        1) df - a dataframe that contains a column with measurement time data\n",
    "        2) x - name of measurement time column\n",
    "    \"\"\"\n",
    "    # Plot the measurement time distribution using seaborn's histogram\n",
    "    # plt.figure(figsize=(15, 6)) - original size\n",
    "    plt.figure(figsize=(25, 6))\n",
    "    sns.histplot(df[x], bins=60, kde=True, color='blue')\n",
    "    plt.xlabel('Period, s')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Measurement Time Distribution')\n",
    "    plt.xticks([i/1000 for i in range(0, 38, 1)])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_data_collection_stability(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the time when the measurements were taken and \n",
    "       relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 14))\n",
    "    axes[0].plot(range(len(df[df['lost_data'] == 0])), df[df['lost_data'] == 0]['measurement_time'])\n",
    "    axes[0].set_title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    axes[0].set_xlabel('number of measurement')\n",
    "    axes[0].set_ylabel('measurement time')\n",
    "    \n",
    "    axes[1].plot(df[df['lost_data'] == 0]['start_time'], df[df['lost_data'] == 0]['measurement_time'])\n",
    "    axes[1].set_title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    axes[1].set_xlabel('time of measurement')\n",
    "    axes[1].set_ylabel('measurement time')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def display_data_collection_stability_measurement_number(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(range(len(df[df['lost_data'] == 0])), df[df['lost_data'] == 0]['measurement_time'])\n",
    "    plt.title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('number of measurement')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_stability_measurement_time(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the time when the measurements were taken\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(time_measurement_df[time_measurement_df['lost_data'] == 0]['start_time'], \n",
    "             time_measurement_df[time_measurement_df['lost_data'] == 0]['measurement_time'])\n",
    "    plt.title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('time of measurement')\n",
    "    plt.ylabel('measurement time')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_losses_measurement_number(df):\n",
    "    \"\"\"A function that displays the loses of data collection relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(range(len(df[df['lost_data'] == 1])), df[df['lost_data'] == 1]['measurement_time'])\n",
    "    plt.title(f'Data Collection Losses (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('number of measurement')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_losses_measurement_time(df):\n",
    "    \"\"\"A function that displays data collection losses relative to the time when the measurements were taken\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(time_measurement_df[time_measurement_df['lost_data'] == 1]['start_time'], \n",
    "             time_measurement_df[time_measurement_df['lost_data'] == 1]['measurement_time'])\n",
    "    plt.title(f'Data Collection Losses (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('time of measurement, s')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0f1fc-9064-468f-ae5a-d20ce3be2753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61686a-e765-4063-80f4-719aa97be529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_three_axes(df, y, x=None, title=None, x_label=None, y_label=None, filename=None):\n",
    "    \"\"\" Function for visualization of three axes (X, Y, Z) of the measurement results of the device\n",
    "    Args:\n",
    "        1) df - a dataframe containing the results of the device measurement\n",
    "        2) x - the name of the column of the dataframe that contains the data for the OX axis (for the three lines, this is the same data)\n",
    "        3) y - the list containing the dataframe column names corresponding to the OX, OY, and OZ axis measurements, respectively\n",
    "        4) title - title of the graph\n",
    "        5) x_label - the name of the OX axis of the graph\n",
    "        6) y_label - the name of the OY axis of the graph\n",
    "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        Nothing, but plots graph\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if x is None:\n",
    "        plt.plot(df[y[0]], label='X')\n",
    "        plt.plot(df[y[1]], label='Y')\n",
    "        plt.plot(df[y[2]], label='Z')\n",
    "    else:\n",
    "        plt.plot(df[x], df[y[0]], label='X')\n",
    "        plt.plot(df[x], df[y[1]], label='Y')\n",
    "        plt.plot(df[x], df[y[2]], label='Z')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_three_axes_sep(df, x, y, title=None, x_label=None, y_labels=None):\n",
    "    \"\"\" Function for visualization of three axes (X, Y, Z) of the measurement results of the device, a separate graph for each axis\n",
    "    Args:\n",
    "        1) df - a dataframe containing the results of the device measurement;\n",
    "        2) x - the name of the column of the dataframe that contains the data for the OX axis (for the three lines, this is the same data);\n",
    "        3) y - the list containing the dataframe column names corresponding to the OX, OY, and OZ axis measurements, respectively;\n",
    "        4) title - title of the graph;\n",
    "        5) x_label - the name of the OX axis of the graph;\n",
    "        6) y_labels - the list of names of the OY axis of the graph.\n",
    "    Returns:\n",
    "        Nothing, but plots graph\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 18))\n",
    "    axes[0].plot(df[x], df[y[0]], color='blue')\n",
    "    axes[0].set_xlabel(x_label)\n",
    "    axes[0].set_ylabel(y_labels[0])\n",
    "    axes[0].set_title(title + ' accX')\n",
    "\n",
    "    axes[1].plot(df[x], df[y[1]], color='yellow')\n",
    "    axes[1].set_xlabel(x_label)\n",
    "    axes[1].set_ylabel(y_labels[1])\n",
    "    axes[1].set_title(title + ' accY')\n",
    "\n",
    "    axes[2].plot(df[x], df[y[2]], color='green')\n",
    "    axes[2].set_xlabel(x_label)\n",
    "    axes[2].set_ylabel(y_labels[2])\n",
    "    axes[2].set_title(title + ' accZ')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54ddda-53cf-4338-b456-27bfef548cad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503dc37-506b-4d9c-a79d-7c475f3a9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_statistical_measures_columns(X_df, data_df, X_df_columns_add, data_df_columns_add):\n",
    "    \"\"\"Function to add columns, which contains statistical measures, to X_df\n",
    "    Args:\n",
    "        1) X_df - the dataframe to which the new columns will be added;\n",
    "        2) data_df - a dataframe that contains arrays with data needed to calculate statistical measures;\n",
    "        3) X_df_columns_add - a suffix that specifies what the new columns of X_df will be named \n",
    "           (for example, for the suffix 'accel', the first 3 columns will be named 'accel_x_mean', 'accel_y_mean' and 'accel_z_mean');\n",
    "        4) data_df_columns_add - a suffix that determines from which columns of the data frame data_df the necessary data for calculating \n",
    "           statistical measures will be taken.\n",
    "           For example, if you need to calculate statistical parameters for the accelerometer, you should specify a suffix as the beginning\n",
    "           of the name of the accelerometer readings in the data_df dataframe, in particular 'gF'.\n",
    "    \"\"\"\n",
    "    # mean\n",
    "    X_df[f'{X_df_columns_add}_x_mean'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.mean())\n",
    "    X_df[f'{X_df_columns_add}_y_mean'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.mean())\n",
    "    X_df[f'{X_df_columns_add}_z_mean'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.mean())\n",
    "\n",
    "    # variation\n",
    "    X_df[f'{X_df_columns_add}_x_variation'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "    X_df[f'{X_df_columns_add}_y_variation'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "    X_df[f'{X_df_columns_add}_z_variation'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "\n",
    "    # std deviation\n",
    "    X_df[f'{X_df_columns_add}_x_std'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.std())\n",
    "    X_df[f'{X_df_columns_add}_y_std'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.std())\n",
    "    X_df[f'{X_df_columns_add}_z_std'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_df[f'{X_df_columns_add}_x_aad'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_df[f'{X_df_columns_add}_y_aad'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_df[f'{X_df_columns_add}_z_aad'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_df[f'{X_df_columns_add}_x_min'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.min())\n",
    "    X_df[f'{X_df_columns_add}_y_min'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.min())\n",
    "    X_df[f'{X_df_columns_add}_z_min'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_df[f'{X_df_columns_add}_x_max'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.max())\n",
    "    X_df[f'{X_df_columns_add}_y_max'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.max())\n",
    "    X_df[f'{X_df_columns_add}_z_max'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.max())\n",
    "\n",
    "    # max-min diff\n",
    "    X_df[f'{X_df_columns_add}_x_maxmin_diff'] = X_df[f'{X_df_columns_add}_x_max'] - X_df[f'{X_df_columns_add}_x_min']\n",
    "    X_df[f'{X_df_columns_add}_y_maxmin_diff'] = X_df[f'{X_df_columns_add}_y_max'] - X_df[f'{X_df_columns_add}_y_min']\n",
    "    X_df[f'{X_df_columns_add}_z_maxmin_diff'] = X_df[f'{X_df_columns_add}_z_max'] - X_df[f'{X_df_columns_add}_z_min']\n",
    "\n",
    "    # median\n",
    "    X_df[f'{X_df_columns_add}_x_median'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.median(x))\n",
    "    X_df[f'{X_df_columns_add}_y_median'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.median(x))\n",
    "    X_df[f'{X_df_columns_add}_z_median'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_df[f'{X_df_columns_add}_x_mad'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_df[f'{X_df_columns_add}_y_mad'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_df[f'{X_df_columns_add}_z_mad'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_df[f'{X_df_columns_add}_x_IQR'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_df[f'{X_df_columns_add}_y_IQR'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_df[f'{X_df_columns_add}_z_IQR'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negative count\n",
    "    X_df[f'{X_df_columns_add}_x_neg_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x < 0))\n",
    "    X_df[f'{X_df_columns_add}_y_neg_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x < 0))\n",
    "    X_df[f'{X_df_columns_add}_z_neg_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_df[f'{X_df_columns_add}_x_pos_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x > 0))\n",
    "    X_df[f'{X_df_columns_add}_y_pos_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x > 0))\n",
    "    X_df[f'{X_df_columns_add}_z_pos_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_df[f'{X_df_columns_add}_x_above_mean'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_df[f'{X_df_columns_add}_y_above_mean'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_df[f'{X_df_columns_add}_z_above_mean'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_df[f'{X_df_columns_add}_x_peak_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_df[f'{X_df_columns_add}_y_peak_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_df[f'{X_df_columns_add}_z_peak_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # skewness = assymetry\n",
    "    X_df[f'{X_df_columns_add}_x_assymetry'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: stats.skew(x))\n",
    "    X_df[f'{X_df_columns_add}_y_assymetry'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: stats.skew(x))\n",
    "    X_df[f'{X_df_columns_add}_z_assymetry'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # kurtosis\n",
    "    X_df[f'{X_df_columns_add}_x_kurtosis'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: stats.kurtosis(x))\n",
    "    X_df[f'{X_df_columns_add}_y_kurtosis'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: stats.kurtosis(x))\n",
    "    X_df[f'{X_df_columns_add}_z_kurtosis'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # energy\n",
    "    X_df[f'{X_df_columns_add}_x_energy'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x**2)/100)\n",
    "    X_df[f'{X_df_columns_add}_y_energy'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x**2)/100)\n",
    "    X_df[f'{X_df_columns_add}_z_energy'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x**2/100))\n",
    "\n",
    "    # avg resultant\n",
    "    X_df[f'{X_df_columns_add}_avg_result_accl'] = [i.mean() for i in ((data_df[f'{data_df_columns_add}x_s']**2 \n",
    "                                                   + data_df[f'{data_df_columns_add}y_s']**2 + data_df[f'{data_df_columns_add}z_s']**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_df[f'{X_df_columns_add}_sma'] =data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(abs(x)/100)) + data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(abs(x)/100)) + data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(abs(x)/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906922fa-c4a1-4812-a252-261dd086badb",
   "metadata": {},
   "source": [
    "# Work with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fddbd8-600f-41a3-8e03-2afa5bef395e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## squats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77a2e259-c04b-4e1c-8876-043831a01670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1692440406933</td>\n",
       "      <td>0.14895</td>\n",
       "      <td>-0.06000</td>\n",
       "      <td>9.775050</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-1.117325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1692440406976</td>\n",
       "      <td>-0.05400</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>9.748950</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>-0.163075</td>\n",
       "      <td>-1.241488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1692440407003</td>\n",
       "      <td>0.23295</td>\n",
       "      <td>-0.12405</td>\n",
       "      <td>9.739051</td>\n",
       "      <td>0.096937</td>\n",
       "      <td>-0.311437</td>\n",
       "      <td>-1.159812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692440407037</td>\n",
       "      <td>-0.18495</td>\n",
       "      <td>-0.01200</td>\n",
       "      <td>9.691051</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>-0.309375</td>\n",
       "      <td>-0.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1692440407057</td>\n",
       "      <td>-0.46305</td>\n",
       "      <td>0.13605</td>\n",
       "      <td>10.146001</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.771787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp     accX     accY       accZ      gyrX      gyrY      gyrZ\n",
       "0  1692440406933  0.14895 -0.06000   9.775050  0.106150 -0.018975 -1.117325\n",
       "1  1692440406976 -0.05400  0.04200   9.748950  0.110550 -0.163075 -1.241488\n",
       "2  1692440407003  0.23295 -0.12405   9.739051  0.096937 -0.311437 -1.159812\n",
       "3  1692440407037 -0.18495 -0.01200   9.691051  0.079475 -0.309375 -0.900900\n",
       "4  1692440407057 -0.46305  0.13605  10.146001  0.065037 -0.293013 -0.771787"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_1 = pd.read_csv('data/40_Hz/original_data/train/Squats/1_HIMU-2023-08-19_13-20-06.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e9908c9-564c-4e05-b1b6-ed4d9195147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2859 entries, 0 to 2858\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  2859 non-null   int64  \n",
      " 1   accX       2859 non-null   float64\n",
      " 2   accY       2859 non-null   float64\n",
      " 3   accZ       2859 non-null   float64\n",
      " 4   gyrX       2859 non-null   float64\n",
      " 5   gyrY       2859 non-null   float64\n",
      " 6   gyrZ       2859 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 156.5 KB\n"
     ]
    }
   ],
   "source": [
    "squats_df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32f77945-c24b-4ba6-92ce-88cbbefc24ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing reindexing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1692440406933</td>\n",
       "      <td>2023-08-19 13:20:06.933</td>\n",
       "      <td>0.14895</td>\n",
       "      <td>-0.06000</td>\n",
       "      <td>9.775050</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-1.117325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1692440406976</td>\n",
       "      <td>2023-08-19 13:20:06.976</td>\n",
       "      <td>-0.05400</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>9.748950</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>-0.163075</td>\n",
       "      <td>-1.241488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1692440407003</td>\n",
       "      <td>2023-08-19 13:20:07.003</td>\n",
       "      <td>0.23295</td>\n",
       "      <td>-0.12405</td>\n",
       "      <td>9.739051</td>\n",
       "      <td>0.096937</td>\n",
       "      <td>-0.311437</td>\n",
       "      <td>-1.159812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692440407037</td>\n",
       "      <td>2023-08-19 13:20:07.037</td>\n",
       "      <td>-0.18495</td>\n",
       "      <td>-0.01200</td>\n",
       "      <td>9.691051</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>-0.309375</td>\n",
       "      <td>-0.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1692440407057</td>\n",
       "      <td>2023-08-19 13:20:07.057</td>\n",
       "      <td>-0.46305</td>\n",
       "      <td>0.13605</td>\n",
       "      <td>10.146001</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.771787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                datetime     accX     accY       accZ  \\\n",
       "0  1692440406933 2023-08-19 13:20:06.933  0.14895 -0.06000   9.775050   \n",
       "1  1692440406976 2023-08-19 13:20:06.976 -0.05400  0.04200   9.748950   \n",
       "2  1692440407003 2023-08-19 13:20:07.003  0.23295 -0.12405   9.739051   \n",
       "3  1692440407037 2023-08-19 13:20:07.037 -0.18495 -0.01200   9.691051   \n",
       "4  1692440407057 2023-08-19 13:20:07.057 -0.46305  0.13605  10.146001   \n",
       "\n",
       "       gyrX      gyrY      gyrZ  \n",
       "0  0.106150 -0.018975 -1.117325  \n",
       "1  0.110550 -0.163075 -1.241488  \n",
       "2  0.096937 -0.311437 -1.159812  \n",
       "3  0.079475 -0.309375 -0.900900  \n",
       "4  0.065037 -0.293013 -0.771787  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_TIME, 'uk_UA')\n",
    "\n",
    "# Get the timezone for your locale\n",
    "local_timezone = dateutil.tz.tzlocal()\n",
    "\n",
    "squats_df_1 = add_datetime_column(df=squats_df_1, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9b282-89f3-4fce-88d4-d96ff931c39b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1a8d6-136e-49b1-baee-43f3433b957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=squats_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2', filename='graphs/squats_acc')\n",
    "display_three_axes(df=squats_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f283c-55a8-4d0b-821b-660dc3be30a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## leg_land_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bd55a-a957-48bc-b7c8-eb6e38106520",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "leg_land_df = pd.read_csv('data/10_Hz/original_data/train/LegLand_HIMU-2023-08-15_09-49-34.csv', names=columns, skiprows=4)\n",
    "\n",
    "leg_land_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91962846-319b-4486-98d5-4efcd5bd1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_land_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1d38b-5c23-4a6b-aca8-fce40432b82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbbb41-c968-4cbd-99a4-6a4e0c2ad480",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=leg_land_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=leg_land_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666a6ef-6a73-4a6a-88a0-c9f0d9a6e163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## walk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38953052-591c-41cf-96ea-84b78361dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "walk_df = pd.read_csv('data/10_Hz/original_data/train/Walk_HIMU-2023-08-16_09-25-42.csv', names=columns, skiprows=4)\n",
    "\n",
    "walk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24909aa8-92ff-4022-85a1-48ec53f803f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0736e-3702-4bde-a0f1-c9b1188f93ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f25c3-4f7f-42ac-94ed-71a00c44a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=walk_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=walk_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe4e71-4e5f-4522-b71a-a5648a56b10c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## lateral_squat_slide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a72223-f5cf-4d05-8063-b7c29a4c2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "lateral_squat_slide_df = pd.read_csv('data/10_Hz/original_data/train/Lateral_HIMU-2023-08-16_09-36-12.csv', names=columns, skiprows=4)\n",
    "\n",
    "lateral_squat_slide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c2c27-ac8e-4f31-9843-7dd3b75112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_squat_slide_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92c79b-5d51-4762-9e5d-d42ca2087bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250f3b8-9728-44a9-8e49-4bb407c8c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=lateral_squat_slide_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=lateral_squat_slide_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e2325-2f25-4b10-8da6-a0c965d83ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## jogging_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661bf64-ec8f-43fa-842e-54a24894336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "jogging_df = pd.read_csv('data/10_Hz/original_data/train/Jogging_HIMU-2023-08-17_09-24-25.csv', names=columns, skiprows=4)\n",
    "\n",
    "jogging_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5a212-cd17-4482-be9f-19fa0301a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jogging_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90bf8c-c5dd-4f6c-96a4-55b755584cc9",
   "metadata": {},
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bfc50-d077-423d-8bf6-fa5294ed2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=jogging_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=jogging_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579b473-acec-41c6-8f0a-c5cd0cbe83a9",
   "metadata": {},
   "source": [
    "## test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a2c60-bfa8-46ca-9855-e5ded9d31054",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "test_df = pd.read_csv('data/10_Hz/original_data/test/Test_HIMU-2023-08-17_09-40-28.csv', names=columns, skiprows=4)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94345834-da52-4618-a22e-6be35a83dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d62fae-5bf4-42d7-8267-6695a4dbaeac",
   "metadata": {},
   "source": [
    "### Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581a01b-4c7e-4fa9-a589-e2e44cb49abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=test_df, y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=test_df, y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   y_label='Angular velocity, rad/s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
