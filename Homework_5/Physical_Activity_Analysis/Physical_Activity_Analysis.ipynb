{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641968-9595-458a-b449-e9028c13ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import locale\n",
    "import dateutil.tz\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90e5f1-ff70-4a9e-b65e-1e9d7a2fe1a7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbc252-8614-427b-8559-226bd8c2387b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a dataframe for each type of activity by connecting smaller dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57510dc6-fcbf-4f2e-aa70-d1eb1353d001",
   "metadata": {},
   "source": [
    "### Implement the necessary columns in smaller dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab123620-c2e3-4e3b-8058-4194182417a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_column(df, timestamp_col_name, local_timezone=datetime.timezone.utc, reordering=False):\n",
    "    \"\"\" A function to add a 'datetime' column that contains information about the date and time of the recording\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the required data\n",
    "        2) timestamp_col_name - the name of the df dataframe column that contains the timestamp information\n",
    "        3) local_timezone - the time zone in which the measurements were made (object of class 'dateutil.tz.tz.tzlocal')\n",
    "        4) reordering - rearrange the dataframe columns so that the 'datetime' column is next to the 'timestamp' column\n",
    "    Returns:\n",
    "        A dataframe that contains a 'datetime' column\n",
    "    \"\"\"\n",
    "    df['datetime'] = df[timestamp_col_name].apply(lambda timestamp:\n",
    "        datetime.datetime.fromtimestamp(timestamp / 1000.0, tz=local_timezone).strftime(\"%d.%m.%Y, %H:%M:%S.%f\")[:-3])\n",
    "    df['datetime'] = df['datetime'].apply(lambda timestamp_str: \n",
    "        datetime.datetime.strptime(timestamp_str, \"%d.%m.%Y, %H:%M:%S.%f\"))\n",
    "    \n",
    "    if reordering:\n",
    "        # Reorder the columns\n",
    "        new_column_order = [timestamp_col_name, 'datetime'] + [col for col in df.columns if col != timestamp_col_name and col != 'datetime']\n",
    "        df = df.reindex(columns=new_column_order)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_time_column(df, timestamp_col_name, initial_time=0, timecol_position=1):\n",
    "    \"\"\"A function to add a 'time' column to the original dataframe, which contains the recording time relative to the initial time instant_time\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the required data\n",
    "        2) timestamp_col_name - the name of the df dataframe column that contains the timestamp information\n",
    "        3) initial_time - initial moment of time (s)\n",
    "        4) timecol_position - index of column 'time'position among other columns (column indexing starts at 0)\n",
    "    Returns:\n",
    "        A dataframe that contains a 'time' column\n",
    "    \"\"\"\n",
    "    # Convert the 'timestamp' column to pandas Timestamp type\n",
    "    df['temp_timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # Calculate the time difference relative to the start\n",
    "    df['time'] = initial_time + (df['temp_timestamp'] - df['temp_timestamp'].iloc[0]).dt.total_seconds()\n",
    "    \n",
    "    # Drop unnecessary 'temp_timestamp' column\n",
    "    df.drop('temp_timestamp', axis=1, inplace=True)\n",
    "    \n",
    "    # Pop the 'time' column and store it in a variable\n",
    "    time_column = df.pop('time')\n",
    "\n",
    "    # Insert the 'time' column at the desired position\n",
    "    df.insert(timecol_position, 'time', time_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7072c87-8e1d-44b9-af32-db16bc4e6735",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create activity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b7b99-5f61-45b9-bca3-b0551e501d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_activities_df(path):\n",
    "    \"\"\" A function for creating a dataframe containing information about the beginning, end and name of each physical activity\n",
    "    Args:\n",
    "        1) path - the path to the Label Studio file that contains the labeled signals\n",
    "    Returns:\n",
    "        Dataframe containing information about the beginning, end and name of each physical activity\n",
    "    \"\"\"\n",
    "    labeled_activities = pd.read_csv(path)\n",
    "    labels = labeled_activities['label']\n",
    "    labels = np.array(labels)[0]    # the original type of labels is pd.Series\n",
    "    labels = labels.split('},')\n",
    "    \n",
    "    activities_dict = {'start_time': [], 'end_time': [], 'activity': []}\n",
    "    for label in labels:\n",
    "        start_time, end_time, _, activity = label.split(',')\n",
    "        activities_dict['start_time'].append(float(start_time.split(':')[1]))\n",
    "        activities_dict['end_time'].append(float(end_time.split(':')[1]))\n",
    "        activities_dict['activity'].append(activity.split(':')[1].strip('[]}\"'))\n",
    "    \n",
    "    activities_df = pd.DataFrame.from_dict(activities_dict)\n",
    "    activities_df = activities_df.sort_values(by='start_time').reset_index(drop=True)\n",
    "    return activities_df\n",
    "\n",
    "def add_activity_column(path, df, df_merge_col):\n",
    "    \"\"\" Function to add 'activity' column to dataframe df\n",
    "    Args:\n",
    "        1) path - the path to the Label Studio file that contains the labeled signals\n",
    "        2) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        3) df_merge_col - the name of the column of the dataframe df, which contains data about the measurement time ('time' column)\n",
    "    \"\"\"\n",
    "    activities_df_local = create_activities_df(path)\n",
    "    merged_df = pd.merge_asof(df, activities_df_local, left_on=df_merge_col, right_on='start_time', direction='backward')\n",
    "    df['activity'] = merged_df['activity']\n",
    "    \n",
    "    \n",
    "def display_activity_freq_spectrum_one_axes(df, activity_name, axes_name, sampling_rate, is_divided_by_g=False, x_lim=10, color='blue'):\n",
    "    \"\"\" Function to display the frequency spectrum of the specified type of activity on the OX, OY and OZ axes for the specified device \n",
    "    (accelerometer or gyroscope)\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        2) activity_name - selected activity type (among the values of the 'activity' column of df)\n",
    "        3) axes_name - the column name of the dataframe df that contain the measurement results for the OX, OY, or OZ axes\n",
    "        4) sampling_rate - actual sampling rate of your dataset (samples per second)\n",
    "        5) is_divided_by_g - True if the content of the column was divided by the free fall acceleration g (g=9.81 m/s^2)\n",
    "        6) x_lim - the limits of the graph along the OX axis are [-x_lim; x_lim]\n",
    "        7) color - the color of the graph\n",
    "    \"\"\"\n",
    "    activity_data = df[df['activity'] == activity_name]\n",
    "    \n",
    "    signal = np.array(activity_data[axes_name])\n",
    "    \n",
    "    if is_divided_by_g:\n",
    "        signal *= 9.81\n",
    "        \n",
    "    fft_result = fft(signal)\n",
    "\n",
    "    fft_freqs = fftfreq(len(activity_data), 1/sampling_rate)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    axes = fig.add_axes([0.1, 0.1, 1, 1])\n",
    "    axes.plot(fft_freqs, np.abs(fft_result), color=color)\n",
    "    axes.set_title(f'{activity_name} {axes_name}')\n",
    "\n",
    "    axes.set_xlabel('Frequency (Hz)')\n",
    "    axes.set_xlim(-x_lim, x_lim)\n",
    "    axes.set_ylabel('Amplitude')\n",
    "    axes.grid(alpha=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def display_activity_freq_spectrum(df, activity_name, axes_names, sampling_rate, is_divided_by_g=False, x_lim=10):\n",
    "    \"\"\" Function to display the frequency spectrum of the specified type of activity on the OX, OY and OZ axes for the specified device \n",
    "    (accelerometer or gyroscope)\n",
    "    Args:\n",
    "        1) df - a dataframe that contains the results of accelerometer and gyroscope measurements\n",
    "        2) activity_name - selected activity type (among the values of the 'activity' column of df)\n",
    "        3) axes_names - an array containing the column names of the dataframe df that contain the measurement results for the OX, OY, and OZ axes, \n",
    "        respectively\n",
    "        4) sampling_rate - actual sampling rate of your dataset (samples per second)\n",
    "        5) is_divided_by_g - True if the content of the column was divided by the free fall acceleration g (g=9.81 m/s^2)\n",
    "        6) x_lim - the limits of the graph along the OX axis are [-x_lim; x_lim]\n",
    "    \"\"\"\n",
    "    activity_data = df[df['activity'] == activity_name]\n",
    "    \n",
    "    signal_x = np.array(activity_data[axes_names[0]])\n",
    "    signal_y = np.array(activity_data[axes_names[1]])\n",
    "    signal_z = np.array(activity_data[axes_names[2]])\n",
    "    \n",
    "    if is_divided_by_g:\n",
    "        signal_x *= 9.81\n",
    "        signal_y *= 9.81\n",
    "        signal_z *= 9.81\n",
    "        \n",
    "    fft_x = fft(signal_x)\n",
    "    fft_y = fft(signal_y)\n",
    "    fft_z = fft(signal_z)\n",
    "\n",
    "    fft_freqs = fftfreq(len(activity_data), 1/sampling_rate)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].plot(fft_freqs, np.abs(fft_x), label='X', color='blue')\n",
    "    axes[0].set_title(f'{activity_name} {axes_names[0]}')\n",
    "\n",
    "    axes[1].plot(fft_freqs, np.abs(fft_y), label='Y', color='yellow')\n",
    "    axes[1].set_title(f'{activity_name} {axes_names[1]}')\n",
    "\n",
    "    axes[2].plot(fft_freqs, np.abs(fft_z), label='Z', color='green')\n",
    "    axes[2].set_title(f'{activity_name} {axes_names[2]}')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Frequency (Hz)')\n",
    "        ax.set_xlim(-x_lim, x_lim)\n",
    "        ax.set_xticks([i for i in range(-x_lim, x_lim+1, 2)])\n",
    "        ax.set_ylabel('Amplitude')\n",
    "        ax.grid(alpha=0.5)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56c5f5-4402-4004-a4c6-7323fcc39510",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploring measurement time and frequency stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724409a-63f5-44c4-b48a-ede3fbfe93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_time_df(df):\n",
    "    \"\"\" A function for building a dataframe that contains information about the time of measurement of each reading of the device\n",
    "    Args:\n",
    "        1) df - a dataframe that contains a 'time' column\n",
    "    Returns:\n",
    "        time_measurement_df - dataframe that contains information about the time of measurement of each reading of the device\n",
    "    \"\"\"\n",
    "    period_dict = {'start_time': [], 'end_time': [], 'measurement_time': []}\n",
    "    prev_time = None\n",
    "    curr_time = None\n",
    "    for index, row in df.iterrows():\n",
    "        if(index == len(df)):\n",
    "            break\n",
    "            \n",
    "        prev_time = curr_time\n",
    "        curr_time = row['time']\n",
    "\n",
    "        if prev_time != None:\n",
    "            period_dict['start_time'].append(prev_time)\n",
    "            period_dict['end_time'].append(curr_time)\n",
    "            period_dict['measurement_time'].append(curr_time - prev_time)\n",
    "    \n",
    "    time_measurement_df = pd.DataFrame.from_dict(period_dict)\n",
    "    return time_measurement_df\n",
    "\n",
    "\n",
    "def display_time_distribution(df, x):\n",
    "    \"\"\" A function that is designed to display the measurement time distribution using a histogram\n",
    "    Args:\n",
    "        1) df - a dataframe that contains a column with measurement time data\n",
    "        2) x - name of measurement time column\n",
    "    \"\"\"\n",
    "    # Plot the measurement time distribution using seaborn's histogram\n",
    "    # plt.figure(figsize=(15, 6)) - original size\n",
    "    plt.figure(figsize=(25, 6))\n",
    "    sns.histplot(df[x], bins=60, kde=True, color='blue')\n",
    "    plt.xlabel('Period, s')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Measurement Time Distribution')\n",
    "    plt.xticks([i/1000 for i in range(0, 38, 1)])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_data_collection_stability(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the time when the measurements were taken and \n",
    "       relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 14))\n",
    "    axes[0].plot(range(len(df[df['lost_data'] == 0])), df[df['lost_data'] == 0]['measurement_time'])\n",
    "    axes[0].set_title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    axes[0].set_xlabel('number of measurement')\n",
    "    axes[0].set_ylabel('measurement time')\n",
    "    \n",
    "    axes[1].plot(df[df['lost_data'] == 0]['start_time'], df[df['lost_data'] == 0]['measurement_time'])\n",
    "    axes[1].set_title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    axes[1].set_xlabel('time of measurement')\n",
    "    axes[1].set_ylabel('measurement time')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def display_data_collection_stability_measurement_number(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(range(len(df[df['lost_data'] == 0])), df[df['lost_data'] == 0]['measurement_time'])\n",
    "    plt.title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('number of measurement')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_stability_measurement_time(df):\n",
    "    \"\"\"A function that displays the stability of data collection relative to the time when the measurements were taken\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(time_measurement_df[time_measurement_df['lost_data'] == 0]['start_time'], \n",
    "             time_measurement_df[time_measurement_df['lost_data'] == 0]['measurement_time'])\n",
    "    plt.title(f'Stability of Data Collection (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('time of measurement')\n",
    "    plt.ylabel('measurement time')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_losses_measurement_number(df):\n",
    "    \"\"\"A function that displays the loses of data collection relative to the measurement number\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(range(len(df[df['lost_data'] == 1])), df[df['lost_data'] == 1]['measurement_time'])\n",
    "    plt.title(f'Data Collection Losses (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('number of measurement')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_data_collection_losses_measurement_time(df):\n",
    "    \"\"\"A function that displays data collection losses relative to the time when the measurements were taken\n",
    "    Args:\n",
    "        1) df - time_measurement_df\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(time_measurement_df[time_measurement_df['lost_data'] == 1]['start_time'], \n",
    "             time_measurement_df[time_measurement_df['lost_data'] == 1]['measurement_time'])\n",
    "    plt.title(f'Data Collection Losses (Filtered)\\nAverage frequency: {freq:.3f} Hz')\n",
    "    plt.xlabel('time of measurement, s')\n",
    "    plt.ylabel('measurement time, s')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0f1fc-9064-468f-ae5a-d20ce3be2753",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61686a-e765-4063-80f4-719aa97be529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_three_axes(df, y, x=None, title=None, x_label=None, y_label=None, filename=None):\n",
    "    \"\"\" Function for visualization of three axes (X, Y, Z) of the measurement results of the device\n",
    "    Args:\n",
    "        1) df - a dataframe containing the results of the device measurement\n",
    "        2) x - the name of the column of the dataframe that contains the data for the OX axis (for the three lines, this is the same data)\n",
    "        3) y - the list containing the dataframe column names corresponding to the OX, OY, and OZ axis measurements, respectively\n",
    "        4) title - title of the graph\n",
    "        5) x_label - the name of the OX axis of the graph\n",
    "        6) y_label - the name of the OY axis of the graph\n",
    "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        Nothing, but plots graph\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if x is None:\n",
    "        plt.plot(df[y[0]], label='X')\n",
    "        plt.plot(df[y[1]], label='Y')\n",
    "        plt.plot(df[y[2]], label='Z')\n",
    "    else:\n",
    "        plt.plot(df[x], df[y[0]], label='X')\n",
    "        plt.plot(df[x], df[y[1]], label='Y')\n",
    "        plt.plot(df[x], df[y[2]], label='Z')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def display_three_axes_sep(df, x, y, title=None, x_label=None, y_labels=None):\n",
    "    \"\"\" Function for visualization of three axes (X, Y, Z) of the measurement results of the device, a separate graph for each axis\n",
    "    Args:\n",
    "        1) df - a dataframe containing the results of the device measurement;\n",
    "        2) x - the name of the column of the dataframe that contains the data for the OX axis (for the three lines, this is the same data);\n",
    "        3) y - the list containing the dataframe column names corresponding to the OX, OY, and OZ axis measurements, respectively;\n",
    "        4) title - title of the graph;\n",
    "        5) x_label - the name of the OX axis of the graph;\n",
    "        6) y_labels - the list of names of the OY axis of the graph.\n",
    "    Returns:\n",
    "        Nothing, but plots graph\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 18))\n",
    "    axes[0].plot(df[x], df[y[0]], color='blue')\n",
    "    axes[0].set_xlabel(x_label)\n",
    "    axes[0].set_ylabel(y_labels[0])\n",
    "    axes[0].set_title(title + ' accX')\n",
    "\n",
    "    axes[1].plot(df[x], df[y[1]], color='yellow')\n",
    "    axes[1].set_xlabel(x_label)\n",
    "    axes[1].set_ylabel(y_labels[1])\n",
    "    axes[1].set_title(title + ' accY')\n",
    "\n",
    "    axes[2].plot(df[x], df[y[2]], color='green')\n",
    "    axes[2].set_xlabel(x_label)\n",
    "    axes[2].set_ylabel(y_labels[2])\n",
    "    axes[2].set_title(title + ' accZ')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54ddda-53cf-4338-b456-27bfef548cad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503dc37-506b-4d9c-a79d-7c475f3a9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_statistical_measures_columns(X_df, data_df, X_df_columns_add, data_df_columns_add):\n",
    "    \"\"\"Function to add columns, which contains statistical measures, to X_df\n",
    "    Args:\n",
    "        1) X_df - the dataframe to which the new columns will be added;\n",
    "        2) data_df - a dataframe that contains arrays with data needed to calculate statistical measures;\n",
    "        3) X_df_columns_add - a suffix that specifies what the new columns of X_df will be named \n",
    "           (for example, for the suffix 'accel', the first 3 columns will be named 'accel_x_mean', 'accel_y_mean' and 'accel_z_mean');\n",
    "        4) data_df_columns_add - a suffix that determines from which columns of the data frame data_df the necessary data for calculating \n",
    "           statistical measures will be taken.\n",
    "           For example, if you need to calculate statistical parameters for the accelerometer, you should specify a suffix as the beginning\n",
    "           of the name of the accelerometer readings in the data_df dataframe, in particular 'gF'.\n",
    "    \"\"\"\n",
    "    # mean\n",
    "    X_df[f'{X_df_columns_add}_x_mean'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.mean())\n",
    "    X_df[f'{X_df_columns_add}_y_mean'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.mean())\n",
    "    X_df[f'{X_df_columns_add}_z_mean'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.mean())\n",
    "\n",
    "    # variation\n",
    "    X_df[f'{X_df_columns_add}_x_variation'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "    X_df[f'{X_df_columns_add}_y_variation'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "    X_df[f'{X_df_columns_add}_z_variation'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.std(x, ddof=0) / np.mean(x))\n",
    "\n",
    "    # std deviation\n",
    "    X_df[f'{X_df_columns_add}_x_std'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.std())\n",
    "    X_df[f'{X_df_columns_add}_y_std'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.std())\n",
    "    X_df[f'{X_df_columns_add}_z_std'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.std())\n",
    "\n",
    "    # avg absolute diff\n",
    "    X_df[f'{X_df_columns_add}_x_aad'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_df[f'{X_df_columns_add}_y_aad'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X_df[f'{X_df_columns_add}_z_aad'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    # min\n",
    "    X_df[f'{X_df_columns_add}_x_min'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.min())\n",
    "    X_df[f'{X_df_columns_add}_y_min'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.min())\n",
    "    X_df[f'{X_df_columns_add}_z_min'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.min())\n",
    "\n",
    "    # max\n",
    "    X_df[f'{X_df_columns_add}_x_max'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: x.max())\n",
    "    X_df[f'{X_df_columns_add}_y_max'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: x.max())\n",
    "    X_df[f'{X_df_columns_add}_z_max'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: x.max())\n",
    "\n",
    "    # max-min diff\n",
    "    X_df[f'{X_df_columns_add}_x_maxmin_diff'] = X_df[f'{X_df_columns_add}_x_max'] - X_df[f'{X_df_columns_add}_x_min']\n",
    "    X_df[f'{X_df_columns_add}_y_maxmin_diff'] = X_df[f'{X_df_columns_add}_y_max'] - X_df[f'{X_df_columns_add}_y_min']\n",
    "    X_df[f'{X_df_columns_add}_z_maxmin_diff'] = X_df[f'{X_df_columns_add}_z_max'] - X_df[f'{X_df_columns_add}_z_min']\n",
    "\n",
    "    # median\n",
    "    X_df[f'{X_df_columns_add}_x_median'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.median(x))\n",
    "    X_df[f'{X_df_columns_add}_y_median'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.median(x))\n",
    "    X_df[f'{X_df_columns_add}_z_median'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.median(x))\n",
    "\n",
    "    # median abs dev \n",
    "    X_df[f'{X_df_columns_add}_x_mad'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_df[f'{X_df_columns_add}_y_mad'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X_df[f'{X_df_columns_add}_z_mad'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "\n",
    "    # interquartile range\n",
    "    X_df[f'{X_df_columns_add}_x_IQR'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_df[f'{X_df_columns_add}_y_IQR'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X_df[f'{X_df_columns_add}_z_IQR'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "    # negative count\n",
    "    X_df[f'{X_df_columns_add}_x_neg_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x < 0))\n",
    "    X_df[f'{X_df_columns_add}_y_neg_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x < 0))\n",
    "    X_df[f'{X_df_columns_add}_z_neg_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x < 0))\n",
    "\n",
    "    # positive count\n",
    "    X_df[f'{X_df_columns_add}_x_pos_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x > 0))\n",
    "    X_df[f'{X_df_columns_add}_y_pos_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x > 0))\n",
    "    X_df[f'{X_df_columns_add}_z_pos_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x > 0))\n",
    "\n",
    "    # values above mean\n",
    "    X_df[f'{X_df_columns_add}_x_above_mean'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_df[f'{X_df_columns_add}_y_above_mean'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "    X_df[f'{X_df_columns_add}_z_above_mean'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    # number of peaks\n",
    "    X_df[f'{X_df_columns_add}_x_peak_count'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_df[f'{X_df_columns_add}_y_peak_count'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X_df[f'{X_df_columns_add}_z_peak_count'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    # skewness = assymetry\n",
    "    X_df[f'{X_df_columns_add}_x_assymetry'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: stats.skew(x))\n",
    "    X_df[f'{X_df_columns_add}_y_assymetry'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: stats.skew(x))\n",
    "    X_df[f'{X_df_columns_add}_z_assymetry'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: stats.skew(x))\n",
    "\n",
    "    # kurtosis\n",
    "    X_df[f'{X_df_columns_add}_x_kurtosis'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: stats.kurtosis(x))\n",
    "    X_df[f'{X_df_columns_add}_y_kurtosis'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: stats.kurtosis(x))\n",
    "    X_df[f'{X_df_columns_add}_z_kurtosis'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "    # energy\n",
    "    X_df[f'{X_df_columns_add}_x_energy'] = data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(x**2)/100)\n",
    "    X_df[f'{X_df_columns_add}_y_energy'] = data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(x**2)/100)\n",
    "    X_df[f'{X_df_columns_add}_z_energy'] = data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(x**2/100))\n",
    "\n",
    "    # avg resultant\n",
    "    X_df[f'{X_df_columns_add}_avg_result_accl'] = [i.mean() for i in ((data_df[f'{data_df_columns_add}x_s']**2 \n",
    "                                                   + data_df[f'{data_df_columns_add}y_s']**2 + data_df[f'{data_df_columns_add}z_s']**2)**0.5)]\n",
    "\n",
    "    # signal magnitude area\n",
    "    X_df[f'{X_df_columns_add}_sma'] =data_df[f'{data_df_columns_add}x_s'].apply(lambda x: np.sum(abs(x)/100)) + data_df[f'{data_df_columns_add}y_s'].apply(lambda x: np.sum(abs(x)/100)) + data_df[f'{data_df_columns_add}z_s'].apply(lambda x: np.sum(abs(x)/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906922fa-c4a1-4812-a252-261dd086badb",
   "metadata": {},
   "source": [
    "# Work with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fddbd8-600f-41a3-8e03-2afa5bef395e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## squats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb07872-89c6-4ef3-872f-c7c9bc891148",
   "metadata": {
    "tags": []
   },
   "source": [
    "### squats_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2e259-c04b-4e1c-8876-043831a01670",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_1 = pd.read_csv('data/40_Hz/original_data/train/Squats/1_HIMU-2023-08-19_13-20-06.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9908c9-564c-4e05-b1b6-ed4d9195147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f77945-c24b-4ba6-92ce-88cbbefc24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_TIME, 'uk_UA')\n",
    "\n",
    "# Get the timezone for your locale\n",
    "local_timezone = dateutil.tz.tzlocal()\n",
    "\n",
    "squats_df_1 = add_datetime_column(df=squats_df_1, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652556b1-b1da-4a2f-aa93-07cc2a3c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_1['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce41b02-5180-4816-acd6-bcca7d0ee8d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd211d1-c2dd-491d-a867-9bceab82aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_1 = add_time_column(df=squats_df_1, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "squats_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4ee38-4190-4aad-8a3e-7712f3cd5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_1[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9b282-89f3-4fce-88d4-d96ff931c39b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1a8d6-136e-49b1-baee-43f3433b957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=squats_df_1, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2', filename='graphs/squats_acc')\n",
    "display_three_axes(df=squats_df_1, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f281b89-5626-48fd-a265-6af5e8868bf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### squats_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aec488-8e26-48da-aa4d-48453c07b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_2 = pd.read_csv('data/40_Hz/original_data/train/Squats/2_HIMU-2023-08-19_20-18-08.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6ed81-c95b-4666-b525-69870dfd841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b0007-2bbf-42f4-87ab-f4c23c08aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the timezone for your locale\n",
    "local_timezone = dateutil.tz.tzlocal()\n",
    "\n",
    "squats_df_2 = add_datetime_column(df=squats_df_2, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58403195-04d7-4845-a9d3-6d8fd06b030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_1['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")\n",
    "\n",
    "time_diffs = squats_df_2['timestamp'].diff()\n",
    "print(f\"\\nAverage measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefae5d-c276-4c47-bb73-01a6eedbb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(time_diffs.mean() / 1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575b047-3ca2-4671-88d5-29558e332783",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_1['timestamp'].diff()\n",
    "squats_df_2_init_time = squats_df_1['time'].iloc[-1] + round(time_diffs.mean() / 1000, 3)\n",
    "print(f'initial_time for squats_df_2 = {squats_df_2_init_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67be9d2-f948-42c1-86f5-62ba7a5e739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_2 = add_time_column(df=squats_df_2, timestamp_col_name='timestamp', initial_time=squats_df_2_init_time, timecol_position=2)\n",
    "squats_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06318acc-0980-4c70-906f-e5070ea71a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_2['datetime'].iloc[-1] - squats_df_2['datetime'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb769f8-8be5-45c3-9286-892478e8085b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### squats_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba89d5-a78b-459f-baab-422a89d5462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_3 = pd.read_csv('data/40_Hz/original_data/train/Squats/3_HIMU-2023-08-19_20-35-09.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f603f83-4214-4f04-8100-b369d0c69cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554efb90-4edc-42bf-a2e3-c35fc2229955",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_3 = add_datetime_column(df=squats_df_3, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2caa5ff-c02c-46ba-a147-af3f2a8b97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_2['timestamp'].diff()\n",
    "squats_df_3_init_time = squats_df_2['time'].iloc[-1] + round(time_diffs.mean() / 1000, 3)\n",
    "print(f\"squats_df_2[-1:]['time'] = {squats_df_2[-1:]['time'].values}\")\n",
    "print(f'initial_time for squats_df_3 = {squats_df_3_init_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c68ac-6a25-45ea-b646-e222b914911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_3 = add_time_column(df=squats_df_3, timestamp_col_name='timestamp', initial_time=squats_df_3_init_time, timecol_position=2)\n",
    "squats_df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd438c5-910d-49cf-a231-7617931b0bec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### squats_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc0396-549f-435b-a779-4d4643492ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_4 = pd.read_csv('data/40_Hz/original_data/train/Squats/4_HIMU-2023-08-20_12-13-25.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52a709-66f8-4b55-ae54-b4ba34d04f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebbca5-5899-4c0c-b3b2-8c24f033e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_4 = add_datetime_column(df=squats_df_4, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6442da-4b82-48a1-8c98-095be473222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_3['timestamp'].diff()\n",
    "squats_df_4_init_time = squats_df_3['time'].iloc[-1] + round(time_diffs.mean() / 1000, 3)\n",
    "print(f\"squats_df_3[-1:]['time'] = {squats_df_3[-1:]['time'].values}\")\n",
    "print(f'initial_time for squats_df_4 = {squats_df_4_init_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee0ac7-8de2-40a9-83e6-d247d0c8446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_4 = add_time_column(df=squats_df_4, timestamp_col_name='timestamp', initial_time=squats_df_4_init_time, timecol_position=2)\n",
    "squats_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0f07b-fc71-4606-8427-22d38ebdf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_4[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556f51a-c4c3-4eda-9cb9-e12c8df63575",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### squats_df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4dae13-3d78-4b78-8228-a271203a3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "squats_df_5 = pd.read_csv('data/40_Hz/original_data/train/Squats/5_HIMU-2023-08-20_12-27-08.csv', names=columns, skiprows=4)\n",
    "\n",
    "squats_df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27476c7-97de-434a-86e8-a18c837d2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7e1d9-8946-47aa-b132-b7dca99ed62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_5 = add_datetime_column(df=squats_df_5, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "squats_df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fc6e1-d9ba-4711-9309-82b273b35976",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = squats_df_4['timestamp'].diff()\n",
    "squats_df_5_init_time = squats_df_4['time'].iloc[-1] + round(time_diffs.mean() / 1000, 3)\n",
    "print(f\"squats_df_4[-1:]['time'] = {squats_df_4[-1:]['time'].values}\")\n",
    "print(f'initial_time for squats_df_5 = {squats_df_5_init_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca0a29-dffb-40ea-a6ab-6a8eea445026",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_5 = add_time_column(df=squats_df_5, timestamp_col_name='timestamp', initial_time=squats_df_5_init_time, timecol_position=2)\n",
    "squats_df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9555be-b30a-4822-9fb4-e35656ca93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df_5[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b861793-cac2-4c41-bf8b-d0c0e254e421",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Concatenate squats_df-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e196c-5af3-4cd9-8b2d-8e9d23abf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df = pd.concat([squats_df_1, squats_df_2, squats_df_3, squats_df_4, squats_df_5])\n",
    "squats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c9712-a592-4ca0-92e5-9b56d843ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df.reset_index(inplace=True)\n",
    "squats_df.drop('index', axis=1, inplace=True)\n",
    "squats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949e5e0-29d2-4818-a3d8-1657f0f13d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e211ed-6088-42a4-aa51-fb526b53d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53eb4b-bcff-4f89-a366-a7819365e7f5",
   "metadata": {},
   "source": [
    "#### Visualise accelerometer and gyroscope behaviour (Raw data) for squats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47265f3c-b624-49bb-86e6-a97b8ed032c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=squats_df, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2', filename='graphs/squats_acc')\n",
    "display_three_axes(df=squats_df, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c856718-bec0-47bb-878a-d0f8cccdf91c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save a squats_df dataframe to a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec3e87-02aa-4126-8e3b-9e1d890d7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "squats_df.to_csv('data/40_Hz/concatenated_data/Squats/Squats_1_2023-08-21.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51dc7e-bc55-4f4d-b4ac-b5ed2f732c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Compare the original and saved dataframes to verify that squats_df is saved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36a5e4e6-4422-4547-b320-8fd819db7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1692440406933</td>\n",
       "      <td>2023-08-19 13:20:06.933</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.14895</td>\n",
       "      <td>-0.06000</td>\n",
       "      <td>9.775050</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-1.117325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1692440406976</td>\n",
       "      <td>2023-08-19 13:20:06.976</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.05400</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>9.748950</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>-0.163075</td>\n",
       "      <td>-1.241488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1692440407003</td>\n",
       "      <td>2023-08-19 13:20:07.003</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.23295</td>\n",
       "      <td>-0.12405</td>\n",
       "      <td>9.739051</td>\n",
       "      <td>0.096937</td>\n",
       "      <td>-0.311437</td>\n",
       "      <td>-1.159812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692440407037</td>\n",
       "      <td>2023-08-19 13:20:07.037</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.18495</td>\n",
       "      <td>-0.01200</td>\n",
       "      <td>9.691051</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>-0.309375</td>\n",
       "      <td>-0.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1692440407057</td>\n",
       "      <td>2023-08-19 13:20:07.057</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.46305</td>\n",
       "      <td>0.13605</td>\n",
       "      <td>10.146001</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.771787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                 datetime   time     accX     accY       accZ  \\\n",
       "0  1692440406933  2023-08-19 13:20:06.933  0.000  0.14895 -0.06000   9.775050   \n",
       "1  1692440406976  2023-08-19 13:20:06.976  0.043 -0.05400  0.04200   9.748950   \n",
       "2  1692440407003  2023-08-19 13:20:07.003  0.070  0.23295 -0.12405   9.739051   \n",
       "3  1692440407037  2023-08-19 13:20:07.037  0.104 -0.18495 -0.01200   9.691051   \n",
       "4  1692440407057  2023-08-19 13:20:07.057  0.124 -0.46305  0.13605  10.146001   \n",
       "\n",
       "       gyrX      gyrY      gyrZ  \n",
       "0  0.106150 -0.018975 -1.117325  \n",
       "1  0.110550 -0.163075 -1.241488  \n",
       "2  0.096937 -0.311437 -1.159812  \n",
       "3  0.079475 -0.309375 -0.900900  \n",
       "4  0.065037 -0.293013 -0.771787  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_squats_df = pd.read_csv('data/40_Hz/concatenated_data/Squats/Squats_1_2023-08-21.csv')\n",
    "test_squats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c0d2c685-7da3-4a54-a05e-904b95a90156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1692440406933</td>\n",
       "      <td>2023-08-19 13:20:06.933</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.14895</td>\n",
       "      <td>-0.06000</td>\n",
       "      <td>9.775050</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-1.117325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1692440406976</td>\n",
       "      <td>2023-08-19 13:20:06.976</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.05400</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>9.748950</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>-0.163075</td>\n",
       "      <td>-1.241488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1692440407003</td>\n",
       "      <td>2023-08-19 13:20:07.003</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.23295</td>\n",
       "      <td>-0.12405</td>\n",
       "      <td>9.739051</td>\n",
       "      <td>0.096937</td>\n",
       "      <td>-0.311437</td>\n",
       "      <td>-1.159812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692440407037</td>\n",
       "      <td>2023-08-19 13:20:07.037</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.18495</td>\n",
       "      <td>-0.01200</td>\n",
       "      <td>9.691051</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>-0.309375</td>\n",
       "      <td>-0.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1692440407057</td>\n",
       "      <td>2023-08-19 13:20:07.057</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.46305</td>\n",
       "      <td>0.13605</td>\n",
       "      <td>10.146001</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.771787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                datetime   time     accX     accY       accZ  \\\n",
       "0  1692440406933 2023-08-19 13:20:06.933  0.000  0.14895 -0.06000   9.775050   \n",
       "1  1692440406976 2023-08-19 13:20:06.976  0.043 -0.05400  0.04200   9.748950   \n",
       "2  1692440407003 2023-08-19 13:20:07.003  0.070  0.23295 -0.12405   9.739051   \n",
       "3  1692440407037 2023-08-19 13:20:07.037  0.104 -0.18495 -0.01200   9.691051   \n",
       "4  1692440407057 2023-08-19 13:20:07.057  0.124 -0.46305  0.13605  10.146001   \n",
       "\n",
       "       gyrX      gyrY      gyrZ  \n",
       "0  0.106150 -0.018975 -1.117325  \n",
       "1  0.110550 -0.163075 -1.241488  \n",
       "2  0.096937 -0.311437 -1.159812  \n",
       "3  0.079475 -0.309375 -0.900900  \n",
       "4  0.065037 -0.293013 -0.771787  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "556e743f-bfcb-44b5-8c00-7193dcd9431c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>1692523705154</td>\n",
       "      <td>2023-08-20 12:28:25.154</td>\n",
       "      <td>390.071</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>-0.45000</td>\n",
       "      <td>9.916051</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>0.255887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>1692523705183</td>\n",
       "      <td>2023-08-20 12:28:25.183</td>\n",
       "      <td>390.100</td>\n",
       "      <td>0.07905</td>\n",
       "      <td>-0.24405</td>\n",
       "      <td>8.746051</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.234437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>1692523705212</td>\n",
       "      <td>2023-08-20 12:28:25.212</td>\n",
       "      <td>390.129</td>\n",
       "      <td>-0.08505</td>\n",
       "      <td>-0.58605</td>\n",
       "      <td>11.074950</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-0.015125</td>\n",
       "      <td>0.174212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>1692523705234</td>\n",
       "      <td>2023-08-20 12:28:25.234</td>\n",
       "      <td>390.151</td>\n",
       "      <td>-0.45600</td>\n",
       "      <td>-0.16995</td>\n",
       "      <td>10.074000</td>\n",
       "      <td>-0.023238</td>\n",
       "      <td>-0.020213</td>\n",
       "      <td>0.193875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>1692523705259</td>\n",
       "      <td>2023-08-20 12:28:25.259</td>\n",
       "      <td>390.176</td>\n",
       "      <td>0.12195</td>\n",
       "      <td>-0.47400</td>\n",
       "      <td>9.199950</td>\n",
       "      <td>-0.031762</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.234025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp                datetime     time     accX     accY  \\\n",
       "13295  1692523705154 2023-08-20 12:28:25.154  390.071  0.06000 -0.45000   \n",
       "13296  1692523705183 2023-08-20 12:28:25.183  390.100  0.07905 -0.24405   \n",
       "13297  1692523705212 2023-08-20 12:28:25.212  390.129 -0.08505 -0.58605   \n",
       "13298  1692523705234 2023-08-20 12:28:25.234  390.151 -0.45600 -0.16995   \n",
       "13299  1692523705259 2023-08-20 12:28:25.259  390.176  0.12195 -0.47400   \n",
       "\n",
       "            accZ      gyrX      gyrY      gyrZ  \n",
       "13295   9.916051  0.009900  0.009075  0.255887  \n",
       "13296   8.746051  0.010037  0.004262  0.234437  \n",
       "13297  11.074950 -0.008800 -0.015125  0.174212  \n",
       "13298  10.074000 -0.023238 -0.020213  0.193875  \n",
       "13299   9.199950 -0.031762 -0.011000  0.234025  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squats_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d469f312-0374-4322-9f6d-b758d5391c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time</th>\n",
       "      <th>accX</th>\n",
       "      <th>accY</th>\n",
       "      <th>accZ</th>\n",
       "      <th>gyrX</th>\n",
       "      <th>gyrY</th>\n",
       "      <th>gyrZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>1692523705154</td>\n",
       "      <td>2023-08-20 12:28:25.154</td>\n",
       "      <td>390.071</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>-0.45000</td>\n",
       "      <td>9.916051</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>0.255887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>1692523705183</td>\n",
       "      <td>2023-08-20 12:28:25.183</td>\n",
       "      <td>390.100</td>\n",
       "      <td>0.07905</td>\n",
       "      <td>-0.24405</td>\n",
       "      <td>8.746051</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.234437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>1692523705212</td>\n",
       "      <td>2023-08-20 12:28:25.212</td>\n",
       "      <td>390.129</td>\n",
       "      <td>-0.08505</td>\n",
       "      <td>-0.58605</td>\n",
       "      <td>11.074950</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-0.015125</td>\n",
       "      <td>0.174212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>1692523705234</td>\n",
       "      <td>2023-08-20 12:28:25.234</td>\n",
       "      <td>390.151</td>\n",
       "      <td>-0.45600</td>\n",
       "      <td>-0.16995</td>\n",
       "      <td>10.074000</td>\n",
       "      <td>-0.023238</td>\n",
       "      <td>-0.020213</td>\n",
       "      <td>0.193875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>1692523705259</td>\n",
       "      <td>2023-08-20 12:28:25.259</td>\n",
       "      <td>390.176</td>\n",
       "      <td>0.12195</td>\n",
       "      <td>-0.47400</td>\n",
       "      <td>9.199950</td>\n",
       "      <td>-0.031762</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.234025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp                 datetime     time     accX     accY  \\\n",
       "13295  1692523705154  2023-08-20 12:28:25.154  390.071  0.06000 -0.45000   \n",
       "13296  1692523705183  2023-08-20 12:28:25.183  390.100  0.07905 -0.24405   \n",
       "13297  1692523705212  2023-08-20 12:28:25.212  390.129 -0.08505 -0.58605   \n",
       "13298  1692523705234  2023-08-20 12:28:25.234  390.151 -0.45600 -0.16995   \n",
       "13299  1692523705259  2023-08-20 12:28:25.259  390.176  0.12195 -0.47400   \n",
       "\n",
       "            accZ      gyrX      gyrY      gyrZ  \n",
       "13295   9.916051  0.009900  0.009075  0.255887  \n",
       "13296   8.746051  0.010037  0.004262  0.234437  \n",
       "13297  11.074950 -0.008800 -0.015125  0.174212  \n",
       "13298  10.074000 -0.023238 -0.020213  0.193875  \n",
       "13299   9.199950 -0.031762 -0.011000  0.234025  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_squats_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f462de1-5411-4984-ac2a-87955b1977c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(squats_df) = 13300\n",
      "len(test_squats_df) = 13300\n"
     ]
    }
   ],
   "source": [
    "print(f'len(squats_df) = {len(squats_df)}')\n",
    "print(f'len(test_squats_df) = {len(test_squats_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2101f34-e73e-486c-ad40-58dbafdb4328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squats_df.equals(test_squats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9aaf8da1-d095-48a3-b5d3-8c8b6b8909b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = (0, timestamp                 1692440406933\n",
      "datetime     2023-08-19 13:20:06.933000\n",
      "time                                0.0\n",
      "accX                            0.14895\n",
      "accY                              -0.06\n",
      "accZ                            9.77505\n",
      "gyrX                            0.10615\n",
      "gyrY                          -0.018975\n",
      "gyrZ                          -1.117325\n",
      "Name: 0, dtype: object)\n",
      "test_row = (0, timestamp              1692440406933\n",
      "datetime     2023-08-19 13:20:06.933\n",
      "time                             0.0\n",
      "accX                         0.14895\n",
      "accY                           -0.06\n",
      "accZ                         9.77505\n",
      "gyrX                         0.10615\n",
      "gyrY                       -0.018975\n",
      "gyrZ                       -1.117325\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "for row, test_row in zip(squats_df.iterrows(), test_squats_df.iterrows()):\n",
    "    print(f'row = {row}')\n",
    "    print(f'test_row = {test_row}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ea01d8d0-fed1-49e4-aa81-1da1d029ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squats_df.columns == test_squats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb5a30b1-b754-4a03-b8c8-451a53a5d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(squats_df.index == test_squats_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b989ded-ee06-461f-8dd0-3780f7bfdb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time         \n",
      "          self    other\n",
      "3055    90.311   90.311\n",
      "3057    90.367   90.367\n",
      "3058    90.397   90.397\n",
      "3062    90.513   90.513\n",
      "3067    90.659   90.659\n",
      "...        ...      ...\n",
      "13223  387.857  387.857\n",
      "13236  388.232  388.232\n",
      "13253  388.768  388.768\n",
      "13257  388.915  388.915\n",
      "13266  389.215  389.215\n",
      "\n",
      "[1344 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Compare the dataframes and get the differences\n",
    "differences = squats_df.compare(test_squats_df)\n",
    "\n",
    "# Print the differences\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c4d8c4b-b8ae-4a4c-b997-7d20d34c7249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squats_df['time'].iloc[3055] = 90.31099999999999\n",
      "test_squats_df['time'].iloc[3055] = 90.311\n"
     ]
    }
   ],
   "source": [
    "print(f\"squats_df['time'].iloc[3055] = {squats_df['time'].iloc[3055]}\")\n",
    "print(f\"test_squats_df['time'].iloc[3055] = {test_squats_df['time'].iloc[3055]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f283c-55a8-4d0b-821b-660dc3be30a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## leg_land_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6abf09-ff64-4551-8c13-a3ba5f9f58a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### leg_land_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bd55a-a957-48bc-b7c8-eb6e38106520",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "leg_land_df_1 = pd.read_csv('data/40_Hz/original_data/train/Leg_land/1_HIMU-2023-08-20_15-04-38.csv', names=columns, skiprows=4)\n",
    "\n",
    "leg_land_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91962846-319b-4486-98d5-4efcd5bd1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_land_df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8e261-b8a4-4e09-84d6-4eb50561405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_land_df_1 = add_datetime_column(df=leg_land_df_1, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "leg_land_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e56ac-5725-4074-a63a-fbebb260aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = leg_land_df_1['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed38b9-457f-4ae0-852a-7f24d595ca8e",
   "metadata": {},
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4bd8d-5e15-47b9-98a6-31b970170a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_land_df_1 = add_time_column(df=leg_land_df_1, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "leg_land_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c09042-551a-4d46-82ed-cce00e4df4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_land_df_1[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1d38b-5c23-4a6b-aca8-fce40432b82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbbb41-c968-4cbd-99a4-6a4e0c2ad480",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=leg_land_df_1, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=leg_land_df_1, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666a6ef-6a73-4a6a-88a0-c9f0d9a6e163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## walk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38953052-591c-41cf-96ea-84b78361dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "walk_df = pd.read_csv('data/40_Hz/original_data/train/Walk/1_HIMU-2023-08-19_20-25-23.csv', names=columns, skiprows=4)\n",
    "\n",
    "walk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24909aa8-92ff-4022-85a1-48ec53f803f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29267b-7890-4fa5-80e2-9f296419e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_df = add_datetime_column(df=walk_df, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "walk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b36649-411d-40f5-b832-dbc57eeab616",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = walk_df['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaff42f-4184-45f0-9ada-5c3c7bf56960",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9776ba-bf5f-47e0-b4b3-020b32a374e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_df = add_time_column(df=walk_df, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "walk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c699d99-c703-4dd3-93c1-69a28ae2d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_df[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0736e-3702-4bde-a0f1-c9b1188f93ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f25c3-4f7f-42ac-94ed-71a00c44a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=walk_df, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=walk_df, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe4e71-4e5f-4522-b71a-a5648a56b10c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## lateral_squat_slide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f137d-9757-4d81-b577-9263a30054b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### lateral_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a72223-f5cf-4d05-8063-b7c29a4c2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "lateral_df_1 = pd.read_csv('data/40_Hz/original_data/train/Lateral_squat_slide/1_HIMU-2023-08-21_08-10-01.csv', names=columns, skiprows=4)\n",
    "\n",
    "lateral_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c2c27-ac8e-4f31-9843-7dd3b75112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903acc0d-2895-427f-b601-a853ceb11d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_df_1 = add_datetime_column(df=lateral_df_1, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "lateral_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b23ae-bab6-475d-8d0f-4d17c4100c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = lateral_df_1['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5ac13-e3dc-49ef-a793-866e9ad89611",
   "metadata": {},
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb144d-afbe-45a0-a85b-b774094c0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_df_1 = add_time_column(df=lateral_df_1, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "lateral_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5271a9-b93f-4f42-9cac-214ca42e9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateral_df_1[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92c79b-5d51-4762-9e5d-d42ca2087bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250f3b8-9728-44a9-8e49-4bb407c8c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=lateral_df_1, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=lateral_df_1, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e2325-2f25-4b10-8da6-a0c965d83ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## jogging_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a19753-cf12-4516-9606-4dfd5623e8c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### jogging_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661bf64-ec8f-43fa-842e-54a24894336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "jogging_df_1 = pd.read_csv('data/40_Hz/original_data/train/Jogging/1_HIMU-2023-08-20_09-47-23.csv', names=columns, skiprows=4)\n",
    "\n",
    "jogging_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5a212-cd17-4482-be9f-19fa0301a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jogging_df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fafe305-1a8e-4aa8-a327-b2aaced29d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "jogging_df_1 = add_datetime_column(df=jogging_df_1, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "jogging_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611438d9-9f41-4abe-9cb4-ec1db259a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = jogging_df_1['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee6ce7-a213-479d-8811-429c9216d977",
   "metadata": {},
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b09c8f-7c83-4f60-9a39-2ed46bc0553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jogging_df_1 = add_time_column(df=jogging_df_1, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "jogging_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5f45b-608b-453c-9ae0-ad2e488e5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jogging_df_1[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90bf8c-c5dd-4f6c-96a4-55b755584cc9",
   "metadata": {},
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bfc50-d077-423d-8bf6-fa5294ed2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=jogging_df_1, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=jogging_df_1, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579b473-acec-41c6-8f0a-c5cd0cbe83a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a2c60-bfa8-46ca-9855-e5ded9d31054",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'accX', 'accY', 'accZ', 'gyrX', 'gyrY', 'gyrZ']\n",
    "test_df = pd.read_csv('data/40_Hz/original_data/test/Test1_HIMU-2023-08-20_09-31-52.csv', names=columns, skiprows=4)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94345834-da52-4618-a22e-6be35a83dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70c5ec-574f-41ad-979c-344d774bc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_datetime_column(df=test_df, timestamp_col_name='timestamp', local_timezone=local_timezone, reordering=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c5e5c-48f6-46cf-a09a-4dd2335b490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = test_df['timestamp'].diff()\n",
    "print(f\"Average measurement period = {time_diffs.mean()} ms\")\n",
    "print(f\"Average measurement frequency = {1000 / time_diffs.mean()} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae1b38-48fa-426e-8ccc-5ea22c16a6d3",
   "metadata": {},
   "source": [
    "#### 1) Add 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185cecd-f024-4d9a-a4dc-c90d57b2b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_time_column(df=test_df, timestamp_col_name='timestamp', initial_time=0, timecol_position=2)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dcc4d-45d3-472f-b77a-fedba3d3398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d62fae-5bf4-42d7-8267-6695a4dbaeac",
   "metadata": {},
   "source": [
    "#### 2) Visualise accelerometer and gyroscope behaviour (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581a01b-4c7e-4fa9-a589-e2e44cb49abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_three_axes(df=test_df, x='time', y=['accX', 'accY', 'accZ'], title='Accelerometer readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Linear acceleration, m/s^2')\n",
    "display_three_axes(df=test_df, x='time', y=['gyrX', 'gyrY', 'gyrZ'], title='Gyroscope readings (Raw Data)', \n",
    "                   x_label='Time, s', y_label='Angular velocity, rad/s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
