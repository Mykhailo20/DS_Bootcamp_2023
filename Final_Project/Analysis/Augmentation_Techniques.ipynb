{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34a777-bcef-43f7-8cfd-cd1692971d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4138515-875a-449e-a00b-3a8c6dd8a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'data/garbage_classification_6_classes/garbage_classification/'\n",
    "\n",
    "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
    "source_path_glass = os.path.join(source_path, 'glass')\n",
    "source_path_metal = os.path.join(source_path, 'metal')\n",
    "source_path_paper = os.path.join(source_path, 'paper')\n",
    "source_path_plastic = os.path.join(source_path, 'plastic')\n",
    "source_path_trash = os.path.join(source_path, 'trash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547b7eb-8a12-4645-916e-c4251c55240f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123489d-2258-4006-b28b-7e54ba76adee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be336f-186b-4b3a-be01-86cebb160072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img, title=None):\n",
    "    \"\"\" Function to display an image\n",
    "    Args:\n",
    "        1) img - image object\n",
    "        2) title - the title that will be displayed above the image\n",
    "    Returns:\n",
    "        None; but displays an image\n",
    "    \"\"\"\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ed0f4-7bd1-4bd1-b29b-9bf92fb24f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_original_augmented_img(original_img, augmented_img, original_title=None, augmented_title=None):\n",
    "    \"\"\" Function to display the original and augmented image on the same graph\n",
    "    Args:\n",
    "        1) original_img - object of the original image\n",
    "        2) augmented_img - augmented image object\n",
    "        3) original_title - title for the original image\n",
    "        4) augmented_title - title for the augmented image\n",
    "    Returns:\n",
    "        None; but displays images\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title(original_title)\n",
    "    \n",
    "    axes[1].imshow(augmented_img)\n",
    "    axes[1].set_title(augmented_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427a538-e1a4-49c8-a83c-eae07f147ed3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perform image augmentation using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12d692-f9d5-443a-8c17-73262215ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ImageDataGen_augmentation(imageDataGenerator, images, image_filenames, target_size, \n",
    "                                      augm_prefix, num_augm_images=3, augm_images_dir_path=None, \n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) imageDataGenerator - ImageDataGenerator class object\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    augmented_index = 0\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        x = img.copy()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            i += 1\n",
    "            if i > num_augmented_images:\n",
    "                augmented_index = 0\n",
    "                break \n",
    "            \n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "        \n",
    "            augmented_index += 1\n",
    "            \n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                # tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(batch[0].copy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=batch[0].copy().astype(np.uint8), \n",
    "                                               original_title=f\"Original_image: {image_name}\", \n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23b159-3e21-4735-b7ce-cc3f623bd97a",
   "metadata": {},
   "source": [
    "## Perform image augmentation using CV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ecc2e-b9e3-409b-9486-d6d12093cda1",
   "metadata": {},
   "source": [
    "### Augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3d1a4-1178-4c37-bc52-aa0421bb153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width_shift_image(image, width_shift_fraction):\n",
    "    \"\"\" Function for performing width_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) width_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    width_shift = int(height * width_shift_fraction)\n",
    "\n",
    "    # Calculate the new y-coordinate for height shift\n",
    "    y_shifted = height // 2 + width_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, 0], [0, 1, width_shift]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceab78a-a6d9-4155-ad75-9cf18108ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_height_shift_image(image, height_shift_fraction):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) height_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    height_shift = int(width * height_shift_fraction)\n",
    "\n",
    "    # Calculate the new x-coordinate for height shift\n",
    "    x_shifted = width // 2 + height_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, height_shift], [0, 1, 0]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2042f-4c26-47e4-af11-f5d562b0979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brightness_augmentation_image(image, brightness_range=(0.5, 1.5)):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Generate a random brightness factor within the specified range\n",
    "    brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "    \n",
    "    # Adjust the brightness by scaling the V channel\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)\n",
    "    \n",
    "    # Convert the image back to the original color space (BGR)\n",
    "    augmented_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d1adb-54fa-4b27-b288-71a3a8791eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contrast_augmentation_image(image, contrast_factor):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) contrast_factor - adjusts the contrast of the image by applying CLAHE; possible values: [1.0; 4.0]\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split the LAB image into L, A, and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=contrast_factor, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    \n",
    "    # Convert the LAB image back to BGR color space\n",
    "    contrast_augmented_image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return contrast_augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c458f-be73-4378-a528-3129353a7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsv_image(image, hue_shift, saturation_scale=1, value_scale=1):\n",
    "    \"\"\" Function to change the color tone of the image when switching to the HSV model\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) hue_shift - the value of the Hue parameter of the hsv model; possible values: [0; 179] (OpenCV)\n",
    "        3) saturation_scale - coefficient by which the Saturation parameter of the HSV model will be multiplied\n",
    "        4) value_scale - coefficient by which the Value parameter of the HSV model will be multiplied \n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the original image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the hue shift to the hue channel\n",
    "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
    "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_scale, 0, 255)\n",
    "    hsv_image[:, :, 2] = np.clip(hsv_image[:, :, 2] * value_scale, 0, 255)\n",
    "    \n",
    "    # Convert the image back to the RGB color space\n",
    "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b0f88-973f-40ed-b95a-12206761e5b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Augmentation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3cbb1-3416-482d-afcc-81585f3afd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv2_rotation_augmentation(rotation_range, images, image_filenames, \n",
    "                                      target_size, augm_prefix, \n",
    "                                      num_augm_images=3, augm_images_dir_path=None, \n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) rotation_range - the range (a list of two elements: [range_min; range_max]) in which the angle value will change linearly (depending on num_augm_images) \n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    height = target_size[0]\n",
    "    width = target_size[1]\n",
    "    angle_increment = int((rotation_range[1] - rotation_range[0]) / num_augm_images)\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        angle = rotation_range[0]\n",
    "        for i in range(num_augm_images):\n",
    "            # Calculate the rotation matrix\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "\n",
    "            # Apply the rotation to the image using warpAffine\n",
    "            augmented_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "            angle += angle_increment\n",
    "            if angle == 0:\n",
    "                angle += angle_increment\n",
    "                \n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image, \n",
    "                                               original_title=f\"Original_image: {image_name}\", \n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107375d-36ed-46e7-9287-3691ce47b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv2_flip_augmentation(flip_code, images, image_filenames, \n",
    "                                  target_size, augm_prefix, \n",
    "                                  num_augm_images=3, augm_images_dir_path=None, \n",
    "                                  save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) flip_code - the type of flip augmentation to perform on the image: 0 - vertical, 1 - horizontal \n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    \n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        for i in range(num_augm_images):\n",
    "            augmented_image = cv2.flip(img.copy(), flip_code)\n",
    "                    \n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "            \n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augm_images_dir_path, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image, \n",
    "                                               original_title=f\"Original_image: {image_name}\", \n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba5de9-36e2-4dbf-9cf2-4df4c033b4b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# View test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdd2b3-424e-445a-80dd-e672b2760578",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = [source_path_cardboard, source_path_glass, source_path_metal, source_path_paper, source_path_plastic, \n",
    "                   source_path_trash]\n",
    "image_filenames = ['cardboard148.jpg', 'glass93.jpg', 'metal69.jpg', 'paper104.jpg', 'plastic118.jpg',\n",
    "                  'trash28.jpg']\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "show_images = True\n",
    "images = []\n",
    "for image_filepath, image_filename in zip(image_filepaths, image_filenames):\n",
    "    img = cv2.imread(os.path.join(image_filepath, image_filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    \n",
    "    if show_images:\n",
    "        display_image(img, title=image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952b479-e1cc-4c1c-8b2f-1a2916d32fb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Perform image augmentation using ImageDataGenerator and cv2 algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f7b8d-d1f0-4a1c-afd3-ee7c87c84c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the image (height, width)\n",
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef744f-44ea-4010-935e-4d9e1d95e911",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de27a1e-30d2-4e83-a5d9-a9e3cfe8e787",
   "metadata": {},
   "source": [
    "### ImageDataGenerator -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643e9f6-f799-4604-b221-4607f6ccad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 3\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20be01e-3f48-4e67-b136-6f5121b95f40",
   "metadata": {},
   "source": [
    "### CV2 algorithm +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489928eb-43c7-48b0-b033-5cef19da70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (img_height, img_width)\n",
    "perform_cv2_rotation_augmentation(rotation_range=[-30, 30], images=images, \n",
    "                                  image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=6, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10481a0-5339-41ec-8687-71728a10b5b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## width_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e23c3f-3703-43f4-aaec-9a9de0a0349a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ImageDataGenerator -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498c7c4-ae8a-44ad-921f-dae2af76e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=(0.1, 0.1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 3\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_wShift', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f850c2c-4943-424a-8967-bc1fa09b2ed9",
   "metadata": {},
   "source": [
    "### CV2 algorithm +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67523d6-7194-4e42-b78f-aeaa23f872b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shift_fraction = 0.1\n",
    "for image, image_name in zip(images, image_filenames):\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
    "    \n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image,\n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"wShifted_img: {image_name}\")\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image,\n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"wShifted_img: {image_name}\")\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0a61a-71ed-49ac-810d-ba3d1e0506c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## height_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83ba2f-c49d-4d79-8a12-85886258c200",
   "metadata": {},
   "source": [
    "### ImageDataGenerator -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013312c-3f37-4704-b745-15f7906b8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_hShift', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5434-1087-4cc4-a783-657f2aba2a82",
   "metadata": {},
   "source": [
    "### CV2 algorithm +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9405ac-d695-436e-9e5e-bb43c7bea089",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_shift_fraction = 0.15\n",
    "for image, image_name in zip(images, image_filenames):\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
    "    \n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image,\n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"hShifted_img: {image_name}\")\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image,\n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"hShifted_img: {image_name}\")\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbba54-23d8-4637-9763-59daff2c9194",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## horizontal_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1094721-06df-42c1-8e68-ea1cf760b788",
   "metadata": {},
   "source": [
    "### ImageDataGenerator -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141b7f9-1a21-4b09-a518-430fde6a9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_hFlip', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=False, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14ea24-2bb8-4273-887e-ce8ef7d09d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, image_filename in zip(images, image_filenames):\n",
    "    display_image(img, title=image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652d280-209e-4479-86ea-ee05bf5f212c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CV2 algorithm +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31dfdec-5a06-47f9-abba-2c63af53d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_augmented_images = 1\n",
    "perform_cv2_flip_augmentation(flip_code=1, images=images, image_filenames=image_filenames, \n",
    "                              augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                              augm_prefix='aug_hFlip', num_augm_images=num_augmented_images, \n",
    "                              save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67f89b-fe98-4def-a2c6-3389a2f48da0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## vertical_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb8a0b-d120-4cbe-badd-8d611f41ba14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ImageDataGenerator -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a64c3a-43c9-455a-a18a-161759d07300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    vertical_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_vFlip', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8888-5665-4401-952a-4eb26bdecab0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CV2 algorithm +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e6b90-7003-483e-af0c-727effd01e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_augmented_images = 1\n",
    "perform_cv2_flip_augmentation(flip_code=0, images=images, image_filenames=image_filenames, \n",
    "                              augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                              augm_prefix='aug_vFlip', num_augm_images=num_augmented_images, \n",
    "                              save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bcc61-a762-40ae-bf6b-ad4bd411680e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## zoom = scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece650d-88f7-427b-bfe6-017d1127e89e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6adf7-ee37-40a7-94f3-ab08ea6602e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(0.8, 1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_iZoom', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cf18e-1738-47a7-97ca-5f57088d0211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887e75c-8b9a-46a4-aebd-aefbeb2960fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1, 1.2),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_dZoom', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181eebff-e10b-4d0d-9002-bf998cd09c92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## brightness_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af57ab-bdad-4ecf-90d6-bf9254371713",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8926c02-bb22-4335-a820-89507c58cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 0.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_blackBrightness', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751885e-fc1d-45f1-92bc-454e01aee87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames, \n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size, \n",
    "                                  augm_prefix='aug_ligthBrightness', num_augm_images=num_augmented_images, \n",
    "                                  save_augm_image=True, display_orig_augm_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8ebf5-70d0-4104-a19b-f67128954911",
   "metadata": {},
   "source": [
    "### CV2 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2e8e2-aa4f-4112-8df0-4d87de15de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "augm_prefix = 'aug_blackBrightness'\n",
    "for img, image_name in zip(images, image_filenames):\n",
    "    changed_image = apply_brightness_augmentation(image=img, brightness_range=(0.5, 0.5))\n",
    "    augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_0.jpg\"\n",
    "    cv2.imwrite(os.path.join(augmented_images_dir, augmented_image_name), cv2.cvtColor(changed_image, cv2.COLOR_BGR2RGB))\n",
    "    display_original_augmented_img(original_img=img, augmented_img=changed_image, \n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"Brightness_img: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36c3a6-19ef-404b-951b-63382a19f363",
   "metadata": {
    "tags": []
   },
   "source": [
    "## contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50510829-0892-4150-a4e7-a7e952e91a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "augm_prefix = 'aug_Contrast'\n",
    "for image, image_name in zip(images, image_filenames):\n",
    "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=2.0)\n",
    "    augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_0.jpg\"\n",
    "    cv2.imwrite(os.path.join(augmented_images_dir, augmented_image_name), cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image, \n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"Brightness_img: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955d10-89ca-423a-92df-aac5e4f2b670",
   "metadata": {
    "tags": []
   },
   "source": [
    "## backgrounds augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97148f97-c3f1-40d5-99ea-2857206387db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = [source_path_cardboard, source_path_glass, source_path_metal, source_path_paper, source_path_plastic, \n",
    "                   source_path_trash]\n",
    "image_filenames = ['cardboard148.jpg', 'glass93.jpg', 'metal69.jpg', 'paper104.jpg', 'plastic118.jpg',\n",
    "                  'trash28.jpg']\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "garbage_img = cv2.imread(os.path.join(image_filepaths[0], image_filenames[0]))\n",
    "garbage_img = cv2.cvtColor(garbage_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "display_image(img=garbage_img, title=image_filenames[0]) \n",
    "\n",
    "# Get the size of the garbage image (height, width)\n",
    "garbage_img_height, garbage_img_width = garbage_img.shape[:2]\n",
    "print(f\"garbage_img_height = {garbage_img_height}, garbage_img_width = {garbage_img_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5252c-9d7d-414e-8a84-cb8f0c644da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_image_filepath = 'data/backgrounds/'\n",
    "background_image_names = os.listdir(background_image_filepath+'original/')\n",
    "background_images = []\n",
    "show_images = True\n",
    "\n",
    "for background_image_name in background_image_names:\n",
    "    background_image = cv2.imread(os.path.join(background_image_filepath+'original/', background_image_name))\n",
    "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
    "    background_image = cv2.resize(background_image, (garbage_img_width, garbage_img_height))\n",
    "    background_images.append(background_image)\n",
    "    \n",
    "    resized_image_name = f\"{background_image_name.split('.')[0]}_reized.jpg\"\n",
    "    cv2.imwrite(os.path.join(background_image_filepath+'resized/', resized_image_name), \n",
    "                cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB))\n",
    "    if show_images:\n",
    "        display_image(background_image, title=background_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee430748-8e4b-449a-825c-cd93f2789d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585842ba-f63d-4a54-ab31-f0b90e5235d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage_image = images[3]\n",
    "background_image = background_images[0]\n",
    "\n",
    "# Adjust the transparency (alpha channel) of the garbage image\n",
    "alpha = 0.9  # Adjust this value between 0 (completely transparent) and 1 (completely opaque)\n",
    "garbage_image = cv2.addWeighted(garbage_image, alpha, np.zeros_like(garbage_image), 1 - alpha, 0)\n",
    "\n",
    "background_alpha = 0  # Adjust this value between 0 (completely transparent) and 1 (completely opaque)\n",
    "background_image = cv2.addWeighted(background_image, alpha, np.zeros_like(background_image), 1 - background_alpha, 0)\n",
    "\n",
    "# Overlay the resized garbage image onto the resized background image\n",
    "augmented_image = cv2.addWeighted(background_image, 1, garbage_image, 1, 0)\n",
    "\n",
    "display_image(augmented_image, title=background_image_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6fb75d-1aa2-4145-b71c-9f26a392f9d4",
   "metadata": {},
   "source": [
    "## color space transformations (HSV) augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57404f0-03ce-42fa-b01d-483e637976b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "augm_prefix = 'aug_hsv'\n",
    "for image, image_name in zip(images, image_filenames):\n",
    "    augmented_image = get_hsv_image(image=image, hue_shift=180)\n",
    "    augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_0.jpg\"\n",
    "    cv2.imwrite(os.path.join(augmented_images_dir, augmented_image_name), cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "    display_original_augmented_img(original_img=image, augmented_img=augmented_image, \n",
    "                                   original_title=f\"Original_img: {image_name}\",\n",
    "                                   augmented_title=f\"HSV_img: {image_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
