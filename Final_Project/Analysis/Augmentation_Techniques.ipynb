{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a34a777-bcef-43f7-8cfd-cd1692971d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4138515-875a-449e-a00b-3a8c6dd8a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'data/garbage_classification_6_classes/garbage_classification/'\n",
    "\n",
    "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
    "source_path_glass = os.path.join(source_path, 'glass')\n",
    "source_path_metal = os.path.join(source_path, 'metal')\n",
    "source_path_paper = os.path.join(source_path, 'paper')\n",
    "source_path_plastic = os.path.join(source_path, 'plastic')\n",
    "source_path_trash = os.path.join(source_path, 'trash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba5de9-36e2-4dbf-9cf2-4df4c033b4b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### View test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdd2b3-424e-445a-80dd-e672b2760578",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = [source_path_cardboard, source_path_glass, source_path_metal, source_path_paper, source_path_plastic, \n",
    "                   source_path_trash]\n",
    "image_filenames = ['cardboard148.jpg', 'glass93.jpg', 'metal69.jpg', 'paper104.jpg', 'plastic118.jpg',\n",
    "                  'trash28.jpg']\n",
    "\n",
    "images = []\n",
    "for image_filepath, image_filename in zip(image_filepaths, image_filenames):\n",
    "    img = cv2.imread(os.path.join(image_filepath, image_filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(image_filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9ba80-d10b-4159-83f8-ee17d5115286",
   "metadata": {},
   "source": [
    "### Do Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde846a5-fcd6-4816-ae84-246be11710ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_height = 384, img_width = 512\n"
     ]
    }
   ],
   "source": [
    "# Get the size of the image (height, width)\n",
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc07ee46-b40f-4e21-8470-7ba05692f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_images_dir = 'data/garbage_classification_6_classes/garbage_classification_augmentation_test/'\n",
    "\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 5\n",
    "\n",
    "augmented_index = 0\n",
    "augmented_image_names = []\n",
    "\n",
    "for (image_name, img) in zip(image_filenames, images):\n",
    "    x = img.copy()\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Generate augmented images\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1):\n",
    "    # for batch in datagen.flow(x, batch_size=1, save_to_dir=augmented_images_dir, save_prefix='aug', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > num_augmented_images:\n",
    "            augmented_index = 0\n",
    "            break  # Break the loop after generating the desired number of augmented images\n",
    "            \n",
    "        # Create unique name for the augmented image (aug_originalfilename_index.jpg)\n",
    "        augmented_image_name = f\"aug_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "        # Increment the index for the next augmented image\n",
    "        augmented_index += 1\n",
    "        # Save the augmented image with the unique name\n",
    "        augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "        augmented_image_names.append(augmented_image_path)\n",
    "        # Save the augmented image\n",
    "        tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
    "\n",
    "# Print the names of augmented images\n",
    "# print(augmented_image_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
