{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b",
   "metadata": {
    "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b"
   },
   "source": [
    "### Link to the dataset: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RKCaaWRKQye8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "RKCaaWRKQye8",
    "outputId": "1c150c81-6ccc-4184-93a2-a012d27c460f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ecf3715e-01a3-4aa0-9bd8-027581f8dd76\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ecf3715e-01a3-4aa0-9bd8-027581f8dd76\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload the Kaggle API key file (kaggle.json) that you downloaded from Kaggle\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move the uploaded API key to the required directory\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143vln3rRExD",
   "metadata": {
    "id": "143vln3rRExD"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "CRRvWPlURJXy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRRvWPlURJXy",
    "outputId": "91ac760d-088c-48f2-bb26-be19093205e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading garbage-classification.zip to /content\n",
      " 98% 80.0M/82.0M [00:00<00:00, 142MB/s]\n",
      "100% 82.0M/82.0M [00:00<00:00, 136MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d asdasdasasdas/garbage-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qFh2FFk3RQID",
   "metadata": {
    "id": "qFh2FFk3RQID"
   },
   "outputs": [],
   "source": [
    "!unzip garbage-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qW8DMdNSxlEF",
   "metadata": {
    "id": "qW8DMdNSxlEF"
   },
   "outputs": [],
   "source": [
    "!pip install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c",
   "metadata": {
    "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fa0e8-6098-41f8-9901-09e18d152bce",
   "metadata": {
    "id": "a19fa0e8-6098-41f8-9901-09e18d152bce"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
   "metadata": {
    "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47"
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979887c5-9518-4f9b-860a-9f6e586085fd",
   "metadata": {
    "id": "979887c5-9518-4f9b-860a-9f6e586085fd"
   },
   "outputs": [],
   "source": [
    "def create_train_valid_test_dirs(root_path, subdir_names, train_valid_test_names=['train', 'valid', 'test']):\n",
    "    \"\"\" Function for creating separate folders that contain data for training, validation and testing of the model\n",
    "    Args:\n",
    "        1) root_path - the path to the parent folder in which you want to create subfolders\n",
    "        2) subdir_names - a list of label class names (subfolders with the specified names will be created in each of the train, valid, and test folders)\n",
    "        3) train_valid_test_names - a list of names of training, validation and test samples\n",
    "    Returns:\n",
    "        None; but creates folders\n",
    "    \"\"\"\n",
    "    parent_directories = []\n",
    "    for dir_name in train_valid_test_names:\n",
    "        parent_directories.append(os.path.join(root_path, dir_name))\n",
    "\n",
    "    for directory in parent_directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for subdirectory in subdir_names:\n",
    "            subdir_name = os.path.join(directory + '/', subdirectory)\n",
    "            if not os.path.exists(subdir_name):\n",
    "                os.makedirs(subdir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d",
   "metadata": {
    "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d"
   },
   "outputs": [],
   "source": [
    "def split_data(source_dir_path, train_dir_path, valid_dir_path, test_dir_path, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
    "    \"\"\" Function to split the files of the specified folder into training, validation and test samples by copying\n",
    "    the files from source_dir_path to the corresponding folders\n",
    "    Args:\n",
    "        1) source_dir_path - the path to the folder containing the original data to be split into train/valid/test\n",
    "        2) train_dir_path - the path to the folder that will contain the training data\n",
    "        3) valid_dir_path - the path to the folder that will contain the validation data\n",
    "        4) test_dir_path - the path to the folder that will contain the test data\n",
    "        5) train_test_split - the ratio between training and test samples ([0; 1])\n",
    "        6) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
    "        7) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
    "    Returns:\n",
    "        None, but split the files into training, validation and test samples\n",
    "    \"\"\"\n",
    "    fnames = os.listdir(source_dir_path)\n",
    "\n",
    "    processed_fnames = []\n",
    "    for file_name in fnames:\n",
    "        if os.path.getsize(os.path.join(source_dir_path, file_name)) > 0:\n",
    "            processed_fnames.append(file_name)\n",
    "        else:\n",
    "            print(f'{file_name} is zero length, so ignoring.')\n",
    "\n",
    "    if random_sample:\n",
    "        processed_fnames = random.sample(processed_fnames, len(processed_fnames))\n",
    "\n",
    "    split_index = int(train_test_split * len(processed_fnames))\n",
    "    train_valid_files = processed_fnames[:split_index]\n",
    "    test_files = processed_fnames[split_index:]\n",
    "\n",
    "    split_index = int(train_valid_split * len(train_valid_files))\n",
    "    train_files = train_valid_files[:split_index]\n",
    "    valid_files = train_valid_files[split_index:]\n",
    "\n",
    "    # Copy training files\n",
    "    for file in train_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(train_dir_path, file)\n",
    "        copyfile(source, destination)\n",
    "\n",
    "    # Copy validation files\n",
    "    for file in valid_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(valid_dir_path, file)\n",
    "        copyfile(source, destination)\n",
    "\n",
    "    # Copy test files\n",
    "    for file in test_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(test_dir_path, file)\n",
    "        copyfile(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da75baf0-c207-4220-bcb3-2f936d00049d",
   "metadata": {
    "id": "da75baf0-c207-4220-bcb3-2f936d00049d"
   },
   "outputs": [],
   "source": [
    "def split_class_data(source_dir_path, train_valid_test_paths, class_dir_name, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
    "    \"\"\" Function for dividing the data of one label class into train/valid/test\n",
    "    Args:\n",
    "        1) source_dir_path - the path to the folder containing the original data of all label classes which needs to be splitted into train/valid/test;\n",
    "        2) train_valid_test_paths - the list of paths to the folders of training, validation and test samples\n",
    "        (the paths are specified in this order: train, valid, test)\n",
    "        3) class_dir_name - the name of the folder that contains the label class data\n",
    "        4) train_test_split - the ratio between training and test samples ([0; 1])\n",
    "        5) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
    "        6) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
    "    Returns:\n",
    "        None, but split the files of label class into training, validation and test samples\n",
    "    \"\"\"\n",
    "    train_dir_path_class = os.path.join(train_valid_test_paths[0], class_dir_name)\n",
    "    valid_dir_path_class = os.path.join(train_valid_test_paths[1], class_dir_name)\n",
    "    test_dir_path_class = os.path.join(train_valid_test_paths[2], class_dir_name)\n",
    "    source_dir_path_class = os.path.join(source_dir_path, class_dir_name)\n",
    "    split_data(source_dir_path=source_dir_path_class, train_dir_path=train_dir_path_class, valid_dir_path=valid_dir_path_class,\n",
    "               test_dir_path=test_dir_path_class,\n",
    "               train_test_split=train_test_split, train_valid_split=train_valid_split, random_sample=random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QtwmTbl9PK5u",
   "metadata": {
    "id": "QtwmTbl9PK5u"
   },
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uDa_N5C5PKbQ",
   "metadata": {
    "id": "uDa_N5C5PKbQ"
   },
   "outputs": [],
   "source": [
    "def display_image(img, title=None):\n",
    "    \"\"\" Function to display an image\n",
    "    Args:\n",
    "        1) img - image object\n",
    "        2) title - the title that will be displayed above the image\n",
    "    Returns:\n",
    "        None; but displays an image\n",
    "    \"\"\"\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GnJCHNEDPWLG",
   "metadata": {
    "id": "GnJCHNEDPWLG"
   },
   "outputs": [],
   "source": [
    "def display_original_augmented_img(original_img, augmented_img, original_title=None, augmented_title=None):\n",
    "    \"\"\" Function to display the original and augmented image on the same graph\n",
    "    Args:\n",
    "        1) original_img - object of the original image\n",
    "        2) augmented_img - augmented image object\n",
    "        3) original_title - title for the original image\n",
    "        4) augmented_title - title for the augmented image\n",
    "    Returns:\n",
    "        None; but displays images\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title(original_title)\n",
    "\n",
    "    axes[1].imshow(augmented_img)\n",
    "    axes[1].set_title(augmented_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87ed02-b353-41ff-a831-495238d0361b",
   "metadata": {
    "id": "ff87ed02-b353-41ff-a831-495238d0361b",
    "tags": []
   },
   "source": [
    "## Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "_cc_OjlNRHcM",
   "metadata": {
    "id": "_cc_OjlNRHcM"
   },
   "outputs": [],
   "source": [
    "def load_display_image(root_path, image_name, title=None):\n",
    "    \"\"\" Function to display an image\n",
    "    Args:\n",
    "        1) root_path - the path to the folder that contains the image\n",
    "        2) image_name - the name of the image\n",
    "        3) title - the title that will be displayed above the image\n",
    "    Returns:\n",
    "        None; but displays an image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(os.path.join(root_path, image_name))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4",
   "metadata": {
    "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4"
   },
   "outputs": [],
   "source": [
    "def display_pie_chart(df, column_name, title=None, column_contains_count=False, filename=None):\n",
    "    \"\"\" Function to display the percentage ratio of column (with the name column_name) content\n",
    "    Args:\n",
    "        1) df - the original dataframe that contains the required information\n",
    "        2) column_name - the name of the df dataframe column whose percentage values are to be found\n",
    "        3) title - the title of the graph\n",
    "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
    "        5) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        None, but plots graph\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of each activity in original_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_df = df[column_name] / sum(df[column_name])\n",
    "    else:\n",
    "        activity_percentages_df = df[column_name].value_counts(normalize=True) * 100\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot pie chart for df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    plt.pie(activity_percentages_df, labels=activity_percentages_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_pie_charts(first_df, second_df, column, column_contains_count=False, first_chart_title='First DataFrame', second_chart_title='Second DataFrame', filename=None):\n",
    "    \"\"\"Function for displaying the ratio of column content between two dataframes in the form of pie charts\n",
    "    Args:\n",
    "        1) first_df - the original dataframe that contains the required information\n",
    "        2) second_df - a dataframe that contains the results of windowing\n",
    "        3) column - the name of the dataframe column whose percentage values are to be found\n",
    "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
    "        5) first_chart_title - the title for the first pie chart\n",
    "        6) second_chart_title - the title for the second pie chart\n",
    "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        None; just builds a pie chart to display the ratio of column contents between two dataframes\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of each activity in first_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_first_df = first_df[column] / sum(first_df[column]) * 100\n",
    "    else:\n",
    "        activity_percentages_first_df = first_df[column].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Calculate the percentage of each activity in second_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_second_df = second_df[column] / sum(second_df[column]) * 100\n",
    "    else:\n",
    "        activity_percentages_second_df = second_df[column].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Create subplots for pie charts\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot pie chart for df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    axes[0].pie(activity_percentages_first_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    axes[0].set_title(first_chart_title)\n",
    "\n",
    "    # Plot pie chart for windowed_df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    axes[1].pie(activity_percentages_second_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    axes[1].set_title(second_chart_title)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jH-5MYFlPiGG",
   "metadata": {
    "id": "jH-5MYFlPiGG"
   },
   "source": [
    "## Perform image augmentation using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0iT7IBC51ely",
   "metadata": {
    "id": "0iT7IBC51ely"
   },
   "outputs": [],
   "source": [
    "def get_ImageDataGen_image(imageDataGenerator, image):\n",
    "  \"\"\" Function that returns an image augmented with imageDataGenerator\n",
    "  Args:\n",
    "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
    "    2) image - an image passed as a numpy array\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  x = image.copy()\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  for batch in imageDataGenerator.flow(x, batch_size=1):\n",
    "      augmented_image=batch[0].copy().astype(np.uint8)\n",
    "      break\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "kdVdixQDPhmW",
   "metadata": {
    "id": "kdVdixQDPhmW"
   },
   "outputs": [],
   "source": [
    "def perform_ImageDataGen_augmentation(imageDataGenerator, images, image_filenames, target_size,\n",
    "                                      augm_prefix, num_augm_images=3, augm_images_dir_path=None,\n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) imageDataGenerator - ImageDataGenerator class object\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    augmented_index = 0\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        x = img.copy()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            i += 1\n",
    "            if i > num_augm_images:\n",
    "                augmented_index = 0\n",
    "                break\n",
    "\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "\n",
    "            augmented_index += 1\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                # tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(batch[0].copy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=batch[0].copy().astype(np.uint8),\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oewmXvvYPoS2",
   "metadata": {
    "id": "oewmXvvYPoS2"
   },
   "source": [
    "## Perform image augmentation using CV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5PxQiefcUULF",
   "metadata": {
    "id": "5PxQiefcUULF"
   },
   "source": [
    "### Augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "l42CveFAPquW",
   "metadata": {
    "id": "l42CveFAPquW"
   },
   "outputs": [],
   "source": [
    "def get_width_shift_image(image, width_shift_fraction):\n",
    "    \"\"\" Function for performing width_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) width_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    width_shift = int(height * width_shift_fraction)\n",
    "\n",
    "    # Calculate the new y-coordinate for height shift\n",
    "    y_shifted = height // 2 + width_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, 0], [0, 1, width_shift]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "yjmv3HHoPtqd",
   "metadata": {
    "id": "yjmv3HHoPtqd"
   },
   "outputs": [],
   "source": [
    "def get_height_shift_image(image, height_shift_fraction):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) height_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    height_shift = int(width * height_shift_fraction)\n",
    "\n",
    "    # Calculate the new x-coordinate for height shift\n",
    "    x_shifted = width // 2 + height_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, height_shift], [0, 1, 0]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eG8FTDtWPwGe",
   "metadata": {
    "id": "eG8FTDtWPwGe"
   },
   "outputs": [],
   "source": [
    "def get_brightness_augmentation_image(image, brightness_range=(0.5, 1.5)):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Generate a random brightness factor within the specified range\n",
    "    brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "\n",
    "    # Adjust the brightness by scaling the V channel\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)\n",
    "\n",
    "    # Convert the image back to the original color space (BGR)\n",
    "    augmented_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2tYCvwyDPx3V",
   "metadata": {
    "id": "2tYCvwyDPx3V"
   },
   "outputs": [],
   "source": [
    "def get_contrast_augmentation_image(image, contrast_factor):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) contrast_factor - adjusts the contrast of the image by applying CLAHE; possible values: [1.0; 4.0]\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into L, A, and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=contrast_factor, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "\n",
    "    # Convert the LAB image back to BGR color space\n",
    "    contrast_augmented_image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return contrast_augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "KqcGVI2NP1j-",
   "metadata": {
    "id": "KqcGVI2NP1j-"
   },
   "outputs": [],
   "source": [
    "def get_hsv_image(image, hue_shift, saturation_scale=1, value_scale=1):\n",
    "    \"\"\" Function to change the color tone of the image when switching to the HSV model\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) hue_shift - the value of the Hue parameter of the hsv model; possible values: [0; 179] (OpenCV)\n",
    "        3) saturation_scale - coefficient by which the Saturation parameter of the HSV model will be multiplied\n",
    "        4) value_scale - coefficient by which the Value parameter of the HSV model will be multiplied\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the original image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the hue shift to the hue channel\n",
    "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
    "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_scale, 0, 255)\n",
    "    hsv_image[:, :, 2] = np.clip(hsv_image[:, :, 2] * value_scale, 0, 255)\n",
    "\n",
    "    # Convert the image back to the RGB color space\n",
    "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "GYnBKRn51YfT",
   "metadata": {
    "id": "GYnBKRn51YfT"
   },
   "outputs": [],
   "source": [
    "def get_noisy_image(image, mean=1, std_dev=0.7):\n",
    "    \"\"\" Function for adding random noise to the image 'image'\n",
    "    Args:\n",
    "        1) image - an image passed as a numpy array\n",
    "        2) mean - the mean value of the noise\n",
    "        3) std_dev - the standard deviation of the noise (the larger the std_dev, the more intense the noise will be)\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(mean, std_dev, image.shape).astype('uint8')\n",
    "    augmented_image = cv2.add(image, noise)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mGnfBhhQ1jJI",
   "metadata": {
    "id": "mGnfBhhQ1jJI"
   },
   "outputs": [],
   "source": [
    "def remove_background(input_path, output_path=None):\n",
    "    \"\"\" Function to remove the background from the image\n",
    "    Args:\n",
    "      1) input_path - the path to the image whose background should be removed\n",
    "      2) output_path - the path to save an image without a background\n",
    "    Returns:\n",
    "      Image without background\n",
    "    \"\"\"\n",
    "     # Processing the image\n",
    "    input_image = Image.open(input_path)\n",
    "\n",
    "    # Removing the background from the given Image\n",
    "    output_image = remove(input_image)\n",
    "\n",
    "    # Convert the output image to RGB mode (removing transparency)\n",
    "    output_image = output_image.convert(\"RGB\")\n",
    "\n",
    "    if output_path:\n",
    "      # Save the image with the background removed\n",
    "      output_image.save(output_path)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "LEuXuDQ51nfo",
   "metadata": {
    "id": "LEuXuDQ51nfo"
   },
   "outputs": [],
   "source": [
    "def get_background_image(image, background_image, source_path, image_name, no_background_output_path=None):\n",
    "  \"\"\" Function to replace the background of the original image with the background image background_image\n",
    "  Args:\n",
    "    1) image - an image passed as a numpy array\n",
    "    2) background_image - a background image passed as a numpy array\n",
    "    3) source_path - path to image 'image'\n",
    "    4) image_name - name of the image 'image'\n",
    "    5) no_background_output_path - the path (along with the image name) to store the original image without the background\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  if no_background_output_path is not None:\n",
    "    pil_image = remove_background(input_path=os.path.join(source_path, image_name),\n",
    "                    output_path=os.path.join(no_background_output_path, image_name))\n",
    "  else:\n",
    "    pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
    "\n",
    "  augmented_image = background_image.copy()\n",
    "\n",
    "  # Convert PIL image to OpenCV format (NumPy array)\n",
    "  image_without_background = np.array(pil_image)\n",
    "\n",
    "  mask = cv2.cvtColor(image_without_background, cv2.COLOR_BGR2GRAY)\n",
    "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "  mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "  garbage_area = cv2.bitwise_and(image_without_background, image_without_background, mask=mask)\n",
    "  background_area = cv2.bitwise_and(augmented_image, augmented_image, mask=mask_inv)\n",
    "  augmented_image = cv2.add(garbage_area, background_area)\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "zwbR-nZX1rJl",
   "metadata": {
    "id": "zwbR-nZX1rJl"
   },
   "outputs": [],
   "source": [
    "def get_augmented_background_image(imageDataGenerator, image, background_image, source_path, image_name):\n",
    "  \"\"\" Function that returns a new augmented image (eg reduced in size) with a new background\n",
    "  Args:\n",
    "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
    "    2) image - an image passed as a numpy array\n",
    "    3) background_image - a background image passed as a numpy array\n",
    "    4) source_path -  path to image 'image'\n",
    "    5) image_name - name of the image 'image'\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
    "\n",
    "  # Convert PIL image to OpenCV format (NumPy array)\n",
    "  image_without_background = np.array(pil_image)\n",
    "\n",
    "  changed_image = get_ImageDataGen_image(imageDataGenerator=imageDataGenerator,\n",
    "                                         image=image_without_background)\n",
    "\n",
    "  mask = cv2.cvtColor(changed_image, cv2.COLOR_BGR2GRAY)\n",
    "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "  mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "  garbage_area = cv2.bitwise_and(changed_image, changed_image, mask=mask)\n",
    "  augmented_image = background_image.copy()\n",
    "  background_area = cv2.bitwise_and(augmented_image, augmented_image,\n",
    "                                  mask=mask_inv)\n",
    "  augmented_image = cv2.add(garbage_area, background_area)\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cwXhFVwTUYPI",
   "metadata": {
    "id": "cwXhFVwTUYPI"
   },
   "source": [
    "### Augmentation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "OBXdj3gTUbgd",
   "metadata": {
    "id": "OBXdj3gTUbgd"
   },
   "outputs": [],
   "source": [
    "def perform_cv2_rotation_augmentation(rotation_range, images, image_filenames,\n",
    "                                      target_size, augm_prefix,\n",
    "                                      num_augm_images=3, augm_images_dir_path=None,\n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) rotation_range - the range (a list of two elements: [range_min; range_max]) in which the angle value will change linearly (depending on num_augm_images)\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    height = target_size[0]\n",
    "    width = target_size[1]\n",
    "    angle_increment = int((rotation_range[1] - rotation_range[0]) / num_augm_images)\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        angle = rotation_range[0]\n",
    "        for i in range(num_augm_images):\n",
    "            # Calculate the rotation matrix\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "\n",
    "            # Apply the rotation to the image using warpAffine\n",
    "            augmented_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "            angle += angle_increment\n",
    "            if angle == 0:\n",
    "                angle += angle_increment\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augm_images_dir_path, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augm_images_dir_path, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dAaU8XHhUeAG",
   "metadata": {
    "id": "dAaU8XHhUeAG"
   },
   "outputs": [],
   "source": [
    "def perform_cv2_flip_augmentation(flip_code, images, image_filenames,\n",
    "                                  target_size, augm_prefix,\n",
    "                                  num_augm_images=3, augm_images_dir_path=None,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) flip_code - the type of flip augmentation to perform on the image: 0 - vertical, 1 - horizontal\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        for i in range(num_augm_images):\n",
    "            augmented_image = cv2.flip(img.copy(), flip_code)\n",
    "\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c",
   "metadata": {
    "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba",
   "metadata": {
    "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, strings, filename=None):\n",
    "    \"\"\"Function to plot graphs for two training history parameters (eg accuracy and loss)\n",
    "    Args:\n",
    "        1) history - model training history\n",
    "        2) strings - an array of names of history parameters (only the data of the first two history parameters specified in this array will be taken for graphing)\n",
    "        3) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].plot(history.history[strings[0]], label=strings[0])\n",
    "    axes[0].plot(history.history[f\"val_{strings[0]}\"], label=f\"val_{strings[0]}\")\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel(strings[0])\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(history.history[strings[1]], label=strings[1])\n",
    "    axes[1].plot(history.history[f\"val_{strings[1]}\"], label=f\"val_{strings[1]}\")\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel(strings[1])\n",
    "    axes[1].legend()\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(f\"{filename}.png\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
   "metadata": {
    "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089707ba-256c-4e27-9a65-c764999f41ac",
   "metadata": {
    "id": "089707ba-256c-4e27-9a65-c764999f41ac"
   },
   "outputs": [],
   "source": [
    "source_path = '/content/Garbage classification/Garbage classification'\n",
    "\n",
    "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
    "source_path_glass = os.path.join(source_path, 'glass')\n",
    "source_path_metal = os.path.join(source_path, 'metal')\n",
    "source_path_paper = os.path.join(source_path, 'paper')\n",
    "source_path_plastic = os.path.join(source_path, 'plastic')\n",
    "source_path_trash = os.path.join(source_path, 'trash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6808b080-50b3-423d-aca4-60fc14129e79",
   "metadata": {
    "id": "6808b080-50b3-423d-aca4-60fc14129e79"
   },
   "outputs": [],
   "source": [
    "cardboard_image_names = os.listdir(source_path_cardboard)\n",
    "glass_image_names = os.listdir(source_path_glass)\n",
    "metal_image_names = os.listdir(source_path_metal)\n",
    "paper_image_names = os.listdir(source_path_paper)\n",
    "plastic_image_names = os.listdir(source_path_plastic)\n",
    "trash_image_names = os.listdir(source_path_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
    "outputId": "6f6ca860-f361-4aba-9f50-914e16fc4f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 403 images of cardboard.\n",
      "There are 501 images of glass.\n",
      "There are 410 images of metal.\n",
      "There are 594 images of paper.\n",
      "There are 482 images of plastic.\n",
      "There are 137 images of trash.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(cardboard_image_names)} images of cardboard.\") # 403\n",
    "print(f\"There are {len(glass_image_names)} images of glass.\") # 501\n",
    "print(f\"There are {len(metal_image_names)} images of metal.\") # 410\n",
    "print(f\"There are {len(paper_image_names)} images of paper.\") # 594\n",
    "print(f\"There are {len(plastic_image_names)} images of plastic.\") # 482\n",
    "print(f\"There are {len(trash_image_names)} images of trash.\") # 137"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3365a-13fe-480a-b5a1-a73191acca39",
   "metadata": {
    "id": "a9d3365a-13fe-480a-b5a1-a73191acca39"
   },
   "source": [
    "## Display classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
    "outputId": "2ceb8fbf-79c3-4db2-f479-05cacc0c2e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 403 images of cardboard.\n",
      "There are 501 images of glass.\n",
      "There are 410 images of metal.\n",
      "There are 594 images of paper.\n",
      "There are 482 images of plastic.\n",
      "There are 137 images of trash.\n"
     ]
    }
   ],
   "source": [
    "classes_representatives = {'cardboard': len(cardboard_image_names),\n",
    "                           'glass': len(glass_image_names),\n",
    "                           'metal': len(metal_image_names),\n",
    "                           'paper': len(paper_image_names),\n",
    "                           'plastic': len(plastic_image_names),\n",
    "                           'trash': len(trash_image_names)\n",
    "                          }\n",
    "for label_class in classes_representatives.keys():\n",
    "    print(f\"There are {classes_representatives[label_class]} images of {label_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
    "outputId": "63c8e93a-abbc-4fea-97aa-c0016531e3e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0ad7c433-b003-4330-933c-1422eac89b91\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardboard</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metal</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plastic</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trash</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad7c433-b003-4330-933c-1422eac89b91')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       class  count\n",
       "0  cardboard    403\n",
       "1      glass    501\n",
       "2      metal    410\n",
       "3      paper    594\n",
       "4    plastic    482\n",
       "5      trash    137"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_df = pd.DataFrame(list(classes_representatives.items()), columns=['class', 'count'])\n",
    "classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be70e4-b5f7-4d75-8f22-3523543856c1",
   "metadata": {
    "id": "95be70e4-b5f7-4d75-8f22-3523543856c1"
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.barplot(data=classes_df, x='class', y='count')\n",
    "plt.title('The number of representatives of the label class (Original dataset)')\n",
    "# plt.savefig('graphs/original_barplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc",
   "metadata": {
    "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=classes_df, column_name='count', title='Percentage ratio between label classes (Original dataset)',\n",
    "                  column_contains_count=True) # filename='graphs/original_piechart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59dd5b1-3054-4e06-a376-42362774907a",
   "metadata": {
    "id": "e59dd5b1-3054-4e06-a376-42362774907a",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Display representatives of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
   "metadata": {
    "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
    "tags": []
   },
   "source": [
    "### Cardboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d",
   "metadata": {
    "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d"
   },
   "outputs": [],
   "source": [
    "for cardboard_image_name in cardboard_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_cardboard, image_name=cardboard_image_name, title=cardboard_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
   "metadata": {
    "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
    "tags": []
   },
   "source": [
    "### Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f",
   "metadata": {
    "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f"
   },
   "outputs": [],
   "source": [
    "for glass_image_name in glass_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_glass, image_name=glass_image_name, title=glass_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
   "metadata": {
    "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
    "tags": []
   },
   "source": [
    "### Metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111dde7-c214-4c69-aa42-58c907e167d8",
   "metadata": {
    "id": "d111dde7-c214-4c69-aa42-58c907e167d8"
   },
   "outputs": [],
   "source": [
    "for metal_image_name in metal_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_metal, image_name=metal_image_name, title=metal_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
   "metadata": {
    "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
    "tags": []
   },
   "source": [
    "### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095e9ea-86af-404e-969d-d077462c81b4",
   "metadata": {
    "id": "0095e9ea-86af-404e-969d-d077462c81b4"
   },
   "outputs": [],
   "source": [
    "for paper_image_name in paper_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_paper, image_name=paper_image_name, title=paper_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
   "metadata": {
    "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
    "tags": []
   },
   "source": [
    "### Plastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05",
   "metadata": {
    "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05"
   },
   "outputs": [],
   "source": [
    "for plastic_image_name in plastic_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_plastic, image_name=plastic_image_name, title=plastic_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
   "metadata": {
    "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
    "tags": []
   },
   "source": [
    "### Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6",
   "metadata": {
    "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6"
   },
   "outputs": [],
   "source": [
    "for trash_image_name in trash_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_trash, image_name=trash_image_name, title=trash_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
   "metadata": {
    "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split data into train, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39",
   "metadata": {
    "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39"
   },
   "source": [
    "## Create folders for train/valid/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0",
   "metadata": {
    "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0"
   },
   "outputs": [],
   "source": [
    "destination_path = '/content/garbage_classification_TrainValidTest/'\n",
    "\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "create_train_valid_test_dirs(root_path=destination_path, subdir_names=garbage_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce8b08-d600-431e-9365-395f20cf0402",
   "metadata": {
    "id": "70ce8b08-d600-431e-9365-395f20cf0402"
   },
   "source": [
    "## Split the data and save it in the appropriate folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
   "metadata": {
    "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Split classes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
    "outputId": "fadbf718-3759-46a9-907d-7447ea16576d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard: train = 307\n",
      "cardboard: valid = 55\n",
      "cardboard: test = 41\n",
      "\n",
      "glass: train = 382\n",
      "glass: valid = 68\n",
      "glass: test = 51\n",
      "\n",
      "metal: train = 313\n",
      "metal: valid = 56\n",
      "metal: test = 41\n",
      "\n",
      "paper: train = 453\n",
      "paper: valid = 81\n",
      "paper: test = 60\n",
      "\n",
      "plastic: train = 368\n",
      "plastic: valid = 65\n",
      "plastic: test = 49\n",
      "\n",
      "trash: train = 104\n",
      "trash: valid = 19\n",
      "trash: test = 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
    "\n",
    "for class_name in garbage_class_names:\n",
    "    split_class_data(source_dir_path=source_path, train_valid_test_paths=train_valid_test_paths,\n",
    "                 class_dir_name=class_name, train_test_split=0.9, train_valid_split=0.85, random_sample=False)\n",
    "\n",
    "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
    "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
    "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
    "\n",
    "    print(f\"{class_name}: train = {len(class_train_images)}\")\n",
    "    print(f\"{class_name}: valid = {len(class_valid_images)}\")\n",
    "    print(f\"{class_name}: test = {len(class_test_images)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
   "metadata": {
    "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef"
   },
   "source": [
    "#### Check classes distribution after spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51",
   "metadata": {
    "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51"
   },
   "outputs": [],
   "source": [
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "classes_train_dict = {}\n",
    "classes_valid_dict = {}\n",
    "classes_test_dict = {}\n",
    "for class_name in garbage_class_names:\n",
    "    classes_train_dict[class_name] = 0\n",
    "    classes_valid_dict[class_name] = 0\n",
    "    classes_test_dict[class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
    "outputId": "87c457d8-c029-4738-bf57-f94a0c89f428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_train_dict = {'cardboard': 307, 'glass': 382, 'metal': 313, 'paper': 453, 'plastic': 368, 'trash': 104}\n",
      "classes_valid_dict = {'cardboard': 55, 'glass': 68, 'metal': 56, 'paper': 81, 'plastic': 65, 'trash': 19}\n",
      "classes_test_dict = {'cardboard': 41, 'glass': 51, 'metal': 41, 'paper': 60, 'plastic': 49, 'trash': 14}\n"
     ]
    }
   ],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
    "\n",
    "for class_name in garbage_class_names:\n",
    "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
    "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
    "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
    "\n",
    "    classes_train_dict[class_name] = len(class_train_images)\n",
    "    classes_valid_dict[class_name] = len(class_valid_images)\n",
    "    classes_test_dict[class_name] = len(class_test_images)\n",
    "\n",
    "print(f\"classes_train_dict = {classes_train_dict}\")\n",
    "print(f\"classes_valid_dict = {classes_valid_dict}\")\n",
    "print(f\"classes_test_dict = {classes_test_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
    "outputId": "886f2cdc-c551-468a-f9c8-9b5c8ba39a99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-33a0842b-d886-4732-a9d2-02312509c3f1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardboard</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metal</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plastic</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trash</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a0842b-d886-4732-a9d2-02312509c3f1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-137538ec-8be6-4d17-8c60-93217d09dfe2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-137538ec-8be6-4d17-8c60-93217d09dfe2')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-137538ec-8be6-4d17-8c60-93217d09dfe2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       class  count\n",
       "0  cardboard    307\n",
       "1      glass    382\n",
       "2      metal    313\n",
       "3      paper    453\n",
       "4    plastic    368\n",
       "5      trash    104"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes_df = pd.DataFrame(list(classes_train_dict.items()), columns=['class', 'count'])\n",
    "valid_classes_df = pd.DataFrame(list(classes_valid_dict.items()), columns=['class', 'count'])\n",
    "test_classes_df = pd.DataFrame(list(classes_test_dict.items()), columns=['class', 'count'])\n",
    "\n",
    "train_classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2",
   "metadata": {
    "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2"
   },
   "source": [
    "##### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4",
   "metadata": {
    "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=train_classes_df, column_name='count', title='Percentage ratio between label classes (Train dataset)',\n",
    "                  column_contains_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3",
   "metadata": {
    "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=train_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Train Data',\n",
    "                   filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae",
   "metadata": {
    "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae"
   },
   "source": [
    "##### Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c742c2-33f7-436e-bd50-aeb229afbf10",
   "metadata": {
    "id": "93c742c2-33f7-436e-bd50-aeb229afbf10"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=valid_classes_df, column_name='count', title='Percentage ratio between label classes (Validation dataset)',\n",
    "                  column_contains_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26",
   "metadata": {
    "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=valid_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Valid Data',\n",
    "                   filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2c56e-aac4-4403-a89c-177d7584ca76",
   "metadata": {
    "id": "50d2c56e-aac4-4403-a89c-177d7584ca76"
   },
   "source": [
    "##### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592",
   "metadata": {
    "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=test_classes_df, column_name='count', title='Percentage ratio between label classes (Test dataset)',\n",
    "                  column_contains_count=True, filename='graphs/test_piechart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a51dc2-dff2-408c-818d-9e9b052699a6",
   "metadata": {
    "id": "81a51dc2-dff2-408c-818d-9e9b052699a6"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=test_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Test Data',\n",
    "                   filename='graphs/original_vs_test_piecharts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mQE7_geHaYNI",
   "metadata": {
    "id": "mQE7_geHaYNI"
   },
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iF2NpBGwTgKy",
   "metadata": {
    "id": "iF2NpBGwTgKy"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2tXUGWXkTfKY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tXUGWXkTfKY",
    "outputId": "a746819f-6d4b-4a53-c9bf-4bc17618af5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard: len(images) = 307\n",
      "glass: len(images) = 382\n",
      "metal: len(images) = 313\n",
      "paper: len(images) = 453\n",
      "plastic: len(images) = 368\n",
      "trash: len(images) = 104\n"
     ]
    }
   ],
   "source": [
    "image_classes_filepaths = [train_dir_path + 'cardboard', train_dir_path + 'glass',\n",
    "                           train_dir_path + 'metal', train_dir_path + 'paper',\n",
    "                           train_dir_path + 'plastic', train_dir_path + 'trash']\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "show_images = False\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "  image_filenames = os.listdir(image_filepath)\n",
    "\n",
    "  for image_name in image_filenames:\n",
    "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      garbage_class_images[garbage_class_name].append(img)\n",
    "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
    "\n",
    "      if show_images:\n",
    "          display_image(img, title=image_name)\n",
    "\n",
    "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "g3czvCJIWO6O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3czvCJIWO6O",
    "outputId": "49bfa745-20c2-452a-a0ae-5b683055fdae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_height = 384, img_width = 512\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
    "target_size = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49lwYs7vW5X-",
   "metadata": {
    "id": "49lwYs7vW5X-"
   },
   "outputs": [],
   "source": [
    "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "G08ohnwpL5Oc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G08ohnwpL5Oc",
    "outputId": "278d109c-c7a7-4f0f-cf26-eb743456888a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.5 * len(garbage_class_images['cardboard']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "INok7fjPMTXm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INok7fjPMTXm",
    "outputId": "12bc8e6f-3d39-46e3-9c4f-9301504fdecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_index = 153\n",
      "len(image_names) = 153\n",
      "split_index = 191\n",
      "len(image_names) = 191\n",
      "split_index = 156\n",
      "len(image_names) = 156\n",
      "split_index = 226\n",
      "len(image_names) = 226\n",
      "split_index = 184\n",
      "len(image_names) = 184\n",
      "split_index = 52\n",
      "len(image_names) = 52\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  split_index = int(0.5 * len(image_names))\n",
    "  print(f'split_index = {split_index}')\n",
    "  image_names = image_names[:split_index]\n",
    "  print(f'len(image_names) = {len(image_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMRZMug1axTK",
   "metadata": {
    "id": "rMRZMug1axTK"
   },
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FIayHvfOLeZ1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIayHvfOLeZ1",
    "outputId": "af1991d8-3408-4a3b-d734-b69755bf5dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 307\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
      "cardboard after augmentation: len(images) = 921\n",
      "glass before augmentation: len(images) = 382\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
      "glass after augmentation: len(images) = 1146\n",
      "metal before augmentation: len(images) = 313\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
      "metal after augmentation: len(images) = 939\n",
      "paper before augmentation: len(images) = 453\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
      "paper after augmentation: len(images) = 1359\n",
      "plastic before augmentation: len(images) = 368\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
      "plastic after augmentation: len(images) = 1104\n",
      "trash before augmentation: len(images) = 104\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
      "trash after augmentation: len(images) = 312\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
    "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                  augm_images_dir_path=augmented_images_dir,\n",
    "                                  target_size=target_size,\n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_TZ7u46SaVaN",
   "metadata": {
    "id": "_TZ7u46SaVaN"
   },
   "source": [
    "#### Expacted output:\n",
    "cardboard before augmentation: len(images) = 307;\n",
    "cardboard after augmentation: len(images) = 2149\n",
    "\n",
    "glass before augmentation: len(images) = 382;\n",
    "glass after augmentation: len(images) = 2674\n",
    "\n",
    "metal before augmentation: len(images) = 313;\n",
    "metal after augmentation: len(images) = 2191\n",
    "\n",
    "paper before augmentation: len(images) = 453;\n",
    "paper after augmentation: len(images) = 3171\n",
    "\n",
    "plastic before augmentation: len(images) = 368;\n",
    "plastic after augmentation: len(images) = 2576\n",
    "\n",
    "trash before augmentation: len(images) = 104;\n",
    "trash after augmentation: len(images) = 728"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SVoc99d2bFV6",
   "metadata": {
    "id": "SVoc99d2bFV6"
   },
   "source": [
    "### width_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dhGL15Ira2tr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhGL15Ira2tr",
    "outputId": "9aeaff69-f792-4567-f356-0a3f9e169663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(garbage_class_images[cardboard]) = 307\n",
      "len(garbage_class_images[glass]) = 382\n",
      "len(garbage_class_images[metal]) = 313\n",
      "len(garbage_class_images[paper]) = 453\n",
      "len(garbage_class_images[plastic]) = 368\n",
      "len(garbage_class_images[trash]) = 104\n"
     ]
    }
   ],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9--uJ-PkbGH5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9--uJ-PkbGH5",
    "outputId": "e603ee55-d805-4447-d45b-d7bbcc78d3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 2149\n",
      "cardboard after augmentation: len(images) = 2763\n",
      "\n",
      "glass before augmentation: len(images) = 2674\n",
      "glass after augmentation: len(images) = 3438\n",
      "\n",
      "metal before augmentation: len(images) = 2191\n",
      "metal after augmentation: len(images) = 2817\n",
      "\n",
      "paper before augmentation: len(images) = 3171\n",
      "paper after augmentation: len(images) = 4077\n",
      "\n",
      "plastic before augmentation: len(images) = 2576\n",
      "plastic after augmentation: len(images) = 3312\n",
      "\n",
      "trash before augmentation: len(images) = 728\n",
      "trash after augmentation: len(images) = 936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "width_shift_fraction = 0.1\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cl36lkpgeR9X",
   "metadata": {
    "id": "cl36lkpgeR9X"
   },
   "source": [
    "#### Expacted output:\n",
    "cardboard before augmentation: len(images) = 2149;\n",
    "cardboard after augmentation: len(images) = 2149 + 307*2 = 2763\n",
    "\n",
    "glass before augmentation: len(images) = 2674;\n",
    "glass after augmentation: len(images) = 3438\n",
    "\n",
    "metal before augmentation: len(images) = 2191;\n",
    "metal after augmentation: len(images) = 2817\n",
    "\n",
    "paper before augmentation: len(images) = 3171;\n",
    "paper after augmentation: len(images) = 4077\n",
    "\n",
    "plastic before augmentation: len(images) = 2576;\n",
    "plastic after augmentation: len(images) = 3312\n",
    "\n",
    "trash before augmentation: len(images) = 728;\n",
    "trash after augmentation: len(images) = 936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r1oj75sjbMPq",
   "metadata": {
    "id": "r1oj75sjbMPq"
   },
   "source": [
    "### height_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wCysQhwUfG5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCysQhwUfG5f",
    "outputId": "c445f467-bbd2-495c-f705-b24fc1e8a696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(garbage_class_images[cardboard]) = 307\n",
      "len(garbage_class_images[glass]) = 382\n",
      "len(garbage_class_images[metal]) = 313\n",
      "len(garbage_class_images[paper]) = 453\n",
      "len(garbage_class_images[plastic]) = 368\n",
      "len(garbage_class_images[trash]) = 104\n"
     ]
    }
   ],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-jqPyxqofQVu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jqPyxqofQVu",
    "outputId": "f8aa356d-3b14-4dad-abc2-f5790cf8ab22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 2763\n",
      "cardboard after augmentation: len(images) = 3377\n",
      "\n",
      "glass before augmentation: len(images) = 3438\n",
      "glass after augmentation: len(images) = 4202\n",
      "\n",
      "metal before augmentation: len(images) = 2817\n",
      "metal after augmentation: len(images) = 3443\n",
      "\n",
      "paper before augmentation: len(images) = 4077\n",
      "paper after augmentation: len(images) = 4983\n",
      "\n",
      "plastic before augmentation: len(images) = 3312\n",
      "plastic after augmentation: len(images) = 4048\n",
      "\n",
      "trash before augmentation: len(images) = 936\n",
      "trash after augmentation: len(images) = 1144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "height_shift_fraction = 0.10\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nq6an5m7bYeU",
   "metadata": {
    "id": "Nq6an5m7bYeU"
   },
   "source": [
    "### horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Puc6cYtLf49y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Puc6cYtLf49y",
    "outputId": "bc6ed82b-04d2-4596-ae63-41c73dd55745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 921\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
      "cardboard after augmentation: len(images) = 1228\n",
      "glass before augmentation: len(images) = 1146\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
      "glass after augmentation: len(images) = 1528\n",
      "metal before augmentation: len(images) = 939\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
      "metal after augmentation: len(images) = 1252\n",
      "paper before augmentation: len(images) = 1359\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
      "paper after augmentation: len(images) = 1812\n",
      "plastic before augmentation: len(images) = 1104\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
      "plastic after augmentation: len(images) = 1472\n",
      "trash before augmentation: len(images) = 312\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
      "trash after augmentation: len(images) = 416\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xN_CBfSMbsNy",
   "metadata": {
    "id": "xN_CBfSMbsNy"
   },
   "source": [
    "### vertical_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uk2dbTtnjXPr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk2dbTtnjXPr",
    "outputId": "fcc5a26d-69a7-463b-d8c8-3548b49f90ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 1228\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
      "cardboard after augmentation: len(images) = 1535\n",
      "\n",
      "glass before augmentation: len(images) = 1528\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
      "glass after augmentation: len(images) = 1910\n",
      "\n",
      "metal before augmentation: len(images) = 1252\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
      "metal after augmentation: len(images) = 1565\n",
      "\n",
      "paper before augmentation: len(images) = 1812\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
      "paper after augmentation: len(images) = 2265\n",
      "\n",
      "plastic before augmentation: len(images) = 1472\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
      "plastic after augmentation: len(images) = 1840\n",
      "\n",
      "trash before augmentation: len(images) = 416\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
      "trash after augmentation: len(images) = 520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wTLkX5eyb3ny",
   "metadata": {
    "id": "wTLkX5eyb3ny"
   },
   "source": [
    "### zoom = scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "URnp4hbnb_kD",
   "metadata": {
    "id": "URnp4hbnb_kD"
   },
   "source": [
    "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "g127KTuBj3bC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g127KTuBj3bC",
    "outputId": "b23cc138-0840-4a93-bca8-88c564c66ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 307\n",
      "cardboard after augmentation: len(images) = 460\n",
      "\n",
      "glass before augmentation: len(images) = 382\n",
      "glass after augmentation: len(images) = 573\n",
      "\n",
      "metal before augmentation: len(images) = 313\n",
      "metal after augmentation: len(images) = 469\n",
      "\n",
      "paper before augmentation: len(images) = 453\n",
      "paper after augmentation: len(images) = 679\n",
      "\n",
      "plastic before augmentation: len(images) = 368\n",
      "plastic after augmentation: len(images) = 552\n",
      "\n",
      "trash before augmentation: len(images) = 104\n",
      "trash after augmentation: len(images) = 156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(0.8, 1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8QlRMm8cQHR",
   "metadata": {
    "id": "b8QlRMm8cQHR"
   },
   "source": [
    "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8koWMEdEmorg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8koWMEdEmorg",
    "outputId": "c24dd8b2-6fcf-4c32-bf3e-e469048c7887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 460\n",
      "cardboard after augmentation: len(images) = 614\n",
      "\n",
      "glass before augmentation: len(images) = 573\n",
      "glass after augmentation: len(images) = 764\n",
      "\n",
      "metal before augmentation: len(images) = 469\n",
      "metal after augmentation: len(images) = 626\n",
      "\n",
      "paper before augmentation: len(images) = 679\n",
      "paper after augmentation: len(images) = 906\n",
      "\n",
      "plastic before augmentation: len(images) = 552\n",
      "plastic after augmentation: len(images) = 736\n",
      "\n",
      "trash before augmentation: len(images) = 156\n",
      "trash after augmentation: len(images) = 208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1, 1.2),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M6N_HmcbcdN6",
   "metadata": {
    "id": "M6N_HmcbcdN6"
   },
   "source": [
    "### brightness_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LRjIIZx-n-N7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRjIIZx-n-N7",
    "outputId": "d27080d7-bc60-408a-be55-54c43b7a23da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 2149\n",
      "cardboard after augmentation: len(images) = 2456\n",
      "\n",
      "glass before augmentation: len(images) = 2674\n",
      "glass after augmentation: len(images) = 3056\n",
      "\n",
      "metal before augmentation: len(images) = 2191\n",
      "metal after augmentation: len(images) = 2504\n",
      "\n",
      "paper before augmentation: len(images) = 3171\n",
      "paper after augmentation: len(images) = 3624\n",
      "\n",
      "plastic before augmentation: len(images) = 2576\n",
      "plastic after augmentation: len(images) = 2944\n",
      "\n",
      "trash before augmentation: len(images) = 728\n",
      "trash after augmentation: len(images) = 832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 0.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aWSH_5Fioxi1",
   "metadata": {
    "id": "aWSH_5Fioxi1"
   },
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.25, 0.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                  augm_prefix='aug_blackBrightness_0.25', num_augm_images=num_augmented_images,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R-iJpKwQo_hH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-iJpKwQo_hH",
    "outputId": "69da1b2b-f3a7-45bd-e541-e31d23fc6447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 2456\n",
      "cardboard after augmentation: len(images) = 2763\n",
      "\n",
      "glass before augmentation: len(images) = 3056\n",
      "glass after augmentation: len(images) = 3438\n",
      "\n",
      "metal before augmentation: len(images) = 2504\n",
      "metal after augmentation: len(images) = 2817\n",
      "\n",
      "paper before augmentation: len(images) = 3624\n",
      "paper after augmentation: len(images) = 4077\n",
      "\n",
      "plastic before augmentation: len(images) = 2944\n",
      "plastic after augmentation: len(images) = 3312\n",
      "\n",
      "trash before augmentation: len(images) = 832\n",
      "trash after augmentation: len(images) = 936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VLthfnuCpTKv",
   "metadata": {
    "id": "VLthfnuCpTKv"
   },
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.5, 1.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                  augm_prefix='aug_ligthBrightness_1.5', num_augm_images=num_augmented_images,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvIN0bJrdWjL",
   "metadata": {
    "id": "OvIN0bJrdWjL"
   },
   "source": [
    "### contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p9iw6kVhpe4g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9iw6kVhpe4g",
    "outputId": "069834fd-543c-494f-b636-5e2fc201ed71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 2763\n",
      "cardboard after augmentation: len(images) = 3070\n",
      "\n",
      "glass before augmentation: len(images) = 3438\n",
      "glass after augmentation: len(images) = 3820\n",
      "\n",
      "metal before augmentation: len(images) = 2817\n",
      "metal after augmentation: len(images) = 3130\n",
      "\n",
      "paper before augmentation: len(images) = 4077\n",
      "paper after augmentation: len(images) = 4530\n",
      "\n",
      "plastic before augmentation: len(images) = 3312\n",
      "plastic after augmentation: len(images) = 3680\n",
      "\n",
      "trash before augmentation: len(images) = 936\n",
      "trash after augmentation: len(images) = 1040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contrast_factor = 2.0\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auf2c59BdgWR",
   "metadata": {
    "id": "auf2c59BdgWR"
   },
   "source": [
    "### color space transformations (HSV) augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgEIQcbTqPIa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgEIQcbTqPIa",
    "outputId": "d4d1ede3-5336-487a-86c7-d9b91d5b1473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 3070\n",
      "cardboard after augmentation: len(images) = 3377\n",
      "\n",
      "glass before augmentation: len(images) = 3820\n",
      "glass after augmentation: len(images) = 4202\n",
      "\n",
      "metal before augmentation: len(images) = 3130\n",
      "metal after augmentation: len(images) = 3443\n",
      "\n",
      "paper before augmentation: len(images) = 4530\n",
      "paper after augmentation: len(images) = 4983\n",
      "\n",
      "plastic before augmentation: len(images) = 3680\n",
      "plastic after augmentation: len(images) = 4048\n",
      "\n",
      "trash before augmentation: len(images) = 1040\n",
      "trash after augmentation: len(images) = 1144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hue_shift=180\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
    "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkNIrE5i9yff",
   "metadata": {
    "id": "bkNIrE5i9yff"
   },
   "source": [
    "### noise addition augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q0yQQ7L091s1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0yQQ7L091s1",
    "outputId": "7b70dc8a-a0a2-4292-fa35-2a9e299eb2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 3377\n",
      "cardboard after augmentation: len(images) = 3684\n",
      "\n",
      "glass before augmentation: len(images) = 4202\n",
      "glass after augmentation: len(images) = 4584\n",
      "\n",
      "metal before augmentation: len(images) = 3443\n",
      "metal after augmentation: len(images) = 3756\n",
      "\n",
      "paper before augmentation: len(images) = 4983\n",
      "paper after augmentation: len(images) = 5436\n",
      "\n",
      "plastic before augmentation: len(images) = 4048\n",
      "plastic after augmentation: len(images) = 4416\n",
      "\n",
      "trash before augmentation: len(images) = 1144\n",
      "trash after augmentation: len(images) = 1248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_noisy_image(image=image)\n",
    "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5xs5E4lc92xt",
   "metadata": {
    "id": "5xs5E4lc92xt"
   },
   "source": [
    "### reduce garbage image + background augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpVxOJ_t-HH8",
   "metadata": {
    "id": "wpVxOJ_t-HH8"
   },
   "outputs": [],
   "source": [
    "background_image_filepath = '/content/backgrounds/'\n",
    "background_image_names = os.listdir(background_image_filepath)\n",
    "background_images = []\n",
    "show_images = True\n",
    "\n",
    "for background_image_name in background_image_names:\n",
    "    if '.ipynb' in background_image_name:\n",
    "      continue\n",
    "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
    "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
    "    background_images.append(background_image)\n",
    "\n",
    "    if show_images:\n",
    "        display_image(background_image, title=background_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506V4KEx-AqO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "506V4KEx-AqO",
    "outputId": "6f43df19-11e9-44d8-d4aa-5a4d86db0330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 3377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 149GB/s]\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1.2, 1.5),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.1\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "    counter = 0\n",
    "    for background_image in background_images:\n",
    "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
    "                                                       image=image,\n",
    "                                                       background_image=background_image,\n",
    "                                                       source_path=image_class_filepath,\n",
    "                                                       image_name=image_name)\n",
    "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
    "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "      counter += 1\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rwEBRaCz-A13",
   "metadata": {
    "id": "rwEBRaCz-A13"
   },
   "source": [
    "### brightness_shift + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aMm3JU0z-P18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMm3JU0z-P18",
    "outputId": "6ef5c6dd-3ebe-421b-bca6-46e95f966b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 3684\n",
      "cardboard after augmentation: len(images) = 3991\n",
      "\n",
      "glass before augmentation: len(images) = 4584\n",
      "glass after augmentation: len(images) = 4966\n",
      "\n",
      "metal before augmentation: len(images) = 3756\n",
      "metal after augmentation: len(images) = 4069\n",
      "\n",
      "paper before augmentation: len(images) = 5436\n",
      "paper after augmentation: len(images) = 5889\n",
      "\n",
      "plastic before augmentation: len(images) = 4416\n",
      "plastic after augmentation: len(images) = 4784\n",
      "\n",
      "trash before augmentation: len(images) = 1248\n",
      "trash after augmentation: len(images) = 1352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.35, 0.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][split_index:], garbage_class_image_names[garbage_class_name][split_index:]):\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QQTigweq-QHk",
   "metadata": {
    "id": "QQTigweq-QHk"
   },
   "source": [
    "### color space transformations (HSV) + brightness + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2lA2U8-j-Ztj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lA2U8-j-Ztj",
    "outputId": "63036b76-3eb4-403e-86cb-db506707c696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 3991\n",
      "cardboard after augmentation: len(images) = 4298\n",
      "\n",
      "glass before augmentation: len(images) = 4966\n",
      "glass after augmentation: len(images) = 5348\n",
      "\n",
      "metal before augmentation: len(images) = 4069\n",
      "metal after augmentation: len(images) = 4382\n",
      "\n",
      "paper before augmentation: len(images) = 5889\n",
      "paper after augmentation: len(images) = 6342\n",
      "\n",
      "plastic before augmentation: len(images) = 4784\n",
      "plastic after augmentation: len(images) = 5152\n",
      "\n",
      "trash before augmentation: len(images) = 1352\n",
      "trash after augmentation: len(images) = 1456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "hue_shift=170\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
    "\n",
    "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hDpVqXyVqtoX",
   "metadata": {
    "id": "hDpVqXyVqtoX"
   },
   "source": [
    "### Save train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I2RYqgC7qsAe",
   "metadata": {
    "id": "I2RYqgC7qsAe"
   },
   "outputs": [],
   "source": [
    "#!zip -r /content/train.zip /content/garbage_classification_TrainValidTest/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vH1WzuiGl9J7",
   "metadata": {
    "id": "vH1WzuiGl9J7"
   },
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "xhEFaLTPm7sj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhEFaLTPm7sj",
    "outputId": "390f1b33-fd79-4acc-951d-7020061ab5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard: len(images) = 55\n",
      "glass: len(images) = 68\n",
      "metal: len(images) = 56\n",
      "paper: len(images) = 81\n",
      "plastic: len(images) = 65\n",
      "trash: len(images) = 19\n"
     ]
    }
   ],
   "source": [
    "image_classes_filepaths = [valid_dir_path + 'cardboard', valid_dir_path + 'glass',\n",
    "                           valid_dir_path + 'metal', valid_dir_path + 'paper',\n",
    "                           valid_dir_path + 'plastic', valid_dir_path + 'trash']\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "show_images = False\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "  image_filenames = os.listdir(image_filepath)\n",
    "\n",
    "  for image_name in image_filenames:\n",
    "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      garbage_class_images[garbage_class_name].append(img)\n",
    "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
    "\n",
    "      if show_images:\n",
    "          display_image(img, title=image_name)\n",
    "\n",
    "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GX3lA1zTrK-N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GX3lA1zTrK-N",
    "outputId": "55a6e2bb-55ee-4c66-f185-1419423dbcd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_height = 384, img_width = 512\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
    "target_size = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LhPjOZiNuN0O",
   "metadata": {
    "id": "LhPjOZiNuN0O"
   },
   "source": [
    "### View image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kW0x9NzFrLpk",
   "metadata": {
    "id": "kW0x9NzFrLpk"
   },
   "outputs": [],
   "source": [
    "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wm0HzUnim4GY",
   "metadata": {
    "id": "Wm0HzUnim4GY"
   },
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3n4ETjxl_px",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3n4ETjxl_px",
    "outputId": "1244fbf6-c01b-4fd5-c2f4-94e697a26f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 55\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
      "cardboard after augmentation: len(images) = 165\n",
      "glass before augmentation: len(images) = 68\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
      "glass after augmentation: len(images) = 204\n",
      "metal before augmentation: len(images) = 56\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
      "metal after augmentation: len(images) = 168\n",
      "paper before augmentation: len(images) = 81\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
      "paper after augmentation: len(images) = 243\n",
      "plastic before augmentation: len(images) = 65\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
      "plastic after augmentation: len(images) = 195\n",
      "trash before augmentation: len(images) = 19\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
      "trash after augmentation: len(images) = 57\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
    "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                  augm_images_dir_path=augmented_images_dir,\n",
    "                                  target_size=target_size,\n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S1YCpPVUryl2",
   "metadata": {
    "id": "S1YCpPVUryl2"
   },
   "source": [
    "### width_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QdCBVionsCIl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdCBVionsCIl",
    "outputId": "9d1ff199-c4fe-4f86-d686-0b86cec11591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(garbage_class_images[cardboard]) = 55\n",
      "len(garbage_class_images[glass]) = 68\n",
      "len(garbage_class_images[metal]) = 56\n",
      "len(garbage_class_images[paper]) = 81\n",
      "len(garbage_class_images[plastic]) = 65\n",
      "len(garbage_class_images[trash]) = 19\n"
     ]
    }
   ],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yps6lh8nsPcp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yps6lh8nsPcp",
    "outputId": "7a90f4bb-3240-4201-d121-8a9432692764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 385\n",
      "cardboard after augmentation: len(images) = 495\n",
      "\n",
      "glass before augmentation: len(images) = 476\n",
      "glass after augmentation: len(images) = 612\n",
      "\n",
      "metal before augmentation: len(images) = 392\n",
      "metal after augmentation: len(images) = 504\n",
      "\n",
      "paper before augmentation: len(images) = 567\n",
      "paper after augmentation: len(images) = 729\n",
      "\n",
      "plastic before augmentation: len(images) = 455\n",
      "plastic after augmentation: len(images) = 585\n",
      "\n",
      "trash before augmentation: len(images) = 133\n",
      "trash after augmentation: len(images) = 171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "width_shift_fraction = 0.1\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iDPvcoMgseEW",
   "metadata": {
    "id": "iDPvcoMgseEW"
   },
   "source": [
    "### height_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2pfiHsBskgP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2pfiHsBskgP",
    "outputId": "276035a5-90c5-4cb6-90d1-937e907e5171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 495\n",
      "cardboard after augmentation: len(images) = 605\n",
      "\n",
      "glass before augmentation: len(images) = 612\n",
      "glass after augmentation: len(images) = 748\n",
      "\n",
      "metal before augmentation: len(images) = 504\n",
      "metal after augmentation: len(images) = 616\n",
      "\n",
      "paper before augmentation: len(images) = 729\n",
      "paper after augmentation: len(images) = 891\n",
      "\n",
      "plastic before augmentation: len(images) = 585\n",
      "plastic after augmentation: len(images) = 715\n",
      "\n",
      "trash before augmentation: len(images) = 171\n",
      "trash after augmentation: len(images) = 209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "height_shift_fraction = 0.10\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NdonW8OusrtF",
   "metadata": {
    "id": "NdonW8OusrtF"
   },
   "source": [
    "### horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQ5EvjcJsxD8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQ5EvjcJsxD8",
    "outputId": "4d5a1568-00ed-48d3-fff4-fbdbe39ee966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 165\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
      "cardboard after augmentation: len(images) = 220\n",
      "glass before augmentation: len(images) = 204\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
      "glass after augmentation: len(images) = 272\n",
      "metal before augmentation: len(images) = 168\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
      "metal after augmentation: len(images) = 224\n",
      "paper before augmentation: len(images) = 243\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
      "paper after augmentation: len(images) = 324\n",
      "plastic before augmentation: len(images) = 195\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
      "plastic after augmentation: len(images) = 260\n",
      "trash before augmentation: len(images) = 57\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
      "trash after augmentation: len(images) = 76\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lxd7HGmlsyRc",
   "metadata": {
    "id": "Lxd7HGmlsyRc"
   },
   "source": [
    "### vertical_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k-TBIPuzs-K9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-TBIPuzs-K9",
    "outputId": "0f9f1c53-d9e7-4978-db9e-514d6badd07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 220\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
      "cardboard after augmentation: len(images) = 275\n",
      "\n",
      "glass before augmentation: len(images) = 272\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
      "glass after augmentation: len(images) = 340\n",
      "\n",
      "metal before augmentation: len(images) = 224\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
      "metal after augmentation: len(images) = 280\n",
      "\n",
      "paper before augmentation: len(images) = 324\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
      "paper after augmentation: len(images) = 405\n",
      "\n",
      "plastic before augmentation: len(images) = 260\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
      "plastic after augmentation: len(images) = 325\n",
      "\n",
      "trash before augmentation: len(images) = 76\n",
      "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
      "trash after augmentation: len(images) = 95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oZNmeaEis_M9",
   "metadata": {
    "id": "oZNmeaEis_M9"
   },
   "source": [
    "### zoom = scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PLEmuhGMtKR2",
   "metadata": {
    "id": "PLEmuhGMtKR2"
   },
   "source": [
    "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "kFwoII_CSBLU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFwoII_CSBLU",
    "outputId": "bff5c8c6-7284-45b3-d853-725ff3688e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 55\n",
      "cardboard after augmentation: len(images) = 82\n",
      "\n",
      "glass before augmentation: len(images) = 68\n",
      "glass after augmentation: len(images) = 102\n",
      "\n",
      "metal before augmentation: len(images) = 56\n",
      "metal after augmentation: len(images) = 84\n",
      "\n",
      "paper before augmentation: len(images) = 81\n",
      "paper after augmentation: len(images) = 121\n",
      "\n",
      "plastic before augmentation: len(images) = 65\n",
      "plastic after augmentation: len(images) = 97\n",
      "\n",
      "trash before augmentation: len(images) = 19\n",
      "trash after augmentation: len(images) = 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(0.8, 1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3CXocmX_tJRk",
   "metadata": {
    "id": "3CXocmX_tJRk"
   },
   "source": [
    "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "V716jtPotgB1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V716jtPotgB1",
    "outputId": "e80849e5-50b0-46df-cfdb-06195f3c7b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 82\n",
      "cardboard after augmentation: len(images) = 110\n",
      "\n",
      "glass before augmentation: len(images) = 102\n",
      "glass after augmentation: len(images) = 136\n",
      "\n",
      "metal before augmentation: len(images) = 84\n",
      "metal after augmentation: len(images) = 112\n",
      "\n",
      "paper before augmentation: len(images) = 121\n",
      "paper after augmentation: len(images) = 162\n",
      "\n",
      "plastic before augmentation: len(images) = 97\n",
      "plastic after augmentation: len(images) = 130\n",
      "\n",
      "trash before augmentation: len(images) = 28\n",
      "trash after augmentation: len(images) = 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1, 1.2),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zLqDaHmgtgTd",
   "metadata": {
    "id": "zLqDaHmgtgTd"
   },
   "source": [
    "### brightness_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "Gec8GLoctvh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gec8GLoctvh1",
    "outputId": "47d31997-2ba9-4a0f-8ac6-b95fc7bf5081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 110\n",
      "cardboard after augmentation: len(images) = 137\n",
      "\n",
      "glass before augmentation: len(images) = 136\n",
      "glass after augmentation: len(images) = 170\n",
      "\n",
      "metal before augmentation: len(images) = 112\n",
      "metal after augmentation: len(images) = 140\n",
      "\n",
      "paper before augmentation: len(images) = 162\n",
      "paper after augmentation: len(images) = 202\n",
      "\n",
      "plastic before augmentation: len(images) = 130\n",
      "plastic after augmentation: len(images) = 162\n",
      "\n",
      "trash before augmentation: len(images) = 38\n",
      "trash after augmentation: len(images) = 47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 0.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "AbJMQn6lt-3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbJMQn6lt-3e",
    "outputId": "70dd63d6-cf2e-40e9-f2ee-1da3b9f5fd2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 137\n",
      "cardboard after augmentation: len(images) = 165\n",
      "\n",
      "glass before augmentation: len(images) = 170\n",
      "glass after augmentation: len(images) = 204\n",
      "\n",
      "metal before augmentation: len(images) = 140\n",
      "metal after augmentation: len(images) = 168\n",
      "\n",
      "paper before augmentation: len(images) = 202\n",
      "paper after augmentation: len(images) = 243\n",
      "\n",
      "plastic before augmentation: len(images) = 162\n",
      "plastic after augmentation: len(images) = 195\n",
      "\n",
      "trash before augmentation: len(images) = 47\n",
      "trash after augmentation: len(images) = 57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lADCJADjtvxU",
   "metadata": {
    "id": "lADCJADjtvxU"
   },
   "source": [
    "### contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2KyAabx-uLV0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KyAabx-uLV0",
    "outputId": "e26d8cd3-7b0f-4921-8402-9214617b55fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 495\n",
      "cardboard after augmentation: len(images) = 550\n",
      "\n",
      "glass before augmentation: len(images) = 612\n",
      "glass after augmentation: len(images) = 680\n",
      "\n",
      "metal before augmentation: len(images) = 504\n",
      "metal after augmentation: len(images) = 560\n",
      "\n",
      "paper before augmentation: len(images) = 729\n",
      "paper after augmentation: len(images) = 810\n",
      "\n",
      "plastic before augmentation: len(images) = 585\n",
      "plastic after augmentation: len(images) = 650\n",
      "\n",
      "trash before augmentation: len(images) = 171\n",
      "trash after augmentation: len(images) = 190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contrast_factor = 2.0\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xPP3kC0vuLgD",
   "metadata": {
    "id": "xPP3kC0vuLgD"
   },
   "source": [
    "### color space transformations (HSV) augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ypPMgGi6udIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypPMgGi6udIm",
    "outputId": "4f35d48a-5084-401d-8cee-4bd584e0cfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 550\n",
      "cardboard after augmentation: len(images) = 605\n",
      "\n",
      "glass before augmentation: len(images) = 680\n",
      "glass after augmentation: len(images) = 748\n",
      "\n",
      "metal before augmentation: len(images) = 560\n",
      "metal after augmentation: len(images) = 616\n",
      "\n",
      "paper before augmentation: len(images) = 810\n",
      "paper after augmentation: len(images) = 891\n",
      "\n",
      "plastic before augmentation: len(images) = 650\n",
      "plastic after augmentation: len(images) = 715\n",
      "\n",
      "trash before augmentation: len(images) = 190\n",
      "trash after augmentation: len(images) = 209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hue_shift=180\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
    "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y1qLJ2g506nN",
   "metadata": {
    "id": "Y1qLJ2g506nN"
   },
   "source": [
    "### noise addition augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGJnMe4Y1Pvz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGJnMe4Y1Pvz",
    "outputId": "9a295568-8a32-4b35-b6f0-e446dc06baa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 605\n",
      "cardboard after augmentation: len(images) = 660\n",
      "\n",
      "glass before augmentation: len(images) = 748\n",
      "glass after augmentation: len(images) = 816\n",
      "\n",
      "metal before augmentation: len(images) = 616\n",
      "metal after augmentation: len(images) = 672\n",
      "\n",
      "paper before augmentation: len(images) = 891\n",
      "paper after augmentation: len(images) = 972\n",
      "\n",
      "plastic before augmentation: len(images) = 715\n",
      "plastic after augmentation: len(images) = 780\n",
      "\n",
      "trash before augmentation: len(images) = 209\n",
      "trash after augmentation: len(images) = 228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_noisy_image(image=image)\n",
    "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5h2Ggtv72gdt",
   "metadata": {
    "id": "5h2Ggtv72gdt"
   },
   "source": [
    "### reduce garbage image + background augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ngXmJ2lNM",
   "metadata": {
    "id": "bc7ngXmJ2lNM"
   },
   "outputs": [],
   "source": [
    "background_image_filepath = '/content/backgrounds/'\n",
    "background_image_names = os.listdir(background_image_filepath)\n",
    "background_images = []\n",
    "show_images = True\n",
    "\n",
    "for background_image_name in background_image_names:\n",
    "    if '.ipynb' in background_image_name:\n",
    "      continue\n",
    "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
    "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
    "    background_images.append(background_image)\n",
    "\n",
    "    if show_images:\n",
    "        display_image(background_image, title=background_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "SuzNh7AMS0no",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuzNh7AMS0no",
    "outputId": "f89fa2ad-6a1c-4bd8-b01b-f4faebb4992c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 176M/176M [00:00<00:00, 63.2GB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard after augmentation: len(images) = 170\n",
      "\n",
      "glass before augmentation: len(images) = 204\n",
      "glass after augmentation: len(images) = 210\n",
      "\n",
      "metal before augmentation: len(images) = 168\n",
      "metal after augmentation: len(images) = 173\n",
      "\n",
      "paper before augmentation: len(images) = 243\n",
      "paper after augmentation: len(images) = 251\n",
      "\n",
      "plastic before augmentation: len(images) = 195\n",
      "plastic after augmentation: len(images) = 201\n",
      "\n",
      "trash before augmentation: len(images) = 57\n",
      "trash after augmentation: len(images) = 58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1.2, 1.5),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.1\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "    counter = 0\n",
    "    for background_image in background_images:\n",
    "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
    "                                                       image=image,\n",
    "                                                       background_image=background_image,\n",
    "                                                       source_path=image_class_filepath,\n",
    "                                                       image_name=image_name)\n",
    "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
    "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "      counter += 1\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0g3W4Fr6lR2",
   "metadata": {
    "id": "m0g3W4Fr6lR2"
   },
   "source": [
    "### brightness_shift + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "TBBS121o6x0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBBS121o6x0u",
    "outputId": "ba3696dc-5ab2-4a44-a51b-ea33e83ff54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 170\n",
      "cardboard after augmentation: len(images) = 198\n",
      "\n",
      "glass before augmentation: len(images) = 210\n",
      "glass after augmentation: len(images) = 244\n",
      "\n",
      "metal before augmentation: len(images) = 173\n",
      "metal after augmentation: len(images) = 201\n",
      "\n",
      "paper before augmentation: len(images) = 251\n",
      "paper after augmentation: len(images) = 292\n",
      "\n",
      "plastic before augmentation: len(images) = 201\n",
      "plastic after augmentation: len(images) = 234\n",
      "\n",
      "trash before augmentation: len(images) = 58\n",
      "trash after augmentation: len(images) = 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.35, 0.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][split_index:], garbage_class_image_names[garbage_class_name][split_index:]):\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9uPP8ROm7bB9",
   "metadata": {
    "id": "9uPP8ROm7bB9"
   },
   "source": [
    "### color space transformations (HSV) + brightness + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0Kv50wZ7jK_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0Kv50wZ7jK_",
    "outputId": "d7f9c507-4c35-473f-800e-02f024e8c622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard before augmentation: len(images) = 198\n",
      "cardboard after augmentation: len(images) = 225\n",
      "\n",
      "glass before augmentation: len(images) = 244\n",
      "glass after augmentation: len(images) = 278\n",
      "\n",
      "metal before augmentation: len(images) = 201\n",
      "metal after augmentation: len(images) = 229\n",
      "\n",
      "paper before augmentation: len(images) = 292\n",
      "paper after augmentation: len(images) = 332\n",
      "\n",
      "plastic before augmentation: len(images) = 234\n",
      "plastic after augmentation: len(images) = 266\n",
      "\n",
      "trash before augmentation: len(images) = 68\n",
      "trash after augmentation: len(images) = 77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "hue_shift=170\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
    "\n",
    "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHp2s0HkuwPs",
   "metadata": {
    "id": "HHp2s0HkuwPs"
   },
   "source": [
    "### Save valid directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rfgi2wPeuy0l",
   "metadata": {
    "id": "Rfgi2wPeuy0l"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/valid.zip /content/garbage_classification_TrainValidTest/valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YEiPqicE3SOv",
   "metadata": {
    "id": "YEiPqicE3SOv"
   },
   "source": [
    "## Save test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00TsaCNs3Vge",
   "metadata": {
    "id": "00TsaCNs3Vge"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/test.zip /content/garbage_classification_TrainValidTest/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c",
   "metadata": {
    "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c"
   },
   "source": [
    "# Train CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc62474-9df5-4c7d-95ab-f24e06263167",
   "metadata": {
    "id": "edc62474-9df5-4c7d-95ab-f24e06263167"
   },
   "source": [
    "## Create train and valid datagenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
    "outputId": "51195e1e-96d7-443e-8103-30eae0f224ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26978 images belonging to 6 classes.\n",
      "Found 4816 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(300, 300))\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1",
   "metadata": {
    "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VOeyt-j4AwnF",
   "metadata": {
    "id": "VOeyt-j4AwnF"
   },
   "source": [
    "### Take into account the imbalance of garbage classes of the studied dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ajuBi4RhH-6G",
   "metadata": {
    "id": "ajuBi4RhH-6G"
   },
   "source": [
    "https://stackoverflow.com/questions/69783897/compute-class-weight-function-issue-in-sklearn-library-when-used-in-keras-cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voXk2zc0A5sz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voXk2zc0A5sz",
    "outputId": "98c8c0b7-3e24-4ec3-9ddb-3fcf56744e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 1.0461454940282302, 1: 0.8407504363001745, 2: 1.0260915867944622, 3: 0.7089771891096395, 4: 0.8727355072463768, 5: 3.0881410256410255}\n"
     ]
    }
   ],
   "source": [
    "# Get the true labels for the test data\n",
    "true_labels = train_generator.classes\n",
    "\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     classes = np.unique(true_labels),\n",
    "                                     y = true_labels)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
    "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
    "\n",
    "# Print the class weights\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xtCi21DCJdPV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xtCi21DCJdPV",
    "outputId": "abb149bc-5110-4b80-e719-fbcc510ff810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(true_labels) = 26978\n",
      "true_labels = [0 0 0 ... 5 5 5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(f\"len(class_labels) = {len(class_labels)}\")\\nprint(f\"class_labels = {class_labels}\")\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"len(true_labels) = {len(true_labels)}\")\n",
    "print(f\"true_labels = {true_labels}\")\n",
    "\n",
    "\"\"\"\n",
    "print(f\"len(class_labels) = {len(class_labels)}\")\n",
    "print(f\"class_labels = {class_labels}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jY64rbItA8lz",
   "metadata": {
    "id": "jY64rbItA8lz"
   },
   "source": [
    "### Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30815f75-7eb4-484e-bf11-9c03f9394b89",
   "metadata": {
    "id": "30815f75-7eb4-484e-bf11-9c03f9394b89"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
    "outputId": "e74334b5-5cae-4f92-9e12-977bb51a5164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 149, 149, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 73, 73, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 71, 71, 128)       73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 645248)            0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               82591872  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82685894 (315.42 MB)\n",
      "Trainable params: 82685894 (315.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afca06-7431-4884-9c44-60d418f40731",
   "metadata": {
    "id": "b0afca06-7431-4884-9c44-60d418f40731"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\"\"\"\n",
    "model_checkpoint_callback = ModelCheckpoint('/content/models/new_augmented_model.h5', monitor='val_accuracy',\n",
    "                                            mode='max', verbose=1, save_best_only=True)\n",
    "\"\"\"\n",
    "my_callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1",
   "metadata": {
    "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
    "outputId": "7e997708-77fd-49f6-93df-1af9806d9bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  6/422 [..............................] - ETA: 1:22 - loss: 4.8958 - accuracy: 0.1927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0799s vs `on_train_batch_end` time: 0.0973s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 138s 320ms/step - loss: 1.7726 - accuracy: 0.3921 - val_loss: 1.4648 - val_accuracy: 0.5044\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 142s 336ms/step - loss: 1.3622 - accuracy: 0.4816 - val_loss: 1.3810 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 146s 345ms/step - loss: 1.2876 - accuracy: 0.5229 - val_loss: 1.3790 - val_accuracy: 0.5484\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 143s 338ms/step - loss: 1.2294 - accuracy: 0.5499 - val_loss: 1.3649 - val_accuracy: 0.5683\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 143s 339ms/step - loss: 1.1855 - accuracy: 0.5742 - val_loss: 1.3077 - val_accuracy: 0.5791\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 137s 324ms/step - loss: 1.1372 - accuracy: 0.5954 - val_loss: 1.3453 - val_accuracy: 0.5866\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 143s 340ms/step - loss: 1.1051 - accuracy: 0.6118 - val_loss: 1.3399 - val_accuracy: 0.5914\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 145s 343ms/step - loss: 1.0860 - accuracy: 0.6273 - val_loss: 1.3232 - val_accuracy: 0.6055\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 143s 339ms/step - loss: 1.0311 - accuracy: 0.6482 - val_loss: 1.3514 - val_accuracy: 0.5876\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 144s 340ms/step - loss: 1.0087 - accuracy: 0.6642 - val_loss: 1.3102 - val_accuracy: 0.5939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=[early_stopping_callback, my_callback],\n",
    "                    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LUgm4rKtYRO-",
   "metadata": {
    "id": "LUgm4rKtYRO-"
   },
   "source": [
    "#### Display results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eF1vdtTGNFzK",
   "metadata": {
    "id": "eF1vdtTGNFzK"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UQ2V7808YaCu",
   "metadata": {
    "id": "UQ2V7808YaCu"
   },
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YlTY86axYgM4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlTY86axYgM4",
    "outputId": "24308e8d-7ee9-41e0-c85e-00462d6eba1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
    "\n",
    "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "\n",
    "# Load and preprocess test data using the generator\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(300, 300),\n",
    "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
    "\n",
    "# Get the true labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the class labels for the test data\n",
    "class_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qulBKP_KYkl2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qulBKP_KYkl2",
    "outputId": "bda4d7d7-8b8d-4de1-c4e9-840086feac27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PADFi4BpYprH",
   "metadata": {
    "id": "PADFi4BpYprH"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CNNe2YSdYtyN",
   "metadata": {
    "id": "CNNe2YSdYtyN"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "# sns.set(font_scale=1.2)  # Adjust font size for better visualization\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('/content/graphs/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PW2i3j4kYxQk",
   "metadata": {
    "id": "PW2i3j4kYxQk"
   },
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EbxZEQ_iYwsb",
   "metadata": {
    "id": "EbxZEQ_iYwsb"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/6_augmentation_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fFKojdI8Y7h9",
   "metadata": {
    "id": "fFKojdI8Y7h9"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/5_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fghIDHP3LUOB",
   "metadata": {
    "id": "fghIDHP3LUOB"
   },
   "source": [
    "### Train the CNN model using Transfer Learning (ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HtK1_C35Rcjy",
   "metadata": {
    "id": "HtK1_C35Rcjy"
   },
   "source": [
    "#### Example from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B2Rv64TmLZtY",
   "metadata": {
    "id": "B2Rv64TmLZtY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aTgy37lHRbwC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTgy37lHRbwC",
    "outputId": "8906f290-ed81-45f7-c702-8407aff0f384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2276 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = '/content/garbage classification/Garbage classification'\n",
    "valid_path = '/content/garbage classification/Garbage classification'\n",
    "\n",
    "\n",
    "# extract images to training set by applying data preprocessing and data augmentation\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.1).flow_from_directory(\n",
    "    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
    "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n",
    "\n",
    "\n",
    "# extract images to validation set\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    validation_split=0.1).flow_from_directory(\n",
    "    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
    "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ao_b4zb-Pj20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ao_b4zb-Pj20",
    "outputId": "f94ea1a6-04b8-4193-b667-8f63519df217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234698864/234698864 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59489030 (226.93 MB)\n",
      "Trainable params: 1116806 (4.26 MB)\n",
      "Non-trainable params: 58372224 (222.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Load pre-trained ResNet50 model without the top classification layers\n",
    "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SHAPE))\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
    "# during training inorder to extract features\n",
    "base_model.trainable=False\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# add densely-connected NN layer with 512 hidden units\n",
    "model.add(Dense(units=512, activation='relu'))  # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 6 hidden units\n",
    "model.add(Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htp1h_lJEYro",
   "metadata": {
    "id": "htp1h_lJEYro"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yrQZpYujSJKX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "yrQZpYujSJKX",
    "outputId": "7829ae9a-27dc-4f84-80f6-93619a0114c6"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "   train_batches,\n",
    "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
    "    epochs=20,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [es, mc],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrDhIooEWnck",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "UrDhIooEWnck",
    "outputId": "5dcfd583-ffc2-4b7d-d153-f88e36ef4c43"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDSd0Q5aWwrd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDSd0Q5aWwrd",
    "outputId": "0475487a-160b-4bdc-be15-7557d5a0573a"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/4_resnet152_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXM8zfJlW5eG",
   "metadata": {
    "id": "oXM8zfJlW5eG"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/4_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OX3lcwhlTuKn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX3lcwhlTuKn",
    "outputId": "ce764e3f-dfc8-4a65-810a-a8336fb08191"
   },
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "base_model.trainable=True\n",
    "history = model.fit_generator(\n",
    "   train_batches,\n",
    "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
    "    epochs=10,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [es, mc],)\n",
    "\n",
    "loss.extend(history.history['loss'])\n",
    "validation_loss.extend(history.history['val_loss'])\n",
    "accuracy.extend(history.history['accuracy'])\n",
    "validation_accuracy.extend(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GieDQ47P5iUP",
   "metadata": {
    "id": "GieDQ47P5iUP"
   },
   "source": [
    "#### Training by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-wulntQT5piR",
   "metadata": {
    "id": "-wulntQT5piR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dFsesqr76lpF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFsesqr76lpF",
    "outputId": "70c2a6eb-906c-4451-83ca-fee4776050f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26978 images belonging to 6 classes.\n",
      "Found 4816 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size=(224, 224)\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = datagen.flow_from_directory(directory=train_dir_path,\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              target_size=target_size)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(directory=valid_dir_path,\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xJ7XI70_QAj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xJ7XI70_QAj",
    "outputId": "0b601e08-0dca-4fd1-e935-13c7e5debb83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_generator.samples/train_generator.batch_size = 843.0625\n",
      "valid_generator.samples/valid_generator.batch_size = 150.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_generator.samples/train_generator.batch_size = {train_generator.samples/train_generator.batch_size}\")\n",
    "print(f\"valid_generator.samples/valid_generator.batch_size = {valid_generator.samples/valid_generator.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UZmQv4t9JON4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZmQv4t9JON4",
    "outputId": "ea63ffca-9df3-47fa-857b-da4abc3c0dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 1.0461454940282302, 1: 0.8407504363001745, 2: 1.0260915867944622, 3: 0.7089771891096395, 4: 0.8727355072463768, 5: 3.0881410256410255}\n"
     ]
    }
   ],
   "source": [
    "# Get the true labels for the test data\n",
    "true_labels = train_generator.classes\n",
    "\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     classes = np.unique(true_labels),\n",
    "                                     y = true_labels)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
    "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
    "\n",
    "# Print the class weights\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n9RRgj8__Iig",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9RRgj8__Iig",
    "outputId": "84c80dba-d9eb-443c-f72d-1345fa919b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234698864/234698864 [==============================] - 12s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59489030 (226.93 MB)\n",
      "Trainable params: 1116806 (4.26 MB)\n",
      "Non-trainable params: 58372224 (222.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# import the convolution base of the VGG16 model with pre-trained weights\n",
    "base_model = tf.keras.applications.resnet.ResNet152(input_shape=IMG_SHAPE,\n",
    "                                        include_top=False,\n",
    "                                        weights='imagenet')\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
    "# during training inorder to extract features\n",
    "base_model.trainable=False\n",
    "\n",
    "# add VGG16 convolution base to initialize sequential model\n",
    "model.add(base_model)\n",
    "\n",
    "# add global average pooling layer\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add densely-connected NN layer with 512 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))  # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 6 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CxDCpUZnPIEK",
   "metadata": {
    "id": "CxDCpUZnPIEK"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fgL8J-XD5x5Q",
   "metadata": {
    "id": "fgL8J-XD5x5Q"
   },
   "outputs": [],
   "source": [
    "my_callback = myCallback()\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "# model_checkpoint_callback = ModelCheckpoint('VGG152_Garbage_Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCD3JtLzGj9h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCD3JtLzGj9h",
    "outputId": "859d0cb9-16aa-455f-a0b3-74063cc9bfd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "843/843 [==============================] - 289s 327ms/step - loss: 0.5051 - accuracy: 0.8197 - val_loss: 0.3527 - val_accuracy: 0.8833\n",
      "Epoch 2/100\n",
      "843/843 [==============================] - 270s 320ms/step - loss: 0.1635 - accuracy: 0.9444 - val_loss: 0.3103 - val_accuracy: 0.8951\n",
      "Epoch 3/100\n",
      "843/843 [==============================] - 270s 320ms/step - loss: 0.0902 - accuracy: 0.9713 - val_loss: 0.2824 - val_accuracy: 0.9074\n",
      "Epoch 4/100\n",
      "843/843 [==============================] - 267s 317ms/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.2991 - val_accuracy: 0.9111\n",
      "Epoch 5/100\n",
      "843/843 [==============================] - 264s 313ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.2976 - val_accuracy: 0.9097\n",
      "Epoch 6/100\n",
      "844/843 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9906\n",
      "Reached 99% accuracy so cancelling training!\n",
      "843/843 [==============================] - 265s 315ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 0.3286 - val_accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "    epochs=100,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stopping_callback, my_callback],\n",
    "    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sgY_Z1HKZJrP",
   "metadata": {
    "id": "sgY_Z1HKZJrP"
   },
   "source": [
    "##### Display the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DS8ldXfkZOMG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "DS8ldXfkZOMG",
    "outputId": "14787990-40ef-4e26-a317-b38a496a3670"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2QKso6tIZVoc",
   "metadata": {
    "id": "2QKso6tIZVoc"
   },
   "source": [
    "##### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htnK0nJuZY9D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htnK0nJuZY9D",
    "outputId": "9bb7000e-adc7-408a-c2df-ec94312b4994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
    "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load and preprocess test data using the generator\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
    "\n",
    "# Get the true labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the class labels for the test data\n",
    "class_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kCsaptjeZve_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCsaptjeZve_",
    "outputId": "274d1fa1-c7d5-4849-ee1a-92113a5733ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 318ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cardboard       1.00      0.90      0.95        41\n",
      "       glass       0.92      0.94      0.93        51\n",
      "       metal       0.88      0.88      0.88        41\n",
      "       paper       0.94      0.97      0.95        60\n",
      "     plastic       0.98      0.92      0.95        49\n",
      "       trash       0.78      1.00      0.88        14\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.92      0.93      0.92       256\n",
      "weighted avg       0.93      0.93      0.93       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iufZXvZ_ZylX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "iufZXvZ_ZylX",
    "outputId": "654f9d51-abda-41bb-e8cc-36350d50ab43"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('/content/graphs/resnet152_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4IiDoxTmZ2D3",
   "metadata": {
    "id": "4IiDoxTmZ2D3"
   },
   "source": [
    "##### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2EPzdHJ6P8Lh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EPzdHJ6P8Lh",
    "outputId": "36ba91a1-574f-49c5-a52d-8e29279cf387"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/6_resnet152_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BtkE5HNuZ7aD",
   "metadata": {
    "id": "BtkE5HNuZ7aD"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/6_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a19fa0e8-6098-41f8-9901-09e18d152bce",
    "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
    "QtwmTbl9PK5u",
    "ff87ed02-b353-41ff-a831-495238d0361b",
    "jH-5MYFlPiGG",
    "oewmXvvYPoS2",
    "cwXhFVwTUYPI",
    "a9d3365a-13fe-480a-b5a1-a73191acca39",
    "e59dd5b1-3054-4e06-a376-42362774907a",
    "158972c1-8c86-45a5-a767-c7b37b1b6608",
    "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
    "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
    "50d2c56e-aac4-4403-a89c-177d7584ca76",
    "rMRZMug1axTK",
    "SVoc99d2bFV6",
    "r1oj75sjbMPq",
    "Nq6an5m7bYeU",
    "xN_CBfSMbsNy",
    "wTLkX5eyb3ny",
    "URnp4hbnb_kD",
    "b8QlRMm8cQHR",
    "OvIN0bJrdWjL",
    "auf2c59BdgWR",
    "bkNIrE5i9yff",
    "5xs5E4lc92xt",
    "rwEBRaCz-A13",
    "QQTigweq-QHk",
    "Wm0HzUnim4GY",
    "S1YCpPVUryl2",
    "iDPvcoMgseEW",
    "NdonW8OusrtF",
    "Lxd7HGmlsyRc",
    "oZNmeaEis_M9",
    "PLEmuhGMtKR2",
    "3CXocmX_tJRk",
    "lADCJADjtvxU",
    "xPP3kC0vuLgD",
    "Y1qLJ2g506nN",
    "5h2Ggtv72gdt",
    "m0g3W4Fr6lR2",
    "PW2i3j4kYxQk",
    "fghIDHP3LUOB"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
