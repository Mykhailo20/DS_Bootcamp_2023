{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b",
      "metadata": {
        "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b"
      },
      "source": [
        "### Link to the dataset: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the Kaggle API key file (kaggle.json) that you downloaded from Kaggle\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded API key to the required directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RKCaaWRKQye8",
        "outputId": "c2464dad-d3cf-4503-92b6-64aca2e6211d"
      },
      "id": "RKCaaWRKQye8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fff0815b-59dc-4778-ac6d-895618e599c8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fff0815b-59dc-4778-ac6d-895618e599c8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "143vln3rRExD"
      },
      "id": "143vln3rRExD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d asdasdasasdas/garbage-classification"
      ],
      "metadata": {
        "id": "CRRvWPlURJXy"
      },
      "id": "CRRvWPlURJXy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip garbage-classification.zip"
      ],
      "metadata": {
        "id": "qFh2FFk3RQID"
      },
      "id": "qFh2FFk3RQID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rembg"
      ],
      "metadata": {
        "id": "qW8DMdNSxlEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea8ca89-e58e-464a-f523-623bca24a085"
      },
      "id": "qW8DMdNSxlEF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rembg\n",
            "  Downloading rembg-2.0.50-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.23.5)\n",
            "Collecting onnxruntime (from rembg)\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from rembg) (4.8.1.78)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from rembg) (9.4.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from rembg) (1.7.0)\n",
            "Collecting pymatting (from rembg)\n",
            "  Downloading PyMatting-1.1.10-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from rembg) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rembg) (4.66.1)\n",
            "Collecting coloredlogs (from onnxruntime->rembg)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (1.12)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (3.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (2.31.0)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting->rembg) (0.56.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2023.7.22)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->rembg)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->rembg) (1.3.0)\n",
            "Installing collected packages: humanfriendly, pymatting, coloredlogs, onnxruntime, rembg\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.0 pymatting-1.1.10 rembg-2.0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c",
      "metadata": {
        "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "from rembg import remove\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19fa0e8-6098-41f8-9901-09e18d152bce",
      "metadata": {
        "id": "a19fa0e8-6098-41f8-9901-09e18d152bce"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
      "metadata": {
        "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "979887c5-9518-4f9b-860a-9f6e586085fd",
      "metadata": {
        "id": "979887c5-9518-4f9b-860a-9f6e586085fd"
      },
      "outputs": [],
      "source": [
        "def create_train_valid_test_dirs(root_path, subdir_names, train_valid_test_names=['train', 'valid', 'test']):\n",
        "    \"\"\" Function for creating separate folders that contain data for training, validation and testing of the model\n",
        "    Args:\n",
        "        1) root_path - the path to the parent folder in which you want to create subfolders\n",
        "        2) subdir_names - a list of label class names (subfolders with the specified names will be created in each of the train, valid, and test folders)\n",
        "        3) train_valid_test_names - a list of names of training, validation and test samples\n",
        "    Returns:\n",
        "        None; but creates folders\n",
        "    \"\"\"\n",
        "    parent_directories = []\n",
        "    for dir_name in train_valid_test_names:\n",
        "        parent_directories.append(os.path.join(root_path, dir_name))\n",
        "\n",
        "    for directory in parent_directories:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "        for subdirectory in subdir_names:\n",
        "            subdir_name = os.path.join(directory + '/', subdirectory)\n",
        "            if not os.path.exists(subdir_name):\n",
        "                os.makedirs(subdir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d",
      "metadata": {
        "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d"
      },
      "outputs": [],
      "source": [
        "def split_data(source_dir_path, train_dir_path, valid_dir_path, test_dir_path, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
        "    \"\"\" Function to split the files of the specified folder into training, validation and test samples by copying\n",
        "    the files from source_dir_path to the corresponding folders\n",
        "    Args:\n",
        "        1) source_dir_path - the path to the folder containing the original data to be split into train/valid/test\n",
        "        2) train_dir_path - the path to the folder that will contain the training data\n",
        "        3) valid_dir_path - the path to the folder that will contain the validation data\n",
        "        4) test_dir_path - the path to the folder that will contain the test data\n",
        "        5) train_test_split - the ratio between training and test samples ([0; 1])\n",
        "        6) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
        "        7) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
        "    Returns:\n",
        "        None, but split the files into training, validation and test samples\n",
        "    \"\"\"\n",
        "    fnames = os.listdir(source_dir_path)\n",
        "\n",
        "    processed_fnames = []\n",
        "    for file_name in fnames:\n",
        "        if os.path.getsize(os.path.join(source_dir_path, file_name)) > 0:\n",
        "            processed_fnames.append(file_name)\n",
        "        else:\n",
        "            print(f'{file_name} is zero length, so ignoring.')\n",
        "\n",
        "    if random_sample:\n",
        "        processed_fnames = random.sample(processed_fnames, len(processed_fnames))\n",
        "\n",
        "    split_index = int(train_test_split * len(processed_fnames))\n",
        "    train_valid_files = processed_fnames[:split_index]\n",
        "    test_files = processed_fnames[split_index:]\n",
        "\n",
        "    split_index = int(train_valid_split * len(train_valid_files))\n",
        "    train_files = train_valid_files[:split_index]\n",
        "    valid_files = train_valid_files[split_index:]\n",
        "\n",
        "    # Copy training files\n",
        "    for file in train_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(train_dir_path, file)\n",
        "        copyfile(source, destination)\n",
        "\n",
        "    # Copy validation files\n",
        "    for file in valid_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(valid_dir_path, file)\n",
        "        copyfile(source, destination)\n",
        "\n",
        "    # Copy test files\n",
        "    for file in test_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(test_dir_path, file)\n",
        "        copyfile(source, destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "da75baf0-c207-4220-bcb3-2f936d00049d",
      "metadata": {
        "id": "da75baf0-c207-4220-bcb3-2f936d00049d"
      },
      "outputs": [],
      "source": [
        "def split_class_data(source_dir_path, train_valid_test_paths, class_dir_name, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
        "    \"\"\" Function for dividing the data of one label class into train/valid/test\n",
        "    Args:\n",
        "        1) source_dir_path - the path to the folder containing the original data of all label classes which needs to be splitted into train/valid/test;\n",
        "        2) train_valid_test_paths - the list of paths to the folders of training, validation and test samples\n",
        "        (the paths are specified in this order: train, valid, test)\n",
        "        3) class_dir_name - the name of the folder that contains the label class data\n",
        "        4) train_test_split - the ratio between training and test samples ([0; 1])\n",
        "        5) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
        "        6) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
        "    Returns:\n",
        "        None, but split the files of label class into training, validation and test samples\n",
        "    \"\"\"\n",
        "    train_dir_path_class = os.path.join(train_valid_test_paths[0], class_dir_name)\n",
        "    valid_dir_path_class = os.path.join(train_valid_test_paths[1], class_dir_name)\n",
        "    test_dir_path_class = os.path.join(train_valid_test_paths[2], class_dir_name)\n",
        "    source_dir_path_class = os.path.join(source_dir_path, class_dir_name)\n",
        "    split_data(source_dir_path=source_dir_path_class, train_dir_path=train_dir_path_class, valid_dir_path=valid_dir_path_class,\n",
        "               test_dir_path=test_dir_path_class,\n",
        "               train_test_split=train_test_split, train_valid_split=train_valid_split, random_sample=random_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display images"
      ],
      "metadata": {
        "id": "QtwmTbl9PK5u"
      },
      "id": "QtwmTbl9PK5u"
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(img, title=None):\n",
        "    \"\"\" Function to display an image\n",
        "    Args:\n",
        "        1) img - image object\n",
        "        2) title - the title that will be displayed above the image\n",
        "    Returns:\n",
        "        None; but displays an image\n",
        "    \"\"\"\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uDa_N5C5PKbQ"
      },
      "id": "uDa_N5C5PKbQ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_original_augmented_img(original_img, augmented_img, original_title=None, augmented_title=None):\n",
        "    \"\"\" Function to display the original and augmented image on the same graph\n",
        "    Args:\n",
        "        1) original_img - object of the original image\n",
        "        2) augmented_img - augmented image object\n",
        "        3) original_title - title for the original image\n",
        "        4) augmented_title - title for the augmented image\n",
        "    Returns:\n",
        "        None; but displays images\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title(original_title)\n",
        "\n",
        "    axes[1].imshow(augmented_img)\n",
        "    axes[1].set_title(augmented_title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GnJCHNEDPWLG"
      },
      "id": "GnJCHNEDPWLG",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff87ed02-b353-41ff-a831-495238d0361b",
      "metadata": {
        "tags": [],
        "id": "ff87ed02-b353-41ff-a831-495238d0361b"
      },
      "source": [
        "## Display data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_display_image(root_path, image_name, title=None):\n",
        "    \"\"\" Function to display an image\n",
        "    Args:\n",
        "        1) root_path - the path to the folder that contains the image\n",
        "        2) image_name - the name of the image\n",
        "        3) title - the title that will be displayed above the image\n",
        "    Returns:\n",
        "        None; but displays an image\n",
        "    \"\"\"\n",
        "    img = cv2.imread(os.path.join(root_path, image_name))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_cc_OjlNRHcM"
      },
      "id": "_cc_OjlNRHcM",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4",
      "metadata": {
        "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4"
      },
      "outputs": [],
      "source": [
        "def display_pie_chart(df, column_name, title=None, column_contains_count=False, filename=None):\n",
        "    \"\"\" Function to display the percentage ratio of column (with the name column_name) content\n",
        "    Args:\n",
        "        1) df - the original dataframe that contains the required information\n",
        "        2) column_name - the name of the df dataframe column whose percentage values are to be found\n",
        "        3) title - the title of the graph\n",
        "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
        "        5) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    Returns:\n",
        "        None, but plots graph\n",
        "    \"\"\"\n",
        "    # Calculate the percentage of each activity in original_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_df = df[column_name] / sum(df[column_name])\n",
        "    else:\n",
        "        activity_percentages_df = df[column_name].value_counts(normalize=True) * 100\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot pie chart for df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    plt.pie(activity_percentages_df, labels=activity_percentages_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_pie_charts(first_df, second_df, column, column_contains_count=False, first_chart_title='First DataFrame', second_chart_title='Second DataFrame', filename=None):\n",
        "    \"\"\"Function for displaying the ratio of column content between two dataframes in the form of pie charts\n",
        "    Args:\n",
        "        1) first_df - the original dataframe that contains the required information\n",
        "        2) second_df - a dataframe that contains the results of windowing\n",
        "        3) column - the name of the dataframe column whose percentage values are to be found\n",
        "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
        "        5) first_chart_title - the title for the first pie chart\n",
        "        6) second_chart_title - the title for the second pie chart\n",
        "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    Returns:\n",
        "        None; just builds a pie chart to display the ratio of column contents between two dataframes\n",
        "    \"\"\"\n",
        "    # Calculate the percentage of each activity in first_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_first_df = first_df[column] / sum(first_df[column]) * 100\n",
        "    else:\n",
        "        activity_percentages_first_df = first_df[column].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Calculate the percentage of each activity in second_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_second_df = second_df[column] / sum(second_df[column]) * 100\n",
        "    else:\n",
        "        activity_percentages_second_df = second_df[column].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Create subplots for pie charts\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot pie chart for df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    axes[0].pie(activity_percentages_first_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    axes[0].set_title(first_chart_title)\n",
        "\n",
        "    # Plot pie chart for windowed_df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    axes[1].pie(activity_percentages_second_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    axes[1].set_title(second_chart_title)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform image augmentation using ImageDataGenerator"
      ],
      "metadata": {
        "id": "jH-5MYFlPiGG"
      },
      "id": "jH-5MYFlPiGG"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ImageDataGen_image(imageDataGenerator, image):\n",
        "  \"\"\" Function that returns an image augmented with imageDataGenerator\n",
        "  Args:\n",
        "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
        "    2) image - an image passed as a numpy array\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  x = image.copy()\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  for batch in imageDataGenerator.flow(x, batch_size=1):\n",
        "      augmented_image=batch[0].copy().astype(np.uint8)\n",
        "      break\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "0iT7IBC51ely"
      },
      "id": "0iT7IBC51ely",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_ImageDataGen_augmentation(imageDataGenerator, images, image_filenames, target_size,\n",
        "                                      augm_prefix, num_augm_images=3, augm_images_dir_path=None,\n",
        "                                      save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) imageDataGenerator - ImageDataGenerator class object\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "    augmented_index = 0\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        x = img.copy()\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1):\n",
        "            i += 1\n",
        "            if i > num_augm_images:\n",
        "                augmented_index = 0\n",
        "                break\n",
        "\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "\n",
        "            augmented_index += 1\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "                # tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(batch[0].copy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=batch[0].copy().astype(np.uint8),\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "kdVdixQDPhmW"
      },
      "id": "kdVdixQDPhmW",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform image augmentation using CV2"
      ],
      "metadata": {
        "id": "oewmXvvYPoS2"
      },
      "id": "oewmXvvYPoS2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation functions"
      ],
      "metadata": {
        "id": "5PxQiefcUULF"
      },
      "id": "5PxQiefcUULF"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_width_shift_image(image, width_shift_fraction):\n",
        "    \"\"\" Function for performing width_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) width_shift_fraction - offset value ([-1; 1])\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Get the height and width of the image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Calculate the height shift value\n",
        "    width_shift = int(height * width_shift_fraction)\n",
        "\n",
        "    # Calculate the new y-coordinate for height shift\n",
        "    y_shifted = height // 2 + width_shift\n",
        "\n",
        "    # Calculate the rotation matrix for height shift\n",
        "    shift_matrix = np.float32([[1, 0, 0], [0, 1, width_shift]])\n",
        "\n",
        "    # Apply the height shift to the image using warpAffine\n",
        "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
        "    return changed_image"
      ],
      "metadata": {
        "id": "l42CveFAPquW"
      },
      "id": "l42CveFAPquW",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_height_shift_image(image, height_shift_fraction):\n",
        "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) height_shift_fraction - offset value ([-1; 1])\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Get the height and width of the image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Calculate the height shift value\n",
        "    height_shift = int(width * height_shift_fraction)\n",
        "\n",
        "    # Calculate the new x-coordinate for height shift\n",
        "    x_shifted = width // 2 + height_shift\n",
        "\n",
        "    # Calculate the rotation matrix for height shift\n",
        "    shift_matrix = np.float32([[1, 0, height_shift], [0, 1, 0]])\n",
        "\n",
        "    # Apply the height shift to the image using warpAffine\n",
        "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
        "    return changed_image"
      ],
      "metadata": {
        "id": "yjmv3HHoPtqd"
      },
      "id": "yjmv3HHoPtqd",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_brightness_augmentation_image(image, brightness_range=(0.5, 1.5)):\n",
        "    # Convert the image to HSV color space\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Generate a random brightness factor within the specified range\n",
        "    brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
        "\n",
        "    # Adjust the brightness by scaling the V channel\n",
        "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)\n",
        "\n",
        "    # Convert the image back to the original color space (BGR)\n",
        "    augmented_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "eG8FTDtWPwGe"
      },
      "id": "eG8FTDtWPwGe",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_contrast_augmentation_image(image, contrast_factor):\n",
        "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) contrast_factor - adjusts the contrast of the image by applying CLAHE; possible values: [1.0; 4.0]\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Convert the image to LAB color space\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # Split the LAB image into L, A, and B channels\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=contrast_factor, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l)\n",
        "\n",
        "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
        "    limg = cv2.merge((cl, a, b))\n",
        "\n",
        "    # Convert the LAB image back to BGR color space\n",
        "    contrast_augmented_image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return contrast_augmented_image"
      ],
      "metadata": {
        "id": "2tYCvwyDPx3V"
      },
      "id": "2tYCvwyDPx3V",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hsv_image(image, hue_shift, saturation_scale=1, value_scale=1):\n",
        "    \"\"\" Function to change the color tone of the image when switching to the HSV model\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) hue_shift - the value of the Hue parameter of the hsv model; possible values: [0; 179] (OpenCV)\n",
        "        3) saturation_scale - coefficient by which the Saturation parameter of the HSV model will be multiplied\n",
        "        4) value_scale - coefficient by which the Value parameter of the HSV model will be multiplied\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Convert the original image to the HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Apply the hue shift to the hue channel\n",
        "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
        "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_scale, 0, 255)\n",
        "    hsv_image[:, :, 2] = np.clip(hsv_image[:, :, 2] * value_scale, 0, 255)\n",
        "\n",
        "    # Convert the image back to the RGB color space\n",
        "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "KqcGVI2NP1j-"
      },
      "id": "KqcGVI2NP1j-",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_noisy_image(image, mean=1, std_dev=0.7):\n",
        "    \"\"\" Function for adding random noise to the image 'image'\n",
        "    Args:\n",
        "        1) image - an image passed as a numpy array\n",
        "        2) mean - the mean value of the noise\n",
        "        3) std_dev - the standard deviation of the noise (the larger the std_dev, the more intense the noise will be)\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    noise = np.random.normal(mean, std_dev, image.shape).astype('uint8')\n",
        "    augmented_image = cv2.add(image, noise)\n",
        "\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "GYnBKRn51YfT"
      },
      "id": "GYnBKRn51YfT",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_background(input_path, output_path=None):\n",
        "    \"\"\" Function to remove the background from the image\n",
        "    Args:\n",
        "      1) input_path - the path to the image whose background should be removed\n",
        "      2) output_path - the path to save an image without a background\n",
        "    Returns:\n",
        "      Image without background\n",
        "    \"\"\"\n",
        "     # Processing the image\n",
        "    input_image = Image.open(input_path)\n",
        "\n",
        "    # Removing the background from the given Image\n",
        "    output_image = remove(input_image)\n",
        "\n",
        "    # Convert the output image to RGB mode (removing transparency)\n",
        "    output_image = output_image.convert(\"RGB\")\n",
        "\n",
        "    if output_path:\n",
        "      # Save the image with the background removed\n",
        "      output_image.save(output_path)\n",
        "    return output_image"
      ],
      "metadata": {
        "id": "mGnfBhhQ1jJI"
      },
      "id": "mGnfBhhQ1jJI",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_background_image(image, background_image, source_path, image_name, no_background_output_path=None):\n",
        "  \"\"\" Function to replace the background of the original image with the background image background_image\n",
        "  Args:\n",
        "    1) image - an image passed as a numpy array\n",
        "    2) background_image - a background image passed as a numpy array\n",
        "    3) source_path - path to image 'image'\n",
        "    4) image_name - name of the image 'image'\n",
        "    5) no_background_output_path - the path (along with the image name) to store the original image without the background\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  if no_background_output_path is not None:\n",
        "    pil_image = remove_background(input_path=os.path.join(source_path, image_name),\n",
        "                    output_path=os.path.join(no_background_output_path, image_name))\n",
        "  else:\n",
        "    pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
        "\n",
        "  augmented_image = background_image.copy()\n",
        "\n",
        "  # Convert PIL image to OpenCV format (NumPy array)\n",
        "  image_without_background = np.array(pil_image)\n",
        "\n",
        "  mask = cv2.cvtColor(image_without_background, cv2.COLOR_BGR2GRAY)\n",
        "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "  garbage_area = cv2.bitwise_and(image_without_background, image_without_background, mask=mask)\n",
        "  background_area = cv2.bitwise_and(augmented_image, augmented_image, mask=mask_inv)\n",
        "  augmented_image = cv2.add(garbage_area, background_area)\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "LEuXuDQ51nfo"
      },
      "id": "LEuXuDQ51nfo",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmented_background_image(imageDataGenerator, image, background_image, source_path, image_name):\n",
        "  \"\"\" Function that returns a new augmented image (eg reduced in size) with a new background\n",
        "  Args:\n",
        "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
        "    2) image - an image passed as a numpy array\n",
        "    3) background_image - a background image passed as a numpy array\n",
        "    4) source_path -  path to image 'image'\n",
        "    5) image_name - name of the image 'image'\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
        "\n",
        "  # Convert PIL image to OpenCV format (NumPy array)\n",
        "  image_without_background = np.array(pil_image)\n",
        "\n",
        "  changed_image = get_ImageDataGen_image(imageDataGenerator=imageDataGenerator,\n",
        "                                         image=image_without_background)\n",
        "\n",
        "  mask = cv2.cvtColor(changed_image, cv2.COLOR_BGR2GRAY)\n",
        "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "  garbage_area = cv2.bitwise_and(changed_image, changed_image, mask=mask)\n",
        "  augmented_image = background_image.copy()\n",
        "  background_area = cv2.bitwise_and(augmented_image, augmented_image,\n",
        "                                  mask=mask_inv)\n",
        "  augmented_image = cv2.add(garbage_area, background_area)\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "zwbR-nZX1rJl"
      },
      "id": "zwbR-nZX1rJl",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation algorithms"
      ],
      "metadata": {
        "id": "cwXhFVwTUYPI"
      },
      "id": "cwXhFVwTUYPI"
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cv2_rotation_augmentation(rotation_range, images, image_filenames,\n",
        "                                      target_size, augm_prefix,\n",
        "                                      num_augm_images=3, augm_images_dir_path=None,\n",
        "                                      save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) rotation_range - the range (a list of two elements: [range_min; range_max]) in which the angle value will change linearly (depending on num_augm_images)\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "    height = target_size[0]\n",
        "    width = target_size[1]\n",
        "    angle_increment = int((rotation_range[1] - rotation_range[0]) / num_augm_images)\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        augmented_index = 0\n",
        "        angle = rotation_range[0]\n",
        "        for i in range(num_augm_images):\n",
        "            # Calculate the rotation matrix\n",
        "            rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
        "\n",
        "            # Apply the rotation to the image using warpAffine\n",
        "            augmented_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "            augmented_index += 1\n",
        "            angle += angle_increment\n",
        "            if angle == 0:\n",
        "                angle += angle_increment\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augm_images_dir_path, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augm_images_dir_path, augmented_image_name)\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "OBXdj3gTUbgd"
      },
      "id": "OBXdj3gTUbgd",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cv2_flip_augmentation(flip_code, images, image_filenames,\n",
        "                                  target_size, augm_prefix,\n",
        "                                  num_augm_images=3, augm_images_dir_path=None,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) flip_code - the type of flip augmentation to perform on the image: 0 - vertical, 1 - horizontal\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        augmented_index = 0\n",
        "        for i in range(num_augm_images):\n",
        "            augmented_image = cv2.flip(img.copy(), flip_code)\n",
        "\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "            augmented_index += 1\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "dAaU8XHhUeAG"
      },
      "id": "dAaU8XHhUeAG",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c",
      "metadata": {
        "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba",
      "metadata": {
        "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(history, strings, filename=None):\n",
        "    \"\"\"Function to plot graphs for two training history parameters (eg accuracy and loss)\n",
        "    Args:\n",
        "        1) history - model training history\n",
        "        2) strings - an array of names of history parameters (only the data of the first two history parameters specified in this array will be taken for graphing)\n",
        "        3) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].plot(history.history[strings[0]], label=strings[0])\n",
        "    axes[0].plot(history.history[f\"val_{strings[0]}\"], label=f\"val_{strings[0]}\")\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel(strings[0])\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(history.history[strings[1]], label=strings[1])\n",
        "    axes[1].plot(history.history[f\"val_{strings[1]}\"], label=f\"val_{strings[1]}\")\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel(strings[1])\n",
        "    axes[1].legend()\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(f\"{filename}.png\", bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "099e9f3d-af53-4f7d-92ac-f6347091c448"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "089707ba-256c-4e27-9a65-c764999f41ac",
      "metadata": {
        "id": "089707ba-256c-4e27-9a65-c764999f41ac"
      },
      "outputs": [],
      "source": [
        "source_path = '/content/Garbage classification/Garbage classification'\n",
        "\n",
        "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
        "source_path_glass = os.path.join(source_path, 'glass')\n",
        "source_path_metal = os.path.join(source_path, 'metal')\n",
        "source_path_paper = os.path.join(source_path, 'paper')\n",
        "source_path_plastic = os.path.join(source_path, 'plastic')\n",
        "source_path_trash = os.path.join(source_path, 'trash')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6808b080-50b3-423d-aca4-60fc14129e79",
      "metadata": {
        "id": "6808b080-50b3-423d-aca4-60fc14129e79"
      },
      "outputs": [],
      "source": [
        "cardboard_image_names = os.listdir(source_path_cardboard)\n",
        "glass_image_names = os.listdir(source_path_glass)\n",
        "metal_image_names = os.listdir(source_path_metal)\n",
        "paper_image_names = os.listdir(source_path_paper)\n",
        "plastic_image_names = os.listdir(source_path_plastic)\n",
        "trash_image_names = os.listdir(source_path_trash)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
        "outputId": "90f1b3ae-3d7b-4a74-aa67-76f85bc3cb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 403 images of cardboard.\n",
            "There are 501 images of glass.\n",
            "There are 410 images of metal.\n",
            "There are 594 images of paper.\n",
            "There are 482 images of plastic.\n",
            "There are 137 images of trash.\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {len(cardboard_image_names)} images of cardboard.\") # 403\n",
        "print(f\"There are {len(glass_image_names)} images of glass.\") # 501\n",
        "print(f\"There are {len(metal_image_names)} images of metal.\") # 410\n",
        "print(f\"There are {len(paper_image_names)} images of paper.\") # 594\n",
        "print(f\"There are {len(plastic_image_names)} images of plastic.\") # 482\n",
        "print(f\"There are {len(trash_image_names)} images of trash.\") # 137"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d3365a-13fe-480a-b5a1-a73191acca39",
      "metadata": {
        "id": "a9d3365a-13fe-480a-b5a1-a73191acca39"
      },
      "source": [
        "## Display classes distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
        "outputId": "2ceb8fbf-79c3-4db2-f479-05cacc0c2e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 403 images of cardboard.\n",
            "There are 501 images of glass.\n",
            "There are 410 images of metal.\n",
            "There are 594 images of paper.\n",
            "There are 482 images of plastic.\n",
            "There are 137 images of trash.\n"
          ]
        }
      ],
      "source": [
        "classes_representatives = {'cardboard': len(cardboard_image_names),\n",
        "                           'glass': len(glass_image_names),\n",
        "                           'metal': len(metal_image_names),\n",
        "                           'paper': len(paper_image_names),\n",
        "                           'plastic': len(plastic_image_names),\n",
        "                           'trash': len(trash_image_names)\n",
        "                          }\n",
        "for label_class in classes_representatives.keys():\n",
        "    print(f\"There are {classes_representatives[label_class]} images of {label_class}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
        "outputId": "63c8e93a-abbc-4fea-97aa-c0016531e3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  count\n",
              "0  cardboard    403\n",
              "1      glass    501\n",
              "2      metal    410\n",
              "3      paper    594\n",
              "4    plastic    482\n",
              "5      trash    137"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ad7c433-b003-4330-933c-1422eac89b91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glass</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plastic</td>\n",
              "      <td>482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>trash</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad7c433-b003-4330-933c-1422eac89b91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "classes_df = pd.DataFrame(list(classes_representatives.items()), columns=['class', 'count'])\n",
        "classes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95be70e4-b5f7-4d75-8f22-3523543856c1",
      "metadata": {
        "id": "95be70e4-b5f7-4d75-8f22-3523543856c1"
      },
      "outputs": [],
      "source": [
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize = (10, 5))\n",
        "sns.barplot(data=classes_df, x='class', y='count')\n",
        "plt.title('The number of representatives of the label class (Original dataset)')\n",
        "# plt.savefig('graphs/original_barplot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc",
      "metadata": {
        "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=classes_df, column_name='count', title='Percentage ratio between label classes (Original dataset)',\n",
        "                  column_contains_count=True) # filename='graphs/original_piechart'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e59dd5b1-3054-4e06-a376-42362774907a",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "e59dd5b1-3054-4e06-a376-42362774907a"
      },
      "source": [
        "## Display representatives of each class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
      "metadata": {
        "tags": [],
        "id": "158972c1-8c86-45a5-a767-c7b37b1b6608"
      },
      "source": [
        "### Cardboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d",
      "metadata": {
        "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d"
      },
      "outputs": [],
      "source": [
        "for cardboard_image_name in cardboard_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_cardboard, image_name=cardboard_image_name, title=cardboard_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
      "metadata": {
        "tags": [],
        "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74"
      },
      "source": [
        "### Glass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f",
      "metadata": {
        "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f"
      },
      "outputs": [],
      "source": [
        "for glass_image_name in glass_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_glass, image_name=glass_image_name, title=glass_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
      "metadata": {
        "tags": [],
        "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b"
      },
      "source": [
        "### Metal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d111dde7-c214-4c69-aa42-58c907e167d8",
      "metadata": {
        "id": "d111dde7-c214-4c69-aa42-58c907e167d8"
      },
      "outputs": [],
      "source": [
        "for metal_image_name in metal_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_metal, image_name=metal_image_name, title=metal_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
      "metadata": {
        "tags": [],
        "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac"
      },
      "source": [
        "### Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0095e9ea-86af-404e-969d-d077462c81b4",
      "metadata": {
        "id": "0095e9ea-86af-404e-969d-d077462c81b4"
      },
      "outputs": [],
      "source": [
        "for paper_image_name in paper_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_paper, image_name=paper_image_name, title=paper_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
      "metadata": {
        "tags": [],
        "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a"
      },
      "source": [
        "### Plastic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05",
      "metadata": {
        "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05"
      },
      "outputs": [],
      "source": [
        "for plastic_image_name in plastic_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_plastic, image_name=plastic_image_name, title=plastic_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
      "metadata": {
        "tags": [],
        "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452"
      },
      "source": [
        "### Trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6",
      "metadata": {
        "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6"
      },
      "outputs": [],
      "source": [
        "for trash_image_name in trash_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_trash, image_name=trash_image_name, title=trash_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "94b8c9cb-0be9-44f4-9952-beb639920617"
      },
      "source": [
        "# Split data into train, validation and test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39",
      "metadata": {
        "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39"
      },
      "source": [
        "## Create folders for train/valid/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0",
      "metadata": {
        "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0"
      },
      "outputs": [],
      "source": [
        "destination_path = '/content/garbage_classification_TrainValidTest/'\n",
        "\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "create_train_valid_test_dirs(root_path=destination_path, subdir_names=garbage_class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ce8b08-d600-431e-9365-395f20cf0402",
      "metadata": {
        "id": "70ce8b08-d600-431e-9365-395f20cf0402"
      },
      "source": [
        "## Split the data and save it in the appropriate folders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5"
      },
      "source": [
        "### Split classes data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
        "outputId": "56ec6127-0b8a-4cae-90ef-6fd5cb11eb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: train = 307\n",
            "cardboard: valid = 55\n",
            "cardboard: test = 41\n",
            "\n",
            "glass: train = 382\n",
            "glass: valid = 68\n",
            "glass: test = 51\n",
            "\n",
            "metal: train = 313\n",
            "metal: valid = 56\n",
            "metal: test = 41\n",
            "\n",
            "paper: train = 453\n",
            "paper: valid = 81\n",
            "paper: test = 60\n",
            "\n",
            "plastic: train = 368\n",
            "plastic: valid = 65\n",
            "plastic: test = 49\n",
            "\n",
            "trash: train = 104\n",
            "trash: valid = 19\n",
            "trash: test = 14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
        "\n",
        "for class_name in garbage_class_names:\n",
        "    split_class_data(source_dir_path=source_path, train_valid_test_paths=train_valid_test_paths,\n",
        "                 class_dir_name=class_name, train_test_split=0.9, train_valid_split=0.85, random_sample=False)\n",
        "\n",
        "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
        "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
        "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
        "\n",
        "    print(f\"{class_name}: train = {len(class_train_images)}\")\n",
        "    print(f\"{class_name}: valid = {len(class_valid_images)}\")\n",
        "    print(f\"{class_name}: test = {len(class_test_images)}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
      "metadata": {
        "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef"
      },
      "source": [
        "#### Check classes distribution after spliting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51",
      "metadata": {
        "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51"
      },
      "outputs": [],
      "source": [
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "classes_train_dict = {}\n",
        "classes_valid_dict = {}\n",
        "classes_test_dict = {}\n",
        "for class_name in garbage_class_names:\n",
        "    classes_train_dict[class_name] = 0\n",
        "    classes_valid_dict[class_name] = 0\n",
        "    classes_test_dict[class_name] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
        "outputId": "87c457d8-c029-4738-bf57-f94a0c89f428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes_train_dict = {'cardboard': 307, 'glass': 382, 'metal': 313, 'paper': 453, 'plastic': 368, 'trash': 104}\n",
            "classes_valid_dict = {'cardboard': 55, 'glass': 68, 'metal': 56, 'paper': 81, 'plastic': 65, 'trash': 19}\n",
            "classes_test_dict = {'cardboard': 41, 'glass': 51, 'metal': 41, 'paper': 60, 'plastic': 49, 'trash': 14}\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
        "\n",
        "for class_name in garbage_class_names:\n",
        "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
        "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
        "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
        "\n",
        "    classes_train_dict[class_name] = len(class_train_images)\n",
        "    classes_valid_dict[class_name] = len(class_valid_images)\n",
        "    classes_test_dict[class_name] = len(class_test_images)\n",
        "\n",
        "print(f\"classes_train_dict = {classes_train_dict}\")\n",
        "print(f\"classes_valid_dict = {classes_valid_dict}\")\n",
        "print(f\"classes_test_dict = {classes_test_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
        "outputId": "886f2cdc-c551-468a-f9c8-9b5c8ba39a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  count\n",
              "0  cardboard    307\n",
              "1      glass    382\n",
              "2      metal    313\n",
              "3      paper    453\n",
              "4    plastic    368\n",
              "5      trash    104"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33a0842b-d886-4732-a9d2-02312509c3f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glass</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plastic</td>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>trash</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a0842b-d886-4732-a9d2-02312509c3f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-137538ec-8be6-4d17-8c60-93217d09dfe2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-137538ec-8be6-4d17-8c60-93217d09dfe2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-137538ec-8be6-4d17-8c60-93217d09dfe2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_classes_df = pd.DataFrame(list(classes_train_dict.items()), columns=['class', 'count'])\n",
        "valid_classes_df = pd.DataFrame(list(classes_valid_dict.items()), columns=['class', 'count'])\n",
        "test_classes_df = pd.DataFrame(list(classes_test_dict.items()), columns=['class', 'count'])\n",
        "\n",
        "train_classes_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2",
      "metadata": {
        "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2"
      },
      "source": [
        "##### Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4",
      "metadata": {
        "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=train_classes_df, column_name='count', title='Percentage ratio between label classes (Train dataset)',\n",
        "                  column_contains_count=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3",
      "metadata": {
        "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=train_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Train Data',\n",
        "                   filename=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae",
      "metadata": {
        "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae"
      },
      "source": [
        "##### Valid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c742c2-33f7-436e-bd50-aeb229afbf10",
      "metadata": {
        "id": "93c742c2-33f7-436e-bd50-aeb229afbf10"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=valid_classes_df, column_name='count', title='Percentage ratio between label classes (Validation dataset)',\n",
        "                  column_contains_count=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26",
      "metadata": {
        "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=valid_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Valid Data',\n",
        "                   filename=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d2c56e-aac4-4403-a89c-177d7584ca76",
      "metadata": {
        "id": "50d2c56e-aac4-4403-a89c-177d7584ca76"
      },
      "source": [
        "##### Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592",
      "metadata": {
        "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=test_classes_df, column_name='count', title='Percentage ratio between label classes (Test dataset)',\n",
        "                  column_contains_count=True, filename='graphs/test_piechart')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a51dc2-dff2-408c-818d-9e9b052699a6",
      "metadata": {
        "id": "81a51dc2-dff2-408c-818d-9e9b052699a6"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=test_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Test Data',\n",
        "                   filename='graphs/original_vs_test_piecharts')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ],
      "metadata": {
        "id": "mQE7_geHaYNI"
      },
      "id": "mQE7_geHaYNI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "iF2NpBGwTgKy"
      },
      "id": "iF2NpBGwTgKy"
    },
    {
      "cell_type": "code",
      "source": [
        "image_classes_filepaths = [train_dir_path + 'cardboard', train_dir_path + 'glass',\n",
        "                           train_dir_path + 'metal', train_dir_path + 'paper',\n",
        "                           train_dir_path + 'plastic', train_dir_path + 'trash']\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "show_images = False\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "  image_filenames = os.listdir(image_filepath)\n",
        "\n",
        "  for image_name in image_filenames:\n",
        "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      garbage_class_images[garbage_class_name].append(img)\n",
        "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
        "\n",
        "      if show_images:\n",
        "          display_image(img, title=image_name)\n",
        "\n",
        "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tXUGWXkTfKY",
        "outputId": "4ff5854b-7d3d-4d5c-c82c-bcccaaa06f5e"
      },
      "id": "2tXUGWXkTfKY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: len(images) = 307\n",
            "glass: len(images) = 382\n",
            "metal: len(images) = 313\n",
            "paper: len(images) = 453\n",
            "plastic: len(images) = 368\n",
            "trash: len(images) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = img.shape[:2]\n",
        "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
        "target_size = (img_height, img_width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3czvCJIWO6O",
        "outputId": "64f2094c-4ef7-47e1-8691-ed9f89b1548e"
      },
      "id": "g3czvCJIWO6O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_height = 384, img_width = 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
      ],
      "metadata": {
        "id": "49lwYs7vW5X-"
      },
      "id": "49lwYs7vW5X-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation"
      ],
      "metadata": {
        "id": "rMRZMug1axTK"
      },
      "id": "rMRZMug1axTK"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
        "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                  augm_images_dir_path=augmented_images_dir,\n",
        "                                  target_size=target_size,\n",
        "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIayHvfOLeZ1",
        "outputId": "e16fb28a-1d53-4909-9798-75b122f54d7e"
      },
      "id": "FIayHvfOLeZ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 307\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 2149\n",
            "glass before augmentation: len(images) = 382\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 2674\n",
            "metal before augmentation: len(images) = 313\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 2191\n",
            "paper before augmentation: len(images) = 453\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 3171\n",
            "plastic before augmentation: len(images) = 368\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 2576\n",
            "trash before augmentation: len(images) = 104\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expacted output:\n",
        "cardboard before augmentation: len(images) = 307;\n",
        "cardboard after augmentation: len(images) = 2149\n",
        "\n",
        "glass before augmentation: len(images) = 382;\n",
        "glass after augmentation: len(images) = 2674\n",
        "\n",
        "metal before augmentation: len(images) = 313;\n",
        "metal after augmentation: len(images) = 2191\n",
        "\n",
        "paper before augmentation: len(images) = 453;\n",
        "paper after augmentation: len(images) = 3171\n",
        "\n",
        "plastic before augmentation: len(images) = 368;\n",
        "plastic after augmentation: len(images) = 2576\n",
        "\n",
        "trash before augmentation: len(images) = 104;\n",
        "trash after augmentation: len(images) = 728"
      ],
      "metadata": {
        "id": "_TZ7u46SaVaN"
      },
      "id": "_TZ7u46SaVaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### width_shift"
      ],
      "metadata": {
        "id": "SVoc99d2bFV6"
      },
      "id": "SVoc99d2bFV6"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhGL15Ira2tr",
        "outputId": "c9367e7a-c0f2-47a5-a21f-a914158681cc"
      },
      "id": "dhGL15Ira2tr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 307\n",
            "len(garbage_class_images[glass]) = 382\n",
            "len(garbage_class_images[metal]) = 313\n",
            "len(garbage_class_images[paper]) = 453\n",
            "len(garbage_class_images[plastic]) = 368\n",
            "len(garbage_class_images[trash]) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "width_shift_fraction = 0.1\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9--uJ-PkbGH5",
        "outputId": "e603ee55-d805-4447-d45b-d7bbcc78d3c7"
      },
      "id": "9--uJ-PkbGH5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 2149\n",
            "cardboard after augmentation: len(images) = 2763\n",
            "\n",
            "glass before augmentation: len(images) = 2674\n",
            "glass after augmentation: len(images) = 3438\n",
            "\n",
            "metal before augmentation: len(images) = 2191\n",
            "metal after augmentation: len(images) = 2817\n",
            "\n",
            "paper before augmentation: len(images) = 3171\n",
            "paper after augmentation: len(images) = 4077\n",
            "\n",
            "plastic before augmentation: len(images) = 2576\n",
            "plastic after augmentation: len(images) = 3312\n",
            "\n",
            "trash before augmentation: len(images) = 728\n",
            "trash after augmentation: len(images) = 936\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expacted output:\n",
        "cardboard before augmentation: len(images) = 2149;\n",
        "cardboard after augmentation: len(images) = 2149 + 307*2 = 2763\n",
        "\n",
        "glass before augmentation: len(images) = 2674;\n",
        "glass after augmentation: len(images) = 3438\n",
        "\n",
        "metal before augmentation: len(images) = 2191;\n",
        "metal after augmentation: len(images) = 2817\n",
        "\n",
        "paper before augmentation: len(images) = 3171;\n",
        "paper after augmentation: len(images) = 4077\n",
        "\n",
        "plastic before augmentation: len(images) = 2576;\n",
        "plastic after augmentation: len(images) = 3312\n",
        "\n",
        "trash before augmentation: len(images) = 728;\n",
        "trash after augmentation: len(images) = 936"
      ],
      "metadata": {
        "id": "cl36lkpgeR9X"
      },
      "id": "cl36lkpgeR9X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### height_shift"
      ],
      "metadata": {
        "id": "r1oj75sjbMPq"
      },
      "id": "r1oj75sjbMPq"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCysQhwUfG5f",
        "outputId": "c445f467-bbd2-495c-f705-b24fc1e8a696"
      },
      "id": "wCysQhwUfG5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 307\n",
            "len(garbage_class_images[glass]) = 382\n",
            "len(garbage_class_images[metal]) = 313\n",
            "len(garbage_class_images[paper]) = 453\n",
            "len(garbage_class_images[plastic]) = 368\n",
            "len(garbage_class_images[trash]) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "height_shift_fraction = 0.10\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jqPyxqofQVu",
        "outputId": "f8aa356d-3b14-4dad-abc2-f5790cf8ab22"
      },
      "id": "-jqPyxqofQVu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 2763\n",
            "cardboard after augmentation: len(images) = 3377\n",
            "\n",
            "glass before augmentation: len(images) = 3438\n",
            "glass after augmentation: len(images) = 4202\n",
            "\n",
            "metal before augmentation: len(images) = 2817\n",
            "metal after augmentation: len(images) = 3443\n",
            "\n",
            "paper before augmentation: len(images) = 4077\n",
            "paper after augmentation: len(images) = 4983\n",
            "\n",
            "plastic before augmentation: len(images) = 3312\n",
            "plastic after augmentation: len(images) = 4048\n",
            "\n",
            "trash before augmentation: len(images) = 936\n",
            "trash after augmentation: len(images) = 1144\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### horizontal_flip"
      ],
      "metadata": {
        "id": "Nq6an5m7bYeU"
      },
      "id": "Nq6an5m7bYeU"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puc6cYtLf49y",
        "outputId": "47398cb6-218d-4eee-af4a-76fe20ad873f"
      },
      "id": "Puc6cYtLf49y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3377\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 3684\n",
            "glass before augmentation: len(images) = 4202\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 4584\n",
            "metal before augmentation: len(images) = 3443\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 3756\n",
            "paper before augmentation: len(images) = 4983\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 5436\n",
            "plastic before augmentation: len(images) = 4048\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 4416\n",
            "trash before augmentation: len(images) = 1144\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vertical_flip"
      ],
      "metadata": {
        "id": "xN_CBfSMbsNy"
      },
      "id": "xN_CBfSMbsNy"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2dbTtnjXPr",
        "outputId": "3da644e4-0b84-4f5c-fddf-1de416174350"
      },
      "id": "Uk2dbTtnjXPr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3684\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 3991\n",
            "\n",
            "glass before augmentation: len(images) = 4584\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 4966\n",
            "\n",
            "metal before augmentation: len(images) = 3756\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 4069\n",
            "\n",
            "paper before augmentation: len(images) = 5436\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 5889\n",
            "\n",
            "plastic before augmentation: len(images) = 4416\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 4784\n",
            "\n",
            "trash before augmentation: len(images) = 1248\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 1352\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zoom = scaling"
      ],
      "metadata": {
        "id": "wTLkX5eyb3ny"
      },
      "id": "wTLkX5eyb3ny"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "URnp4hbnb_kD"
      },
      "id": "URnp4hbnb_kD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(0.8, 1),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g127KTuBj3bC",
        "outputId": "2bbe1d68-e504-4878-960a-3a51da3f23fa"
      },
      "id": "g127KTuBj3bC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3991\n",
            "cardboard after augmentation: len(images) = 4298\n",
            "\n",
            "glass before augmentation: len(images) = 4966\n",
            "glass after augmentation: len(images) = 5348\n",
            "\n",
            "metal before augmentation: len(images) = 4069\n",
            "metal after augmentation: len(images) = 4382\n",
            "\n",
            "paper before augmentation: len(images) = 5889\n",
            "paper after augmentation: len(images) = 6342\n",
            "\n",
            "plastic before augmentation: len(images) = 4784\n",
            "plastic after augmentation: len(images) = 5152\n",
            "\n",
            "trash before augmentation: len(images) = 1352\n",
            "trash after augmentation: len(images) = 1456\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "b8QlRMm8cQHR"
      },
      "id": "b8QlRMm8cQHR"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1, 1.2),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8koWMEdEmorg",
        "outputId": "7da8d697-c5c5-43e6-a8ae-a98b5a24eac9"
      },
      "id": "8koWMEdEmorg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4298\n",
            "cardboard after augmentation: len(images) = 4605\n",
            "\n",
            "glass before augmentation: len(images) = 5348\n",
            "glass after augmentation: len(images) = 5730\n",
            "\n",
            "metal before augmentation: len(images) = 4382\n",
            "metal after augmentation: len(images) = 4695\n",
            "\n",
            "paper before augmentation: len(images) = 6342\n",
            "paper after augmentation: len(images) = 6795\n",
            "\n",
            "plastic before augmentation: len(images) = 5152\n",
            "plastic after augmentation: len(images) = 5520\n",
            "\n",
            "trash before augmentation: len(images) = 1456\n",
            "trash after augmentation: len(images) = 1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift"
      ],
      "metadata": {
        "id": "M6N_HmcbcdN6"
      },
      "id": "M6N_HmcbcdN6"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.5, 0.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjIIZx-n-N7",
        "outputId": "e0d5747a-a803-4aa1-c412-c502595286a6"
      },
      "id": "LRjIIZx-n-N7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4605\n",
            "cardboard after augmentation: len(images) = 4912\n",
            "\n",
            "glass before augmentation: len(images) = 5730\n",
            "glass after augmentation: len(images) = 6112\n",
            "\n",
            "metal before augmentation: len(images) = 4695\n",
            "metal after augmentation: len(images) = 5008\n",
            "\n",
            "paper before augmentation: len(images) = 6795\n",
            "paper after augmentation: len(images) = 7248\n",
            "\n",
            "plastic before augmentation: len(images) = 5520\n",
            "plastic after augmentation: len(images) = 5888\n",
            "\n",
            "trash before augmentation: len(images) = 1560\n",
            "trash after augmentation: len(images) = 1664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.25, 0.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "target_size = (img_height, img_width)\n",
        "\n",
        "num_augmented_images = 1\n",
        "\n",
        "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
        "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                  augm_prefix='aug_blackBrightness_0.25', num_augm_images=num_augmented_images,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)"
      ],
      "metadata": {
        "id": "aWSH_5Fioxi1"
      },
      "id": "aWSH_5Fioxi1"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-iJpKwQo_hH",
        "outputId": "a86bab0f-99b8-400c-c2a8-11bd3ac3d18d"
      },
      "id": "R-iJpKwQo_hH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4912\n",
            "cardboard after augmentation: len(images) = 5219\n",
            "\n",
            "glass before augmentation: len(images) = 6112\n",
            "glass after augmentation: len(images) = 6494\n",
            "\n",
            "metal before augmentation: len(images) = 5008\n",
            "metal after augmentation: len(images) = 5321\n",
            "\n",
            "paper before augmentation: len(images) = 7248\n",
            "paper after augmentation: len(images) = 7701\n",
            "\n",
            "plastic before augmentation: len(images) = 5888\n",
            "plastic after augmentation: len(images) = 6256\n",
            "\n",
            "trash before augmentation: len(images) = 1664\n",
            "trash after augmentation: len(images) = 1768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.5, 1.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "target_size = (img_height, img_width)\n",
        "\n",
        "num_augmented_images = 1\n",
        "\n",
        "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
        "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                  augm_prefix='aug_ligthBrightness_1.5', num_augm_images=num_augmented_images,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)"
      ],
      "metadata": {
        "id": "VLthfnuCpTKv"
      },
      "id": "VLthfnuCpTKv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### contrast augmentation"
      ],
      "metadata": {
        "id": "OvIN0bJrdWjL"
      },
      "id": "OvIN0bJrdWjL"
    },
    {
      "cell_type": "code",
      "source": [
        "contrast_factor = 2.0\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9iw6kVhpe4g",
        "outputId": "03599552-1b9c-42a3-9d3e-46eb7cc87c95"
      },
      "id": "p9iw6kVhpe4g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 5219\n",
            "cardboard after augmentation: len(images) = 5526\n",
            "\n",
            "glass before augmentation: len(images) = 6494\n",
            "glass after augmentation: len(images) = 6876\n",
            "\n",
            "metal before augmentation: len(images) = 5321\n",
            "metal after augmentation: len(images) = 5634\n",
            "\n",
            "paper before augmentation: len(images) = 7701\n",
            "paper after augmentation: len(images) = 8154\n",
            "\n",
            "plastic before augmentation: len(images) = 6256\n",
            "plastic after augmentation: len(images) = 6624\n",
            "\n",
            "trash before augmentation: len(images) = 1768\n",
            "trash after augmentation: len(images) = 1872\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) augmentation"
      ],
      "metadata": {
        "id": "auf2c59BdgWR"
      },
      "id": "auf2c59BdgWR"
    },
    {
      "cell_type": "code",
      "source": [
        "hue_shift=180\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
        "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgEIQcbTqPIa",
        "outputId": "5004533f-fe56-490f-fc2e-9e914dc81c34"
      },
      "id": "xgEIQcbTqPIa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 5526\n",
            "cardboard after augmentation: len(images) = 5833\n",
            "\n",
            "glass before augmentation: len(images) = 6876\n",
            "glass after augmentation: len(images) = 7258\n",
            "\n",
            "metal before augmentation: len(images) = 5634\n",
            "metal after augmentation: len(images) = 5947\n",
            "\n",
            "paper before augmentation: len(images) = 8154\n",
            "paper after augmentation: len(images) = 8607\n",
            "\n",
            "plastic before augmentation: len(images) = 6624\n",
            "plastic after augmentation: len(images) = 6992\n",
            "\n",
            "trash before augmentation: len(images) = 1872\n",
            "trash after augmentation: len(images) = 1976\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### noise addition augmentation"
      ],
      "metadata": {
        "id": "bkNIrE5i9yff"
      },
      "id": "bkNIrE5i9yff"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_noisy_image(image=image)\n",
        "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "Q0yQQ7L091s1"
      },
      "id": "Q0yQQ7L091s1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reduce garbage image + background augmentation"
      ],
      "metadata": {
        "id": "5xs5E4lc92xt"
      },
      "id": "5xs5E4lc92xt"
    },
    {
      "cell_type": "code",
      "source": [
        "background_image_filepath = '/content/backgrounds/'\n",
        "background_image_names = os.listdir(background_image_filepath)\n",
        "background_images = []\n",
        "show_images = True\n",
        "\n",
        "for background_image_name in background_image_names:\n",
        "    if '.ipynb' in background_image_name:\n",
        "      continue\n",
        "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
        "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
        "    background_images.append(background_image)\n",
        "\n",
        "    if show_images:\n",
        "        display_image(background_image, title=background_image_name)"
      ],
      "metadata": {
        "id": "wpVxOJ_t-HH8"
      },
      "id": "wpVxOJ_t-HH8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1.2, 1.5),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    counter = 0\n",
        "    for background_image in background_images:\n",
        "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
        "                                                       image=image,\n",
        "                                                       background_image=background_image,\n",
        "                                                       source_path=image_class_filepath,\n",
        "                                                       image_name=image_name)\n",
        "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
        "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "      counter += 1\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "506V4KEx-AqO"
      },
      "id": "506V4KEx-AqO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift + contrast augmentation"
      ],
      "metadata": {
        "id": "rwEBRaCz-A13"
      },
      "id": "rwEBRaCz-A13"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.35, 0.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "aMm3JU0z-P18"
      },
      "id": "aMm3JU0z-P18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) + brightness + contrast augmentation"
      ],
      "metadata": {
        "id": "QQTigweq-QHk"
      },
      "id": "QQTigweq-QHk"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "hue_shift=170\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
        "\n",
        "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "2lA2U8-j-Ztj"
      },
      "id": "2lA2U8-j-Ztj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save train directory"
      ],
      "metadata": {
        "id": "hDpVqXyVqtoX"
      },
      "id": "hDpVqXyVqtoX"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/train.zip /content/garbage_classification_TrainValidTest/train"
      ],
      "metadata": {
        "id": "I2RYqgC7qsAe"
      },
      "id": "I2RYqgC7qsAe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valid"
      ],
      "metadata": {
        "id": "vH1WzuiGl9J7"
      },
      "id": "vH1WzuiGl9J7"
    },
    {
      "cell_type": "code",
      "source": [
        "image_classes_filepaths = [valid_dir_path + 'cardboard', valid_dir_path + 'glass',\n",
        "                           valid_dir_path + 'metal', valid_dir_path + 'paper',\n",
        "                           valid_dir_path + 'plastic', valid_dir_path + 'trash']\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "show_images = False\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "  image_filenames = os.listdir(image_filepath)\n",
        "\n",
        "  for image_name in image_filenames:\n",
        "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      garbage_class_images[garbage_class_name].append(img)\n",
        "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
        "\n",
        "      if show_images:\n",
        "          display_image(img, title=image_name)\n",
        "\n",
        "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhEFaLTPm7sj",
        "outputId": "657b6aad-d653-4e4d-9f52-aae0148c745b"
      },
      "id": "xhEFaLTPm7sj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: len(images) = 55\n",
            "glass: len(images) = 68\n",
            "metal: len(images) = 56\n",
            "paper: len(images) = 81\n",
            "plastic: len(images) = 65\n",
            "trash: len(images) = 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = img.shape[:2]\n",
        "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
        "target_size = (img_height, img_width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX3lA1zTrK-N",
        "outputId": "2107eaec-7141-4d3b-9143-18e76af0a64a"
      },
      "id": "GX3lA1zTrK-N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_height = 384, img_width = 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View image example"
      ],
      "metadata": {
        "id": "LhPjOZiNuN0O"
      },
      "id": "LhPjOZiNuN0O"
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
      ],
      "metadata": {
        "id": "kW0x9NzFrLpk"
      },
      "id": "kW0x9NzFrLpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation"
      ],
      "metadata": {
        "id": "Wm0HzUnim4GY"
      },
      "id": "Wm0HzUnim4GY"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
        "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                  augm_images_dir_path=augmented_images_dir,\n",
        "                                  target_size=target_size,\n",
        "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3n4ETjxl_px",
        "outputId": "b7d8ae91-da45-4656-b3d9-302817b0cb65"
      },
      "id": "s3n4ETjxl_px",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 55\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 385\n",
            "glass before augmentation: len(images) = 68\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 476\n",
            "metal before augmentation: len(images) = 56\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 392\n",
            "paper before augmentation: len(images) = 81\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 567\n",
            "plastic before augmentation: len(images) = 65\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 455\n",
            "trash before augmentation: len(images) = 19\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### width_shift"
      ],
      "metadata": {
        "id": "S1YCpPVUryl2"
      },
      "id": "S1YCpPVUryl2"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdCBVionsCIl",
        "outputId": "4d50c8d9-beb3-4da1-8278-3a78fa1eb747"
      },
      "id": "QdCBVionsCIl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 55\n",
            "len(garbage_class_images[glass]) = 68\n",
            "len(garbage_class_images[metal]) = 56\n",
            "len(garbage_class_images[paper]) = 81\n",
            "len(garbage_class_images[plastic]) = 65\n",
            "len(garbage_class_images[trash]) = 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "width_shift_fraction = 0.1\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yps6lh8nsPcp",
        "outputId": "7a90f4bb-3240-4201-d121-8a9432692764"
      },
      "id": "Yps6lh8nsPcp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 385\n",
            "cardboard after augmentation: len(images) = 495\n",
            "\n",
            "glass before augmentation: len(images) = 476\n",
            "glass after augmentation: len(images) = 612\n",
            "\n",
            "metal before augmentation: len(images) = 392\n",
            "metal after augmentation: len(images) = 504\n",
            "\n",
            "paper before augmentation: len(images) = 567\n",
            "paper after augmentation: len(images) = 729\n",
            "\n",
            "plastic before augmentation: len(images) = 455\n",
            "plastic after augmentation: len(images) = 585\n",
            "\n",
            "trash before augmentation: len(images) = 133\n",
            "trash after augmentation: len(images) = 171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### height_shift"
      ],
      "metadata": {
        "id": "iDPvcoMgseEW"
      },
      "id": "iDPvcoMgseEW"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "height_shift_fraction = 0.10\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2pfiHsBskgP",
        "outputId": "276035a5-90c5-4cb6-90d1-937e907e5171"
      },
      "id": "U2pfiHsBskgP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 495\n",
            "cardboard after augmentation: len(images) = 605\n",
            "\n",
            "glass before augmentation: len(images) = 612\n",
            "glass after augmentation: len(images) = 748\n",
            "\n",
            "metal before augmentation: len(images) = 504\n",
            "metal after augmentation: len(images) = 616\n",
            "\n",
            "paper before augmentation: len(images) = 729\n",
            "paper after augmentation: len(images) = 891\n",
            "\n",
            "plastic before augmentation: len(images) = 585\n",
            "plastic after augmentation: len(images) = 715\n",
            "\n",
            "trash before augmentation: len(images) = 171\n",
            "trash after augmentation: len(images) = 209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### horizontal_flip"
      ],
      "metadata": {
        "id": "NdonW8OusrtF"
      },
      "id": "NdonW8OusrtF"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5EvjcJsxD8",
        "outputId": "8affd288-5557-4295-977d-6629054cf8eb"
      },
      "id": "FQ5EvjcJsxD8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 605\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 660\n",
            "glass before augmentation: len(images) = 748\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 816\n",
            "metal before augmentation: len(images) = 616\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 672\n",
            "paper before augmentation: len(images) = 891\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 972\n",
            "plastic before augmentation: len(images) = 715\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 780\n",
            "trash before augmentation: len(images) = 209\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vertical_flip"
      ],
      "metadata": {
        "id": "Lxd7HGmlsyRc"
      },
      "id": "Lxd7HGmlsyRc"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-TBIPuzs-K9",
        "outputId": "de8f8851-772e-45c5-e3a4-ab34c08953c4"
      },
      "id": "k-TBIPuzs-K9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 660\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 715\n",
            "\n",
            "glass before augmentation: len(images) = 816\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 884\n",
            "\n",
            "metal before augmentation: len(images) = 672\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 728\n",
            "\n",
            "paper before augmentation: len(images) = 972\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 1053\n",
            "\n",
            "plastic before augmentation: len(images) = 780\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 845\n",
            "\n",
            "trash before augmentation: len(images) = 228\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 247\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zoom = scaling"
      ],
      "metadata": {
        "id": "oZNmeaEis_M9"
      },
      "id": "oZNmeaEis_M9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "PLEmuhGMtKR2"
      },
      "id": "PLEmuhGMtKR2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(0.8, 1),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC_mli1ptJFM",
        "outputId": "20a2f789-b1a1-4c76-9f66-c6d0bc0b8d36"
      },
      "id": "oC_mli1ptJFM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 715\n",
            "cardboard after augmentation: len(images) = 770\n",
            "\n",
            "glass before augmentation: len(images) = 884\n",
            "glass after augmentation: len(images) = 952\n",
            "\n",
            "metal before augmentation: len(images) = 728\n",
            "metal after augmentation: len(images) = 784\n",
            "\n",
            "paper before augmentation: len(images) = 1053\n",
            "paper after augmentation: len(images) = 1134\n",
            "\n",
            "plastic before augmentation: len(images) = 845\n",
            "plastic after augmentation: len(images) = 910\n",
            "\n",
            "trash before augmentation: len(images) = 247\n",
            "trash after augmentation: len(images) = 266\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "3CXocmX_tJRk"
      },
      "id": "3CXocmX_tJRk"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1, 1.2),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V716jtPotgB1",
        "outputId": "08731f33-8fa6-4598-e015-6eb9fc159511"
      },
      "id": "V716jtPotgB1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 770\n",
            "cardboard after augmentation: len(images) = 825\n",
            "\n",
            "glass before augmentation: len(images) = 952\n",
            "glass after augmentation: len(images) = 1020\n",
            "\n",
            "metal before augmentation: len(images) = 784\n",
            "metal after augmentation: len(images) = 840\n",
            "\n",
            "paper before augmentation: len(images) = 1134\n",
            "paper after augmentation: len(images) = 1215\n",
            "\n",
            "plastic before augmentation: len(images) = 910\n",
            "plastic after augmentation: len(images) = 975\n",
            "\n",
            "trash before augmentation: len(images) = 266\n",
            "trash after augmentation: len(images) = 285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift"
      ],
      "metadata": {
        "id": "zLqDaHmgtgTd"
      },
      "id": "zLqDaHmgtgTd"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.5, 0.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gec8GLoctvh1",
        "outputId": "fe2a9f65-82c5-47a6-9d5c-ae8480e01c1c"
      },
      "id": "Gec8GLoctvh1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 825\n",
            "cardboard after augmentation: len(images) = 880\n",
            "\n",
            "glass before augmentation: len(images) = 1020\n",
            "glass after augmentation: len(images) = 1088\n",
            "\n",
            "metal before augmentation: len(images) = 840\n",
            "metal after augmentation: len(images) = 896\n",
            "\n",
            "paper before augmentation: len(images) = 1215\n",
            "paper after augmentation: len(images) = 1296\n",
            "\n",
            "plastic before augmentation: len(images) = 975\n",
            "plastic after augmentation: len(images) = 1040\n",
            "\n",
            "trash before augmentation: len(images) = 285\n",
            "trash after augmentation: len(images) = 304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbJMQn6lt-3e",
        "outputId": "399fae71-6896-40a7-fce3-379759377360"
      },
      "id": "AbJMQn6lt-3e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 880\n",
            "cardboard after augmentation: len(images) = 935\n",
            "\n",
            "glass before augmentation: len(images) = 1088\n",
            "glass after augmentation: len(images) = 1156\n",
            "\n",
            "metal before augmentation: len(images) = 896\n",
            "metal after augmentation: len(images) = 952\n",
            "\n",
            "paper before augmentation: len(images) = 1296\n",
            "paper after augmentation: len(images) = 1377\n",
            "\n",
            "plastic before augmentation: len(images) = 1040\n",
            "plastic after augmentation: len(images) = 1105\n",
            "\n",
            "trash before augmentation: len(images) = 304\n",
            "trash after augmentation: len(images) = 323\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### contrast augmentation"
      ],
      "metadata": {
        "id": "lADCJADjtvxU"
      },
      "id": "lADCJADjtvxU"
    },
    {
      "cell_type": "code",
      "source": [
        "contrast_factor = 2.0\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KyAabx-uLV0",
        "outputId": "09d52fe8-6667-45bb-9d22-52c495fa88fd"
      },
      "id": "2KyAabx-uLV0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 935\n",
            "cardboard after augmentation: len(images) = 990\n",
            "\n",
            "glass before augmentation: len(images) = 1156\n",
            "glass after augmentation: len(images) = 1224\n",
            "\n",
            "metal before augmentation: len(images) = 952\n",
            "metal after augmentation: len(images) = 1008\n",
            "\n",
            "paper before augmentation: len(images) = 1377\n",
            "paper after augmentation: len(images) = 1458\n",
            "\n",
            "plastic before augmentation: len(images) = 1105\n",
            "plastic after augmentation: len(images) = 1170\n",
            "\n",
            "trash before augmentation: len(images) = 323\n",
            "trash after augmentation: len(images) = 342\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) augmentation"
      ],
      "metadata": {
        "id": "xPP3kC0vuLgD"
      },
      "id": "xPP3kC0vuLgD"
    },
    {
      "cell_type": "code",
      "source": [
        "hue_shift=180\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
        "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypPMgGi6udIm",
        "outputId": "1acc57ef-3593-4a56-b3f2-209ba3cdc8bf"
      },
      "id": "ypPMgGi6udIm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 990\n",
            "cardboard after augmentation: len(images) = 1045\n",
            "\n",
            "glass before augmentation: len(images) = 1224\n",
            "glass after augmentation: len(images) = 1292\n",
            "\n",
            "metal before augmentation: len(images) = 1008\n",
            "metal after augmentation: len(images) = 1064\n",
            "\n",
            "paper before augmentation: len(images) = 1458\n",
            "paper after augmentation: len(images) = 1539\n",
            "\n",
            "plastic before augmentation: len(images) = 1170\n",
            "plastic after augmentation: len(images) = 1235\n",
            "\n",
            "trash before augmentation: len(images) = 342\n",
            "trash after augmentation: len(images) = 361\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### noise addition augmentation"
      ],
      "metadata": {
        "id": "Y1qLJ2g506nN"
      },
      "id": "Y1qLJ2g506nN"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_noisy_image(image=image)\n",
        "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGJnMe4Y1Pvz",
        "outputId": "0f843702-4ce9-498d-aff6-374275727afb"
      },
      "id": "xGJnMe4Y1Pvz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 55\n",
            "cardboard after augmentation: len(images) = 110\n",
            "\n",
            "glass before augmentation: len(images) = 68\n",
            "glass after augmentation: len(images) = 136\n",
            "\n",
            "metal before augmentation: len(images) = 56\n",
            "metal after augmentation: len(images) = 112\n",
            "\n",
            "paper before augmentation: len(images) = 81\n",
            "paper after augmentation: len(images) = 162\n",
            "\n",
            "plastic before augmentation: len(images) = 65\n",
            "plastic after augmentation: len(images) = 130\n",
            "\n",
            "trash before augmentation: len(images) = 19\n",
            "trash after augmentation: len(images) = 38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reduce garbage image + background augmentation"
      ],
      "metadata": {
        "id": "5h2Ggtv72gdt"
      },
      "id": "5h2Ggtv72gdt"
    },
    {
      "cell_type": "code",
      "source": [
        "background_image_filepath = '/content/backgrounds/'\n",
        "background_image_names = os.listdir(background_image_filepath)\n",
        "background_images = []\n",
        "show_images = True\n",
        "\n",
        "for background_image_name in background_image_names:\n",
        "    if '.ipynb' in background_image_name:\n",
        "      continue\n",
        "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
        "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
        "    background_images.append(background_image)\n",
        "\n",
        "    if show_images:\n",
        "        display_image(background_image, title=background_image_name)"
      ],
      "metadata": {
        "id": "bc7ngXmJ2lNM"
      },
      "id": "bc7ngXmJ2lNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1.2, 1.5),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    counter = 0\n",
        "    for background_image in background_images:\n",
        "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
        "                                                       image=image,\n",
        "                                                       background_image=background_image,\n",
        "                                                       source_path=image_class_filepath,\n",
        "                                                       image_name=image_name)\n",
        "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
        "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "      counter += 1\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "8Ep7abI-3JSQ",
        "outputId": "fa1f25da-6584-47da-84a5-afdd583483cb"
      },
      "id": "8Ep7abI-3JSQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 109GB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard after augmentation: len(images) = 330\n",
            "\n",
            "glass before augmentation: len(images) = 136\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5e37bfbb25d2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbackground_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackground_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                        \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                        \u001b[0mbackground_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-dae93a06895b>\u001b[0m in \u001b[0;36mget_augmented_background_image\u001b[0;34m(imageDataGenerator, image, background_image, source_path, image_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maugmented_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mpil_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Convert PIL image to OpenCV format (NumPy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-488e2f06e975>\u001b[0m in \u001b[0;36mremove_background\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Removing the background from the given Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Convert the output image to RGB mode (removing transparency)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/bg.py\u001b[0m in \u001b[0;36mremove\u001b[0;34m(data, alpha_matting, alpha_matting_foreground_threshold, alpha_matting_background_threshold, alpha_matting_erode_size, session, only_mask, post_process_mask, bgcolor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u2net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/session_factory.py\u001b[0m in \u001b[0;36mnew_session\u001b[0;34m(model_name, providers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msess_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter_op_num_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OMP_NUM_THREADS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_opts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/sessions/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, sess_opts, providers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         self.inner_session = ort.InferenceSession(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msess_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess_opts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/sessions/u2net.py\u001b[0m in \u001b[0;36mdownload_models\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.name(*args, **kwargs)}.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         pooch.retrieve(\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;34m\"https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/core.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(url, known_hash, fname, path, processor, downloader, progressbar)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"download\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/core.py\u001b[0m in \u001b[0;36mdownload_action\u001b[0;34m(path, known_hash)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"download\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Downloading\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhash_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Updating\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/hashes.py\u001b[0m in \u001b[0;36mhash_matches\u001b[0;34m(fname, known_hash, strict, source)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/hashes.py\u001b[0m in \u001b[0;36mfile_hash\u001b[0;34m(fname, alg)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift + contrast augmentation"
      ],
      "metadata": {
        "id": "m0g3W4Fr6lR2"
      },
      "id": "m0g3W4Fr6lR2"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.35, 0.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBBS121o6x0u",
        "outputId": "86c4a56e-a743-4e1b-9853-66b9c7207217"
      },
      "id": "TBBS121o6x0u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 330\n",
            "cardboard after augmentation: len(images) = 385\n",
            "\n",
            "glass before augmentation: len(images) = 212\n",
            "glass after augmentation: len(images) = 280\n",
            "\n",
            "metal before augmentation: len(images) = 112\n",
            "metal after augmentation: len(images) = 168\n",
            "\n",
            "paper before augmentation: len(images) = 162\n",
            "paper after augmentation: len(images) = 243\n",
            "\n",
            "plastic before augmentation: len(images) = 130\n",
            "plastic after augmentation: len(images) = 195\n",
            "\n",
            "trash before augmentation: len(images) = 38\n",
            "trash after augmentation: len(images) = 57\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) + brightness + contrast augmentation"
      ],
      "metadata": {
        "id": "9uPP8ROm7bB9"
      },
      "id": "9uPP8ROm7bB9"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "hue_shift=170\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
        "\n",
        "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Kv50wZ7jK_",
        "outputId": "9bc899ec-2993-4028-c3ea-b0f7b958f4ea"
      },
      "id": "a0Kv50wZ7jK_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 385\n",
            "cardboard after augmentation: len(images) = 440\n",
            "\n",
            "glass before augmentation: len(images) = 280\n",
            "glass after augmentation: len(images) = 348\n",
            "\n",
            "metal before augmentation: len(images) = 168\n",
            "metal after augmentation: len(images) = 224\n",
            "\n",
            "paper before augmentation: len(images) = 243\n",
            "paper after augmentation: len(images) = 324\n",
            "\n",
            "plastic before augmentation: len(images) = 195\n",
            "plastic after augmentation: len(images) = 260\n",
            "\n",
            "trash before augmentation: len(images) = 57\n",
            "trash after augmentation: len(images) = 76\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save valid directory"
      ],
      "metadata": {
        "id": "HHp2s0HkuwPs"
      },
      "id": "HHp2s0HkuwPs"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/valid.zip /content/garbage_classification_TrainValidTest/valid"
      ],
      "metadata": {
        "id": "Rfgi2wPeuy0l"
      },
      "id": "Rfgi2wPeuy0l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save test directory"
      ],
      "metadata": {
        "id": "YEiPqicE3SOv"
      },
      "id": "YEiPqicE3SOv"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/test.zip /content/garbage_classification_TrainValidTest/test"
      ],
      "metadata": {
        "id": "00TsaCNs3Vge"
      },
      "id": "00TsaCNs3Vge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c",
      "metadata": {
        "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c"
      },
      "source": [
        "# Train CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc62474-9df5-4c7d-95ab-f24e06263167",
      "metadata": {
        "id": "edc62474-9df5-4c7d-95ab-f24e06263167"
      },
      "source": [
        "## Create train and valid datagenerators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
        "outputId": "af4bed8e-ab5d-4704-f46c-f58fbbb8a036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1927 images belonging to 6 classes.\n",
            "Found 344 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir_path,\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(300, 300))\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir_path,\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(300, 300))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1",
      "metadata": {
        "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take into account the imbalance of garbage classes of the studied dataset"
      ],
      "metadata": {
        "id": "VOeyt-j4AwnF"
      },
      "id": "VOeyt-j4AwnF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/69783897/compute-class-weight-function-issue-in-sklearn-library-when-used-in-keras-cl"
      ],
      "metadata": {
        "id": "ajuBi4RhH-6G"
      },
      "id": "ajuBi4RhH-6G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the true labels for the test data\n",
        "true_labels = train_generator.classes\n",
        "\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes = np.unique(true_labels),\n",
        "                                     y = true_labels)\n",
        "\n",
        "\n",
        "# Create a dictionary to store the class weights\n",
        "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
        "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
        "\n",
        "# Print the class weights\n",
        "print(\"Class Weights:\", class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXk2zc0A5sz",
        "outputId": "9a739cda-f4ff-4e5d-aa11-f19d5ded58df"
      },
      "id": "voXk2zc0A5sz",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0461454940282302, 1: 0.8407504363001745, 2: 1.0260915867944622, 3: 0.7089771891096395, 4: 0.8727355072463768, 5: 3.0881410256410255}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"len(true_labels) = {len(true_labels)}\")\n",
        "print(f\"true_labels = {true_labels}\")\n",
        "\n",
        "\"\"\"\n",
        "print(f\"len(class_labels) = {len(class_labels)}\")\n",
        "print(f\"class_labels = {class_labels}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xtCi21DCJdPV",
        "outputId": "34c4689c-e6e2-480b-ab7c-8f3575d1248e"
      },
      "id": "xtCi21DCJdPV",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(true_labels) = 1927\n",
            "true_labels = [0 0 0 ... 5 5 5]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(f\"len(class_labels) = {len(class_labels)}\")\\nprint(f\"class_labels = {class_labels}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the CNN model"
      ],
      "metadata": {
        "id": "jY64rbItA8lz"
      },
      "id": "jY64rbItA8lz"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "30815f75-7eb4-484e-bf11-9c03f9394b89",
      "metadata": {
        "id": "30815f75-7eb4-484e-bf11-9c03f9394b89"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.95):\n",
        "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
        "outputId": "6b7f29a1-cedf-49ee-ca46-200cde2cf934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 298, 298, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 149, 149, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 147, 147, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 73, 73, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 71, 71, 128)       73856     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 645248)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               82591872  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82685894 (315.42 MB)\n",
            "Trainable params: 82685894 (315.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential(layers=[\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "b0afca06-7431-4884-9c44-60d418f40731",
      "metadata": {
        "id": "b0afca06-7431-4884-9c44-60d418f40731"
      },
      "outputs": [],
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_checkpoint_callback = ModelCheckpoint('/content/models/new_augmented_model.h5', monitor='val_accuracy',\n",
        "                                            mode='max', verbose=1, save_best_only=True)\n",
        "my_callback = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1",
      "metadata": {
        "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
      "metadata": {
        "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb3b0e7-22a4-47dc-ac43-717b45956e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 6/31 [====>.........................] - ETA: 5s - loss: 9.1179 - accuracy: 0.1641 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0896s vs `on_train_batch_end` time: 0.0998s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - ETA: 0s - loss: 5.0340 - accuracy: 0.2382\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31105, saving model to /content/models/new_augmented_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 18s 525ms/step - loss: 5.0340 - accuracy: 0.2382 - val_loss: 2.9828 - val_accuracy: 0.3110\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 2.3633 - accuracy: 0.3560\n",
            "Epoch 2: val_accuracy improved from 0.31105 to 0.38663, saving model to /content/models/new_augmented_model.h5\n",
            "31/31 [==============================] - 16s 513ms/step - loss: 2.3633 - accuracy: 0.3560 - val_loss: 2.0488 - val_accuracy: 0.3866\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.8729 - accuracy: 0.3799\n",
            "Epoch 3: val_accuracy improved from 0.38663 to 0.47965, saving model to /content/models/new_augmented_model.h5\n",
            "31/31 [==============================] - 18s 575ms/step - loss: 1.8729 - accuracy: 0.3799 - val_loss: 1.6790 - val_accuracy: 0.4797\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 0.4286\n",
            "Epoch 4: val_accuracy did not improve from 0.47965\n",
            "31/31 [==============================] - 10s 304ms/step - loss: 1.6506 - accuracy: 0.4286 - val_loss: 1.6344 - val_accuracy: 0.4390\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.6334 - accuracy: 0.4188\n",
            "Epoch 5: val_accuracy did not improve from 0.47965\n",
            "31/31 [==============================] - 9s 278ms/step - loss: 1.6334 - accuracy: 0.4188 - val_loss: 1.5717 - val_accuracy: 0.4651\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.4556\n",
            "Epoch 6: val_accuracy did not improve from 0.47965\n",
            "31/31 [==============================] - 10s 326ms/step - loss: 1.6147 - accuracy: 0.4556 - val_loss: 1.8386 - val_accuracy: 0.4360\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.6516 - accuracy: 0.4281\n",
            "Epoch 7: val_accuracy did not improve from 0.47965\n",
            "31/31 [==============================] - 11s 341ms/step - loss: 1.6516 - accuracy: 0.4281 - val_loss: 1.7292 - val_accuracy: 0.3953\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - ETA: 0s - loss: 1.6772 - accuracy: 0.4250\n",
            "Epoch 8: val_accuracy did not improve from 0.47965\n",
            "31/31 [==============================] - 9s 299ms/step - loss: 1.6772 - accuracy: 0.4250 - val_loss: 1.6571 - val_accuracy: 0.4738\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=valid_generator,\n",
        "                    callbacks=[early_stopping_callback, my_callback, model_checkpoint_callback],\n",
        "                    class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eF1vdtTGNFzK"
      },
      "id": "eF1vdtTGNFzK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the CNN model using Transfer Learning (ResNet50)"
      ],
      "metadata": {
        "id": "fghIDHP3LUOB"
      },
      "id": "fghIDHP3LUOB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example from Kaggle"
      ],
      "metadata": {
        "id": "HtK1_C35Rcjy"
      },
      "id": "HtK1_C35Rcjy"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "B2Rv64TmLZtY"
      },
      "id": "B2Rv64TmLZtY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/garbage classification/Garbage classification'\n",
        "valid_path = '/content/garbage classification/Garbage classification'\n",
        "\n",
        "\n",
        "# extract images to training set by applying data preprocessing and data augmentation\n",
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.1).flow_from_directory(\n",
        "    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
        "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n",
        "\n",
        "\n",
        "# extract images to validation set\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    validation_split=0.1).flow_from_directory(\n",
        "    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
        "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTgy37lHRbwC",
        "outputId": "8906f290-ed81-45f7-c702-8407aff0f384"
      },
      "id": "aTgy37lHRbwC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2276 images belonging to 6 classes.\n",
            "Found 251 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Load pre-trained ResNet50 model without the top classification layers\n",
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SHAPE))\n",
        "\n",
        "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
        "# during training inorder to extract features\n",
        "base_model.trainable=False\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "# add global average pooling layer\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# add densely-connected NN layer with 512 hidden units\n",
        "model.add(Dense(units=512, activation='relu'))  # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 128 hidden units\n",
        "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 6 hidden units\n",
        "model.add(Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao_b4zb-Pj20",
        "outputId": "f94ea1a6-04b8-4193-b667-8f63519df217"
      },
      "id": "ao_b4zb-Pj20",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234698864/234698864 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59489030 (226.93 MB)\n",
            "Trainable params: 1116806 (4.26 MB)\n",
            "Non-trainable params: 58372224 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "htp1h_lJEYro"
      },
      "id": "htp1h_lJEYro",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "   train_batches,\n",
        "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
        "    epochs=20,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [es, mc],)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yrQZpYujSJKX",
        "outputId": "7829ae9a-27dc-4f84-80f6-93619a0114c6"
      },
      "id": "yrQZpYujSJKX",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6a8dea3eafd7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_batches' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "UrDhIooEWnck",
        "outputId": "5dcfd583-ffc2-4b7d-d153-f88e36ef4c43"
      },
      "id": "UrDhIooEWnck",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/models/4_resnet152_garbage_classification_6_classes_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDSd0Q5aWwrd",
        "outputId": "0475487a-160b-4bdc-be15-7557d5a0573a"
      },
      "id": "YDSd0Q5aWwrd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/models/histories/4_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "metadata": {
        "id": "oXM8zfJlW5eG"
      },
      "id": "oXM8zfJlW5eG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "\n",
        "base_model.trainable=True\n",
        "history = model.fit_generator(\n",
        "   train_batches,\n",
        "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
        "    epochs=10,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [es, mc],)\n",
        "\n",
        "loss.extend(history.history['loss'])\n",
        "validation_loss.extend(history.history['val_loss'])\n",
        "accuracy.extend(history.history['accuracy'])\n",
        "validation_accuracy.extend(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3lcwhlTuKn",
        "outputId": "ce764e3f-dfc8-4a65-810a-a8336fb08191"
      },
      "id": "OX3lcwhlTuKn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-687fe0966ab3>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9649\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94024, saving model to VGG152 Garbage Classifier.h5\n",
            "142/142 [==============================] - 42s 293ms/step - loss: 0.1121 - accuracy: 0.9649 - val_loss: 0.2055 - val_accuracy: 0.9402\n",
            "Epoch 2/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9657\n",
            "Epoch 2: val_accuracy improved from 0.94024 to 0.94821, saving model to VGG152 Garbage Classifier.h5\n",
            "142/142 [==============================] - 41s 286ms/step - loss: 0.1118 - accuracy: 0.9657 - val_loss: 0.1786 - val_accuracy: 0.9482\n",
            "Epoch 3/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9587\n",
            "Epoch 3: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 40s 281ms/step - loss: 0.1250 - accuracy: 0.9587 - val_loss: 0.1911 - val_accuracy: 0.9402\n",
            "Epoch 4/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9706\n",
            "Epoch 4: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 39s 276ms/step - loss: 0.1003 - accuracy: 0.9706 - val_loss: 0.1809 - val_accuracy: 0.9363\n",
            "Epoch 5/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9719\n",
            "Epoch 5: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 266ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.2059 - val_accuracy: 0.9203\n",
            "Epoch 6/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9701\n",
            "Epoch 6: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 264ms/step - loss: 0.0918 - accuracy: 0.9701 - val_loss: 0.2014 - val_accuracy: 0.9402\n",
            "Epoch 7/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9714\n",
            "Epoch 7: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 37s 263ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 0.1817 - val_accuracy: 0.9363\n",
            "Epoch 8/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9789\n",
            "Epoch 8: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 267ms/step - loss: 0.0848 - accuracy: 0.9789 - val_loss: 0.2457 - val_accuracy: 0.9203\n",
            "Epoch 9/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9745\n",
            "Epoch 9: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 266ms/step - loss: 0.0815 - accuracy: 0.9745 - val_loss: 0.2427 - val_accuracy: 0.9084\n",
            "Epoch 10/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9763\n",
            "Epoch 10: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 267ms/step - loss: 0.0831 - accuracy: 0.9763 - val_loss: 0.2710 - val_accuracy: 0.9044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training by myself"
      ],
      "metadata": {
        "id": "GieDQ47P5iUP"
      },
      "id": "GieDQ47P5iUP"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "-wulntQT5piR"
      },
      "id": "-wulntQT5piR",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size=(224, 224)\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator = datagen.flow_from_directory(directory=train_dir_path,\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical',\n",
        "                                              target_size=target_size)\n",
        "\n",
        "valid_generator = datagen.flow_from_directory(directory=valid_dir_path,\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical',\n",
        "                                              target_size=target_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFsesqr76lpF",
        "outputId": "8f252834-71a7-4939-ea67-f81f95245fb1"
      },
      "id": "dFsesqr76lpF",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1927 images belonging to 6 classes.\n",
            "Found 344 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_generator.samples/train_generator.batch_size = {train_generator.samples/train_generator.batch_size}\")\n",
        "print(f\"valid_generator.samples/valid_generator.batch_size = {valid_generator.samples/valid_generator.batch_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xJ7XI70_QAj",
        "outputId": "d7b4e050-c600-4d3a-bd35-0c7d9119d5c5"
      },
      "id": "0xJ7XI70_QAj",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_generator.samples/train_generator.batch_size = 60.21875\n",
            "valid_generator.samples/valid_generator.batch_size = 10.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the true labels for the test data\n",
        "true_labels = train_generator.classes\n",
        "\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes = np.unique(true_labels),\n",
        "                                     y = true_labels)\n",
        "\n",
        "\n",
        "# Create a dictionary to store the class weights\n",
        "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
        "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
        "\n",
        "# Print the class weights\n",
        "print(\"Class Weights:\", class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZmQv4t9JON4",
        "outputId": "10408182-d608-470f-b127-0dd1580b0b64"
      },
      "id": "UZmQv4t9JON4",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0461454940282302, 1: 0.8407504363001745, 2: 1.0260915867944622, 3: 0.7089771891096395, 4: 0.8727355072463768, 5: 3.0881410256410255}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# import the convolution base of the VGG16 model with pre-trained weights\n",
        "base_model = tf.keras.applications.resnet.ResNet152(input_shape=IMG_SHAPE,\n",
        "                                        include_top=False,\n",
        "                                        weights='imagenet')\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
        "# during training inorder to extract features\n",
        "base_model.trainable=False\n",
        "\n",
        "# add VGG16 convolution base to initialize sequential model\n",
        "model.add(base_model)\n",
        "\n",
        "# add global average pooling layer\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "# add densely-connected NN layer with 512 hidden units\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))  # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 128 hidden units\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu')) # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 6 hidden units\n",
        "model.add(tf.keras.layers.Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9RRgj8__Iig",
        "outputId": "484e6455-e68a-4f82-ac71-80b080aa5cdf"
      },
      "id": "n9RRgj8__Iig",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59489030 (226.93 MB)\n",
            "Trainable params: 1116806 (4.26 MB)\n",
            "Non-trainable params: 58372224 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.99):\n",
        "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "CxDCpUZnPIEK"
      },
      "id": "CxDCpUZnPIEK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callback = myCallback()\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "model_checkpoint_callback = ModelCheckpoint('VGG152_Garbage_Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "fgL8J-XD5x5Q"
      },
      "id": "fgL8J-XD5x5Q",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "    epochs=20,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [early_stopping_callback, model_checkpoint_callback],\n",
        "    class_weight=class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCD3JtLzGj9h",
        "outputId": "8efecb21-b604-41a3-ff37-6da13f9c3709"
      },
      "id": "TCD3JtLzGj9h",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 1.3578 - accuracy: 0.5309\n",
            "Epoch 1: val_accuracy improved from -inf to 0.74128, saving model to VGG152_Garbage_Classifier.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 38s 413ms/step - loss: 1.3578 - accuracy: 0.5309 - val_loss: 0.7327 - val_accuracy: 0.7413\n",
            "Epoch 2/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.7909\n",
            "Epoch 2: val_accuracy improved from 0.74128 to 0.81977, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 21s 340ms/step - loss: 0.5817 - accuracy: 0.7909 - val_loss: 0.5092 - val_accuracy: 0.8198\n",
            "Epoch 3/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8516\n",
            "Epoch 3: val_accuracy improved from 0.81977 to 0.85465, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 21s 343ms/step - loss: 0.4135 - accuracy: 0.8516 - val_loss: 0.4340 - val_accuracy: 0.8547\n",
            "Epoch 4/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.8926\n",
            "Epoch 4: val_accuracy improved from 0.85465 to 0.86047, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 21s 343ms/step - loss: 0.3178 - accuracy: 0.8926 - val_loss: 0.4039 - val_accuracy: 0.8605\n",
            "Epoch 5/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9175\n",
            "Epoch 5: val_accuracy improved from 0.86047 to 0.88663, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 21s 344ms/step - loss: 0.2450 - accuracy: 0.9175 - val_loss: 0.3664 - val_accuracy: 0.8866\n",
            "Epoch 6/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9393\n",
            "Epoch 6: val_accuracy did not improve from 0.88663\n",
            "60/60 [==============================] - 19s 315ms/step - loss: 0.1996 - accuracy: 0.9393 - val_loss: 0.3516 - val_accuracy: 0.8808\n",
            "Epoch 7/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9434\n",
            "Epoch 7: val_accuracy did not improve from 0.88663\n",
            "60/60 [==============================] - 21s 350ms/step - loss: 0.1896 - accuracy: 0.9434 - val_loss: 0.3415 - val_accuracy: 0.8779\n",
            "Epoch 8/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9621\n",
            "Epoch 8: val_accuracy did not improve from 0.88663\n",
            "60/60 [==============================] - 19s 315ms/step - loss: 0.1422 - accuracy: 0.9621 - val_loss: 0.3358 - val_accuracy: 0.8866\n",
            "Epoch 9/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9689\n",
            "Epoch 9: val_accuracy improved from 0.88663 to 0.88953, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 25s 412ms/step - loss: 0.1243 - accuracy: 0.9689 - val_loss: 0.3238 - val_accuracy: 0.8895\n",
            "Epoch 10/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9720\n",
            "Epoch 10: val_accuracy improved from 0.88953 to 0.90116, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 23s 374ms/step - loss: 0.1057 - accuracy: 0.9720 - val_loss: 0.3158 - val_accuracy: 0.9012\n",
            "Epoch 11/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9782\n",
            "Epoch 11: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 312ms/step - loss: 0.0953 - accuracy: 0.9782 - val_loss: 0.3181 - val_accuracy: 0.8866\n",
            "Epoch 12/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9850\n",
            "Epoch 12: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 22s 364ms/step - loss: 0.0803 - accuracy: 0.9850 - val_loss: 0.3157 - val_accuracy: 0.8866\n",
            "Epoch 13/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9834\n",
            "Epoch 13: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 22s 359ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.3105 - val_accuracy: 0.8953\n",
            "Epoch 14/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9865\n",
            "Epoch 14: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 321ms/step - loss: 0.0676 - accuracy: 0.9865 - val_loss: 0.3114 - val_accuracy: 0.8895\n",
            "Epoch 15/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9829\n",
            "Epoch 15: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 323ms/step - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.3109 - val_accuracy: 0.8983\n",
            "Epoch 16/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9927\n",
            "Epoch 16: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 314ms/step - loss: 0.0498 - accuracy: 0.9927 - val_loss: 0.3032 - val_accuracy: 0.8983\n",
            "Epoch 17/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9927\n",
            "Epoch 17: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 21s 349ms/step - loss: 0.0475 - accuracy: 0.9927 - val_loss: 0.3064 - val_accuracy: 0.8953\n",
            "Epoch 18/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9901\n",
            "Epoch 18: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 318ms/step - loss: 0.0540 - accuracy: 0.9901 - val_loss: 0.2905 - val_accuracy: 0.8983\n",
            "Epoch 19/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9865\n",
            "Epoch 19: val_accuracy did not improve from 0.90116\n",
            "60/60 [==============================] - 19s 320ms/step - loss: 0.0533 - accuracy: 0.9865 - val_loss: 0.2887 - val_accuracy: 0.9012\n",
            "Epoch 20/20\n",
            "61/60 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9943\n",
            "Epoch 20: val_accuracy improved from 0.90116 to 0.90407, saving model to VGG152_Garbage_Classifier.h5\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.0414 - accuracy: 0.9943 - val_loss: 0.2925 - val_accuracy: 0.9041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/models/5_resnet152_garbage_classification_6_classes_model.h5')"
      ],
      "metadata": {
        "id": "2EPzdHJ6P8Lh"
      },
      "id": "2EPzdHJ6P8Lh",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b37eb6e6-b6fe-4c30-b916-d94c4cc7f5e2",
      "metadata": {
        "id": "b37eb6e6-b6fe-4c30-b916-d94c4cc7f5e2"
      },
      "source": [
        "## Display results of training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0ba51-1985-4045-a9de-c5a927e24cd4",
      "metadata": {
        "id": "72b0ba51-1985-4045-a9de-c5a927e24cd4"
      },
      "source": [
        "### Display the training history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['loss'] = loss\n",
        "history.history['val_loss'] = validation_loss\n",
        "history.history['accuracy'] = accuracy\n",
        "history.history['val_accuracy'] = validation_accuracy"
      ],
      "metadata": {
        "id": "05HCYa2lZFGj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "4c97b885-5e0e-4663-e2a4-0f704c833f8c"
      },
      "id": "05HCYa2lZFGj",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-9ab3470172a3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "f6a14c8b-f797-4d4a-8eae-f6caa4a65caa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "f6a14c8b-f797-4d4a-8eae-f6caa4a65caa",
        "outputId": "68e28bdf-6794-4960-8c84-e6fd96dcc2ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "1mW5WqerU6xH"
      },
      "id": "1mW5WqerU6xH"
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
        "\n",
        "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "\n",
        "# Load and preprocess test data using the generator\n",
        "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
        "                                                  batch_size=64,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  target_size=(300, 300),\n",
        "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
        "\n",
        "# Get the true labels for the test data\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Get the class labels for the test data\n",
        "class_labels = list(test_generator.class_indices.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJHYpwabU_Te",
        "outputId": "3f3e17cc-27ef-4b7a-fe7d-17ced94e8aef"
      },
      "id": "WJHYpwabU_Te",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mHQ3I2GEQGI",
        "outputId": "1ef650b4-80de-4591-cb37-f54db69f6285"
      },
      "id": "6mHQ3I2GEQGI",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "# Generate classification report\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
      ],
      "metadata": {
        "id": "2QCjzR5zWBBq"
      },
      "id": "2QCjzR5zWBBq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "# sns.set(font_scale=1.2)  # Adjust font size for better visualization\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('/content/graphs/confusion_matrix.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4V1M4739ViQf"
      },
      "id": "4V1M4739ViQf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e9b698d-9a7e-4a43-bbe6-ddf7edc6b05c",
      "metadata": {
        "id": "2e9b698d-9a7e-4a43-bbe6-ddf7edc6b05c"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf75ef6-e7f3-4e5e-aa4c-88a93cbc6d87",
      "metadata": {
        "id": "fdf75ef6-e7f3-4e5e-aa4c-88a93cbc6d87",
        "outputId": "b0680cd3-d422-49f6-abb3-23f1af972202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/models/4_1_resnet152_garbage_classification_6_classes_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "0024dba9-a088-412c-b01c-87e7da4ddc7d",
      "metadata": {
        "id": "0024dba9-a088-412c-b01c-87e7da4ddc7d"
      },
      "outputs": [],
      "source": [
        "with open('/content/models/histories/5_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a19fa0e8-6098-41f8-9901-09e18d152bce",
        "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
        "QtwmTbl9PK5u",
        "ff87ed02-b353-41ff-a831-495238d0361b",
        "jH-5MYFlPiGG",
        "oewmXvvYPoS2",
        "cwXhFVwTUYPI",
        "a9d3365a-13fe-480a-b5a1-a73191acca39",
        "e59dd5b1-3054-4e06-a376-42362774907a",
        "158972c1-8c86-45a5-a767-c7b37b1b6608",
        "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
        "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
        "50d2c56e-aac4-4403-a89c-177d7584ca76",
        "mQE7_geHaYNI",
        "rMRZMug1axTK",
        "SVoc99d2bFV6",
        "r1oj75sjbMPq",
        "Nq6an5m7bYeU",
        "xN_CBfSMbsNy",
        "wTLkX5eyb3ny",
        "URnp4hbnb_kD",
        "b8QlRMm8cQHR",
        "M6N_HmcbcdN6",
        "OvIN0bJrdWjL",
        "auf2c59BdgWR",
        "bkNIrE5i9yff",
        "5xs5E4lc92xt",
        "rwEBRaCz-A13",
        "QQTigweq-QHk",
        "LhPjOZiNuN0O",
        "Wm0HzUnim4GY",
        "S1YCpPVUryl2",
        "iDPvcoMgseEW",
        "NdonW8OusrtF",
        "Lxd7HGmlsyRc",
        "oZNmeaEis_M9",
        "PLEmuhGMtKR2",
        "3CXocmX_tJRk",
        "zLqDaHmgtgTd",
        "lADCJADjtvxU",
        "xPP3kC0vuLgD",
        "Y1qLJ2g506nN",
        "5h2Ggtv72gdt",
        "m0g3W4Fr6lR2",
        "9uPP8ROm7bB9",
        "YEiPqicE3SOv",
        "HtK1_C35Rcjy"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}