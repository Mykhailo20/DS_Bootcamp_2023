{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b",
   "metadata": {
    "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b"
   },
   "source": [
    "### Link to the dataset: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RKCaaWRKQye8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "RKCaaWRKQye8",
    "outputId": "d22d83c3-58c0-4d9a-db54-ec3b2aaab5b2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload the Kaggle API key file (kaggle.json) that you downloaded from Kaggle\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move the uploaded API key to the required directory\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143vln3rRExD",
   "metadata": {
    "id": "143vln3rRExD"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CRRvWPlURJXy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRRvWPlURJXy",
    "outputId": "636b947f-e6da-40e7-faf9-cbde4ea2b8c8"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d asdasdasasdas/garbage-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qFh2FFk3RQID",
   "metadata": {
    "id": "qFh2FFk3RQID"
   },
   "outputs": [],
   "source": [
    "!unzip garbage-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qW8DMdNSxlEF",
   "metadata": {
    "id": "qW8DMdNSxlEF"
   },
   "outputs": [],
   "source": [
    "!pip install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c",
   "metadata": {
    "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fa0e8-6098-41f8-9901-09e18d152bce",
   "metadata": {
    "id": "a19fa0e8-6098-41f8-9901-09e18d152bce"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
   "metadata": {
    "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47"
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979887c5-9518-4f9b-860a-9f6e586085fd",
   "metadata": {
    "id": "979887c5-9518-4f9b-860a-9f6e586085fd"
   },
   "outputs": [],
   "source": [
    "def create_train_valid_test_dirs(root_path, subdir_names, train_valid_test_names=['train', 'valid', 'test']):\n",
    "    \"\"\" Function for creating separate folders that contain data for training, validation and testing of the model\n",
    "    Args:\n",
    "        1) root_path - the path to the parent folder in which you want to create subfolders\n",
    "        2) subdir_names - a list of label class names (subfolders with the specified names will be created in each of the train, valid, and test folders)\n",
    "        3) train_valid_test_names - a list of names of training, validation and test samples\n",
    "    Returns:\n",
    "        None; but creates folders\n",
    "    \"\"\"\n",
    "    parent_directories = []\n",
    "    for dir_name in train_valid_test_names:\n",
    "        parent_directories.append(os.path.join(root_path, dir_name))\n",
    "\n",
    "    for directory in parent_directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for subdirectory in subdir_names:\n",
    "            subdir_name = os.path.join(directory + '/', subdirectory)\n",
    "            if not os.path.exists(subdir_name):\n",
    "                os.makedirs(subdir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d",
   "metadata": {
    "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d"
   },
   "outputs": [],
   "source": [
    "def split_data(source_dir_path, train_dir_path, valid_dir_path, test_dir_path, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
    "    \"\"\" Function to split the files of the specified folder into training, validation and test samples by copying\n",
    "    the files from source_dir_path to the corresponding folders\n",
    "    Args:\n",
    "        1) source_dir_path - the path to the folder containing the original data to be split into train/valid/test\n",
    "        2) train_dir_path - the path to the folder that will contain the training data\n",
    "        3) valid_dir_path - the path to the folder that will contain the validation data\n",
    "        4) test_dir_path - the path to the folder that will contain the test data\n",
    "        5) train_test_split - the ratio between training and test samples ([0; 1])\n",
    "        6) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
    "        7) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
    "    Returns:\n",
    "        None, but split the files into training, validation and test samples\n",
    "    \"\"\"\n",
    "    fnames = os.listdir(source_dir_path)\n",
    "\n",
    "    processed_fnames = []\n",
    "    for file_name in fnames:\n",
    "        if os.path.getsize(os.path.join(source_dir_path, file_name)) > 0:\n",
    "            processed_fnames.append(file_name)\n",
    "        else:\n",
    "            print(f'{file_name} is zero length, so ignoring.')\n",
    "\n",
    "    if random_sample:\n",
    "        processed_fnames = random.sample(processed_fnames, len(processed_fnames))\n",
    "\n",
    "    split_index = int(train_test_split * len(processed_fnames))\n",
    "    train_valid_files = processed_fnames[:split_index]\n",
    "    test_files = processed_fnames[split_index:]\n",
    "\n",
    "    split_index = int(train_valid_split * len(train_valid_files))\n",
    "    train_files = train_valid_files[:split_index]\n",
    "    valid_files = train_valid_files[split_index:]\n",
    "\n",
    "    # Copy training files\n",
    "    for file in train_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(train_dir_path, file)\n",
    "        copyfile(source, destination)\n",
    "\n",
    "    # Copy validation files\n",
    "    for file in valid_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(valid_dir_path, file)\n",
    "        copyfile(source, destination)\n",
    "\n",
    "    # Copy test files\n",
    "    for file in test_files:\n",
    "        source = os.path.join(source_dir_path, file)\n",
    "        destination = os.path.join(test_dir_path, file)\n",
    "        copyfile(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75baf0-c207-4220-bcb3-2f936d00049d",
   "metadata": {
    "id": "da75baf0-c207-4220-bcb3-2f936d00049d"
   },
   "outputs": [],
   "source": [
    "def split_class_data(source_dir_path, train_valid_test_paths, class_dir_name, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
    "    \"\"\" Function for dividing the data of one label class into train/valid/test\n",
    "    Args:\n",
    "        1) source_dir_path - the path to the folder containing the original data of all label classes which needs to be splitted into train/valid/test;\n",
    "        2) train_valid_test_paths - the list of paths to the folders of training, validation and test samples\n",
    "        (the paths are specified in this order: train, valid, test)\n",
    "        3) class_dir_name - the name of the folder that contains the label class data\n",
    "        4) train_test_split - the ratio between training and test samples ([0; 1])\n",
    "        5) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
    "        6) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
    "    Returns:\n",
    "        None, but split the files of label class into training, validation and test samples\n",
    "    \"\"\"\n",
    "    train_dir_path_class = os.path.join(train_valid_test_paths[0], class_dir_name)\n",
    "    valid_dir_path_class = os.path.join(train_valid_test_paths[1], class_dir_name)\n",
    "    test_dir_path_class = os.path.join(train_valid_test_paths[2], class_dir_name)\n",
    "    source_dir_path_class = os.path.join(source_dir_path, class_dir_name)\n",
    "    split_data(source_dir_path=source_dir_path_class, train_dir_path=train_dir_path_class, valid_dir_path=valid_dir_path_class,\n",
    "               test_dir_path=test_dir_path_class,\n",
    "               train_test_split=train_test_split, train_valid_split=train_valid_split, random_sample=random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QtwmTbl9PK5u",
   "metadata": {
    "id": "QtwmTbl9PK5u"
   },
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uDa_N5C5PKbQ",
   "metadata": {
    "id": "uDa_N5C5PKbQ"
   },
   "outputs": [],
   "source": [
    "def display_image(img, title=None):\n",
    "    \"\"\" Function to display an image\n",
    "    Args:\n",
    "        1) img - image object\n",
    "        2) title - the title that will be displayed above the image\n",
    "    Returns:\n",
    "        None; but displays an image\n",
    "    \"\"\"\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GnJCHNEDPWLG",
   "metadata": {
    "id": "GnJCHNEDPWLG"
   },
   "outputs": [],
   "source": [
    "def display_original_augmented_img(original_img, augmented_img, original_title=None, augmented_title=None):\n",
    "    \"\"\" Function to display the original and augmented image on the same graph\n",
    "    Args:\n",
    "        1) original_img - object of the original image\n",
    "        2) augmented_img - augmented image object\n",
    "        3) original_title - title for the original image\n",
    "        4) augmented_title - title for the augmented image\n",
    "    Returns:\n",
    "        None; but displays images\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title(original_title)\n",
    "\n",
    "    axes[1].imshow(augmented_img)\n",
    "    axes[1].set_title(augmented_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87ed02-b353-41ff-a831-495238d0361b",
   "metadata": {
    "id": "ff87ed02-b353-41ff-a831-495238d0361b",
    "tags": []
   },
   "source": [
    "## Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_cc_OjlNRHcM",
   "metadata": {
    "id": "_cc_OjlNRHcM"
   },
   "outputs": [],
   "source": [
    "def load_display_image(root_path, image_name, title=None):\n",
    "    \"\"\" Function to display an image\n",
    "    Args:\n",
    "        1) root_path - the path to the folder that contains the image\n",
    "        2) image_name - the name of the image\n",
    "        3) title - the title that will be displayed above the image\n",
    "    Returns:\n",
    "        None; but displays an image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(os.path.join(root_path, image_name))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4",
   "metadata": {
    "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4"
   },
   "outputs": [],
   "source": [
    "def display_pie_chart(df, column_name, title=None, column_contains_count=False, filename=None):\n",
    "    \"\"\" Function to display the percentage ratio of column (with the name column_name) content\n",
    "    Args:\n",
    "        1) df - the original dataframe that contains the required information\n",
    "        2) column_name - the name of the df dataframe column whose percentage values are to be found\n",
    "        3) title - the title of the graph\n",
    "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
    "        5) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        None, but plots graph\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of each activity in original_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_df = df[column_name] / sum(df[column_name])\n",
    "    else:\n",
    "        activity_percentages_df = df[column_name].value_counts(normalize=True) * 100\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot pie chart for df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    plt.pie(activity_percentages_df, labels=activity_percentages_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_pie_charts(first_df, second_df, column, column_contains_count=False, first_chart_title='First DataFrame', second_chart_title='Second DataFrame', filename=None):\n",
    "    \"\"\"Function for displaying the ratio of column content between two dataframes in the form of pie charts\n",
    "    Args:\n",
    "        1) first_df - the original dataframe that contains the required information\n",
    "        2) second_df - a dataframe that contains the results of windowing\n",
    "        3) column - the name of the dataframe column whose percentage values are to be found\n",
    "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
    "        5) first_chart_title - the title for the first pie chart\n",
    "        6) second_chart_title - the title for the second pie chart\n",
    "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    Returns:\n",
    "        None; just builds a pie chart to display the ratio of column contents between two dataframes\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of each activity in first_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_first_df = first_df[column] / sum(first_df[column]) * 100\n",
    "    else:\n",
    "        activity_percentages_first_df = first_df[column].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Calculate the percentage of each activity in second_df\n",
    "    if column_contains_count:\n",
    "        activity_percentages_second_df = second_df[column] / sum(second_df[column]) * 100\n",
    "    else:\n",
    "        activity_percentages_second_df = second_df[column].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Create subplots for pie charts\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot pie chart for df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    axes[0].pie(activity_percentages_first_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    axes[0].set_title(first_chart_title)\n",
    "\n",
    "    # Plot pie chart for windowed_df\n",
    "    sns.set_palette(\"Set3\")\n",
    "    axes[1].pie(activity_percentages_second_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
    "    axes[1].set_title(second_chart_title)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jH-5MYFlPiGG",
   "metadata": {
    "id": "jH-5MYFlPiGG"
   },
   "source": [
    "## Perform image augmentation using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0iT7IBC51ely",
   "metadata": {
    "id": "0iT7IBC51ely"
   },
   "outputs": [],
   "source": [
    "def get_ImageDataGen_image(imageDataGenerator, image):\n",
    "  \"\"\" Function that returns an image augmented with imageDataGenerator\n",
    "  Args:\n",
    "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
    "    2) image - an image passed as a numpy array\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  x = image.copy()\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  for batch in imageDataGenerator.flow(x, batch_size=1):\n",
    "      augmented_image=batch[0].copy().astype(np.uint8)\n",
    "      break\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kdVdixQDPhmW",
   "metadata": {
    "id": "kdVdixQDPhmW"
   },
   "outputs": [],
   "source": [
    "def perform_ImageDataGen_augmentation(imageDataGenerator, images, image_filenames, target_size,\n",
    "                                      augm_prefix, num_augm_images=3, augm_images_dir_path=None,\n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) imageDataGenerator - ImageDataGenerator class object\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    augmented_index = 0\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        x = img.copy()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            i += 1\n",
    "            if i > num_augm_images:\n",
    "                augmented_index = 0\n",
    "                break\n",
    "\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "\n",
    "            augmented_index += 1\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                # tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(batch[0].copy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=batch[0].copy().astype(np.uint8),\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oewmXvvYPoS2",
   "metadata": {
    "id": "oewmXvvYPoS2"
   },
   "source": [
    "## Perform image augmentation using CV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5PxQiefcUULF",
   "metadata": {
    "id": "5PxQiefcUULF"
   },
   "source": [
    "### Augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l42CveFAPquW",
   "metadata": {
    "id": "l42CveFAPquW"
   },
   "outputs": [],
   "source": [
    "def get_width_shift_image(image, width_shift_fraction):\n",
    "    \"\"\" Function for performing width_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) width_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    width_shift = int(height * width_shift_fraction)\n",
    "\n",
    "    # Calculate the new y-coordinate for height shift\n",
    "    y_shifted = height // 2 + width_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, 0], [0, 1, width_shift]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yjmv3HHoPtqd",
   "metadata": {
    "id": "yjmv3HHoPtqd"
   },
   "outputs": [],
   "source": [
    "def get_height_shift_image(image, height_shift_fraction):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) height_shift_fraction - offset value ([-1; 1])\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Get the height and width of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the height shift value\n",
    "    height_shift = int(width * height_shift_fraction)\n",
    "\n",
    "    # Calculate the new x-coordinate for height shift\n",
    "    x_shifted = width // 2 + height_shift\n",
    "\n",
    "    # Calculate the rotation matrix for height shift\n",
    "    shift_matrix = np.float32([[1, 0, height_shift], [0, 1, 0]])\n",
    "\n",
    "    # Apply the height shift to the image using warpAffine\n",
    "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
    "    return changed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eG8FTDtWPwGe",
   "metadata": {
    "id": "eG8FTDtWPwGe"
   },
   "outputs": [],
   "source": [
    "def get_brightness_augmentation_image(image, brightness_range=(0.5, 1.5)):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Generate a random brightness factor within the specified range\n",
    "    brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "\n",
    "    # Adjust the brightness by scaling the V channel\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)\n",
    "\n",
    "    # Convert the image back to the original color space (BGR)\n",
    "    augmented_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2tYCvwyDPx3V",
   "metadata": {
    "id": "2tYCvwyDPx3V"
   },
   "outputs": [],
   "source": [
    "def get_contrast_augmentation_image(image, contrast_factor):\n",
    "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) contrast_factor - adjusts the contrast of the image by applying CLAHE; possible values: [1.0; 4.0]\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into L, A, and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=contrast_factor, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "\n",
    "    # Convert the LAB image back to BGR color space\n",
    "    contrast_augmented_image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return contrast_augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KqcGVI2NP1j-",
   "metadata": {
    "id": "KqcGVI2NP1j-"
   },
   "outputs": [],
   "source": [
    "def get_hsv_image(image, hue_shift, saturation_scale=1, value_scale=1):\n",
    "    \"\"\" Function to change the color tone of the image when switching to the HSV model\n",
    "    Args:\n",
    "        1) image - image object\n",
    "        2) hue_shift - the value of the Hue parameter of the hsv model; possible values: [0; 179] (OpenCV)\n",
    "        3) saturation_scale - coefficient by which the Saturation parameter of the HSV model will be multiplied\n",
    "        4) value_scale - coefficient by which the Value parameter of the HSV model will be multiplied\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    # Convert the original image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the hue shift to the hue channel\n",
    "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
    "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_scale, 0, 255)\n",
    "    hsv_image[:, :, 2] = np.clip(hsv_image[:, :, 2] * value_scale, 0, 255)\n",
    "\n",
    "    # Convert the image back to the RGB color space\n",
    "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GYnBKRn51YfT",
   "metadata": {
    "id": "GYnBKRn51YfT"
   },
   "outputs": [],
   "source": [
    "def get_noisy_image(image, mean=1, std_dev=0.7):\n",
    "    \"\"\" Function for adding random noise to the image 'image'\n",
    "    Args:\n",
    "        1) image - an image passed as a numpy array\n",
    "        2) mean - the mean value of the noise\n",
    "        3) std_dev - the standard deviation of the noise (the larger the std_dev, the more intense the noise will be)\n",
    "    Returns:\n",
    "        augmented_image\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(mean, std_dev, image.shape).astype('uint8')\n",
    "    augmented_image = cv2.add(image, noise)\n",
    "\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mGnfBhhQ1jJI",
   "metadata": {
    "id": "mGnfBhhQ1jJI"
   },
   "outputs": [],
   "source": [
    "def remove_background(input_path, output_path=None):\n",
    "    \"\"\" Function to remove the background from the image\n",
    "    Args:\n",
    "      1) input_path - the path to the image whose background should be removed\n",
    "      2) output_path - the path to save an image without a background\n",
    "    Returns:\n",
    "      Image without background\n",
    "    \"\"\"\n",
    "     # Processing the image\n",
    "    input_image = Image.open(input_path)\n",
    "\n",
    "    # Removing the background from the given Image\n",
    "    output_image = remove(input_image)\n",
    "\n",
    "    # Convert the output image to RGB mode (removing transparency)\n",
    "    output_image = output_image.convert(\"RGB\")\n",
    "\n",
    "    if output_path:\n",
    "      # Save the image with the background removed\n",
    "      output_image.save(output_path)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LEuXuDQ51nfo",
   "metadata": {
    "id": "LEuXuDQ51nfo"
   },
   "outputs": [],
   "source": [
    "def get_background_image(image, background_image, source_path, image_name, no_background_output_path=None):\n",
    "  \"\"\" Function to replace the background of the original image with the background image background_image\n",
    "  Args:\n",
    "    1) image - an image passed as a numpy array\n",
    "    2) background_image - a background image passed as a numpy array\n",
    "    3) source_path - path to image 'image'\n",
    "    4) image_name - name of the image 'image'\n",
    "    5) no_background_output_path - the path (along with the image name) to store the original image without the background\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  if no_background_output_path is not None:\n",
    "    pil_image = remove_background(input_path=os.path.join(source_path, image_name),\n",
    "                    output_path=os.path.join(no_background_output_path, image_name))\n",
    "  else:\n",
    "    pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
    "\n",
    "  augmented_image = background_image.copy()\n",
    "\n",
    "  # Convert PIL image to OpenCV format (NumPy array)\n",
    "  image_without_background = np.array(pil_image)\n",
    "\n",
    "  mask = cv2.cvtColor(image_without_background, cv2.COLOR_BGR2GRAY)\n",
    "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "  mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "  garbage_area = cv2.bitwise_and(image_without_background, image_without_background, mask=mask)\n",
    "  background_area = cv2.bitwise_and(augmented_image, augmented_image, mask=mask_inv)\n",
    "  augmented_image = cv2.add(garbage_area, background_area)\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zwbR-nZX1rJl",
   "metadata": {
    "id": "zwbR-nZX1rJl"
   },
   "outputs": [],
   "source": [
    "def get_augmented_background_image(imageDataGenerator, image, background_image, source_path, image_name):\n",
    "  \"\"\" Function that returns a new augmented image (eg reduced in size) with a new background\n",
    "  Args:\n",
    "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
    "    2) image - an image passed as a numpy array\n",
    "    3) background_image - a background image passed as a numpy array\n",
    "    4) source_path -  path to image 'image'\n",
    "    5) image_name - name of the image 'image'\n",
    "  Returns:\n",
    "    augmented_image\n",
    "  \"\"\"\n",
    "  pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
    "\n",
    "  # Convert PIL image to OpenCV format (NumPy array)\n",
    "  image_without_background = np.array(pil_image)\n",
    "\n",
    "  changed_image = get_ImageDataGen_image(imageDataGenerator=imageDataGenerator,\n",
    "                                         image=image_without_background)\n",
    "\n",
    "  mask = cv2.cvtColor(changed_image, cv2.COLOR_BGR2GRAY)\n",
    "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "  mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "  garbage_area = cv2.bitwise_and(changed_image, changed_image, mask=mask)\n",
    "  augmented_image = background_image.copy()\n",
    "  background_area = cv2.bitwise_and(augmented_image, augmented_image,\n",
    "                                  mask=mask_inv)\n",
    "  augmented_image = cv2.add(garbage_area, background_area)\n",
    "\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cwXhFVwTUYPI",
   "metadata": {
    "id": "cwXhFVwTUYPI"
   },
   "source": [
    "### Augmentation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OBXdj3gTUbgd",
   "metadata": {
    "id": "OBXdj3gTUbgd"
   },
   "outputs": [],
   "source": [
    "def perform_cv2_rotation_augmentation(rotation_range, images, image_filenames,\n",
    "                                      target_size, augm_prefix,\n",
    "                                      num_augm_images=3, augm_images_dir_path=None,\n",
    "                                      save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) rotation_range - the range (a list of two elements: [range_min; range_max]) in which the angle value will change linearly (depending on num_augm_images)\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "    height = target_size[0]\n",
    "    width = target_size[1]\n",
    "    angle_increment = int((rotation_range[1] - rotation_range[0]) / num_augm_images)\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        angle = rotation_range[0]\n",
    "        for i in range(num_augm_images):\n",
    "            # Calculate the rotation matrix\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "\n",
    "            # Apply the rotation to the image using warpAffine\n",
    "            augmented_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "            angle += angle_increment\n",
    "            if angle == 0:\n",
    "                angle += angle_increment\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augm_images_dir_path, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augm_images_dir_path, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAaU8XHhUeAG",
   "metadata": {
    "id": "dAaU8XHhUeAG"
   },
   "outputs": [],
   "source": [
    "def perform_cv2_flip_augmentation(flip_code, images, image_filenames,\n",
    "                                  target_size, augm_prefix,\n",
    "                                  num_augm_images=3, augm_images_dir_path=None,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False):\n",
    "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
    "    Args:\n",
    "        1) flip_code - the type of flip augmentation to perform on the image: 0 - vertical, 1 - horizontal\n",
    "        2) images - a list of images, each of which is stored as a numpy array\n",
    "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
    "        4) target_size - the size of the images\n",
    "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
    "        6) num_augm_images - the number of instances of augmented images for one original\n",
    "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
    "        8) save_augm_image - whether to save the augmented image\n",
    "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
    "    Returns:\n",
    "        None; but saves or displays augmented_images\n",
    "    \"\"\"\n",
    "\n",
    "    for (image_name, img) in zip(image_filenames, images):\n",
    "        augmented_index = 0\n",
    "        for i in range(num_augm_images):\n",
    "            augmented_image = cv2.flip(img.copy(), flip_code)\n",
    "\n",
    "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
    "            augmented_index += 1\n",
    "\n",
    "            if save_augm_image and (augm_images_dir_path is not None):\n",
    "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "            if display_orig_augm_images:\n",
    "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
    "                                               original_title=f\"Original_image: {image_name}\",\n",
    "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c",
   "metadata": {
    "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba",
   "metadata": {
    "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, strings, filename=None):\n",
    "    \"\"\"Function to plot graphs for two training history parameters (eg accuracy and loss)\n",
    "    Args:\n",
    "        1) history - model training history\n",
    "        2) strings - an array of names of history parameters (only the data of the first two history parameters specified in this array will be taken for graphing)\n",
    "        3) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].plot(history.history[strings[0]], label=strings[0])\n",
    "    axes[0].plot(history.history[f\"val_{strings[0]}\"], label=f\"val_{strings[0]}\")\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel(strings[0])\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(history.history[strings[1]], label=strings[1])\n",
    "    axes[1].plot(history.history[f\"val_{strings[1]}\"], label=f\"val_{strings[1]}\")\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel(strings[1])\n",
    "    axes[1].legend()\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(f\"{filename}.png\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
   "metadata": {
    "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089707ba-256c-4e27-9a65-c764999f41ac",
   "metadata": {
    "id": "089707ba-256c-4e27-9a65-c764999f41ac"
   },
   "outputs": [],
   "source": [
    "source_path = '/content/Garbage classification/Garbage classification'\n",
    "\n",
    "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
    "source_path_glass = os.path.join(source_path, 'glass')\n",
    "source_path_metal = os.path.join(source_path, 'metal')\n",
    "source_path_paper = os.path.join(source_path, 'paper')\n",
    "source_path_plastic = os.path.join(source_path, 'plastic')\n",
    "source_path_trash = os.path.join(source_path, 'trash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808b080-50b3-423d-aca4-60fc14129e79",
   "metadata": {
    "id": "6808b080-50b3-423d-aca4-60fc14129e79"
   },
   "outputs": [],
   "source": [
    "cardboard_image_names = os.listdir(source_path_cardboard)\n",
    "glass_image_names = os.listdir(source_path_glass)\n",
    "metal_image_names = os.listdir(source_path_metal)\n",
    "paper_image_names = os.listdir(source_path_paper)\n",
    "plastic_image_names = os.listdir(source_path_plastic)\n",
    "trash_image_names = os.listdir(source_path_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
    "outputId": "a0867dab-cc49-4ea5-aa46-8bc14972b0c3"
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(cardboard_image_names)} images of cardboard.\") # 403\n",
    "print(f\"There are {len(glass_image_names)} images of glass.\") # 501\n",
    "print(f\"There are {len(metal_image_names)} images of metal.\") # 410\n",
    "print(f\"There are {len(paper_image_names)} images of paper.\") # 594\n",
    "print(f\"There are {len(plastic_image_names)} images of plastic.\") # 482\n",
    "print(f\"There are {len(trash_image_names)} images of trash.\") # 137"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3365a-13fe-480a-b5a1-a73191acca39",
   "metadata": {
    "id": "a9d3365a-13fe-480a-b5a1-a73191acca39"
   },
   "source": [
    "## Display classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
    "outputId": "2ceb8fbf-79c3-4db2-f479-05cacc0c2e6d"
   },
   "outputs": [],
   "source": [
    "classes_representatives = {'cardboard': len(cardboard_image_names),\n",
    "                           'glass': len(glass_image_names),\n",
    "                           'metal': len(metal_image_names),\n",
    "                           'paper': len(paper_image_names),\n",
    "                           'plastic': len(plastic_image_names),\n",
    "                           'trash': len(trash_image_names)\n",
    "                          }\n",
    "for label_class in classes_representatives.keys():\n",
    "    print(f\"There are {classes_representatives[label_class]} images of {label_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
    "outputId": "63c8e93a-abbc-4fea-97aa-c0016531e3e8"
   },
   "outputs": [],
   "source": [
    "classes_df = pd.DataFrame(list(classes_representatives.items()), columns=['class', 'count'])\n",
    "classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be70e4-b5f7-4d75-8f22-3523543856c1",
   "metadata": {
    "id": "95be70e4-b5f7-4d75-8f22-3523543856c1"
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.barplot(data=classes_df, x='class', y='count')\n",
    "plt.title('The number of representatives of the label class (Original dataset)')\n",
    "# plt.savefig('graphs/original_barplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc",
   "metadata": {
    "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=classes_df, column_name='count', title='Percentage ratio between label classes (Original dataset)',\n",
    "                  column_contains_count=True) # filename='graphs/original_piechart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59dd5b1-3054-4e06-a376-42362774907a",
   "metadata": {
    "id": "e59dd5b1-3054-4e06-a376-42362774907a",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Display representatives of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
   "metadata": {
    "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
    "tags": []
   },
   "source": [
    "### Cardboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d",
   "metadata": {
    "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d"
   },
   "outputs": [],
   "source": [
    "for cardboard_image_name in cardboard_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_cardboard, image_name=cardboard_image_name, title=cardboard_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
   "metadata": {
    "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
    "tags": []
   },
   "source": [
    "### Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f",
   "metadata": {
    "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f"
   },
   "outputs": [],
   "source": [
    "for glass_image_name in glass_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_glass, image_name=glass_image_name, title=glass_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
   "metadata": {
    "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
    "tags": []
   },
   "source": [
    "### Metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111dde7-c214-4c69-aa42-58c907e167d8",
   "metadata": {
    "id": "d111dde7-c214-4c69-aa42-58c907e167d8"
   },
   "outputs": [],
   "source": [
    "for metal_image_name in metal_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_metal, image_name=metal_image_name, title=metal_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
   "metadata": {
    "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
    "tags": []
   },
   "source": [
    "### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095e9ea-86af-404e-969d-d077462c81b4",
   "metadata": {
    "id": "0095e9ea-86af-404e-969d-d077462c81b4"
   },
   "outputs": [],
   "source": [
    "for paper_image_name in paper_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_paper, image_name=paper_image_name, title=paper_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
   "metadata": {
    "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
    "tags": []
   },
   "source": [
    "### Plastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05",
   "metadata": {
    "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05"
   },
   "outputs": [],
   "source": [
    "for plastic_image_name in plastic_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_plastic, image_name=plastic_image_name, title=plastic_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
   "metadata": {
    "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
    "tags": []
   },
   "source": [
    "### Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6",
   "metadata": {
    "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6"
   },
   "outputs": [],
   "source": [
    "for trash_image_name in trash_image_names[:5]:\n",
    "    load_display_image(root_path=source_path_trash, image_name=trash_image_name, title=trash_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
   "metadata": {
    "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split data into train, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39",
   "metadata": {
    "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39"
   },
   "source": [
    "## Create folders for train/valid/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0",
   "metadata": {
    "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0"
   },
   "outputs": [],
   "source": [
    "destination_path = '/content/garbage_classification_TrainValidTest/'\n",
    "\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "create_train_valid_test_dirs(root_path=destination_path, subdir_names=garbage_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce8b08-d600-431e-9365-395f20cf0402",
   "metadata": {
    "id": "70ce8b08-d600-431e-9365-395f20cf0402"
   },
   "source": [
    "## Split the data and save it in the appropriate folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
   "metadata": {
    "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Split classes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
    "outputId": "c07ffd1d-845e-48f1-ac9e-f48837b18dbf"
   },
   "outputs": [],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
    "\n",
    "for class_name in garbage_class_names:\n",
    "    split_class_data(source_dir_path=source_path, train_valid_test_paths=train_valid_test_paths,\n",
    "                 class_dir_name=class_name, train_test_split=0.9, train_valid_split=0.85, random_sample=False)\n",
    "\n",
    "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
    "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
    "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
    "\n",
    "    print(f\"{class_name}: train = {len(class_train_images)}\")\n",
    "    print(f\"{class_name}: valid = {len(class_valid_images)}\")\n",
    "    print(f\"{class_name}: test = {len(class_test_images)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
   "metadata": {
    "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef"
   },
   "source": [
    "#### Check classes distribution after spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51",
   "metadata": {
    "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51"
   },
   "outputs": [],
   "source": [
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "classes_train_dict = {}\n",
    "classes_valid_dict = {}\n",
    "classes_test_dict = {}\n",
    "for class_name in garbage_class_names:\n",
    "    classes_train_dict[class_name] = 0\n",
    "    classes_valid_dict[class_name] = 0\n",
    "    classes_test_dict[class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
    "outputId": "87c457d8-c029-4738-bf57-f94a0c89f428"
   },
   "outputs": [],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
    "\n",
    "for class_name in garbage_class_names:\n",
    "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
    "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
    "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
    "\n",
    "    classes_train_dict[class_name] = len(class_train_images)\n",
    "    classes_valid_dict[class_name] = len(class_valid_images)\n",
    "    classes_test_dict[class_name] = len(class_test_images)\n",
    "\n",
    "print(f\"classes_train_dict = {classes_train_dict}\")\n",
    "print(f\"classes_valid_dict = {classes_valid_dict}\")\n",
    "print(f\"classes_test_dict = {classes_test_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
    "outputId": "886f2cdc-c551-468a-f9c8-9b5c8ba39a99"
   },
   "outputs": [],
   "source": [
    "train_classes_df = pd.DataFrame(list(classes_train_dict.items()), columns=['class', 'count'])\n",
    "valid_classes_df = pd.DataFrame(list(classes_valid_dict.items()), columns=['class', 'count'])\n",
    "test_classes_df = pd.DataFrame(list(classes_test_dict.items()), columns=['class', 'count'])\n",
    "\n",
    "train_classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2",
   "metadata": {
    "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2"
   },
   "source": [
    "##### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4",
   "metadata": {
    "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=train_classes_df, column_name='count', title='Percentage ratio between label classes (Train dataset)',\n",
    "                  column_contains_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3",
   "metadata": {
    "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=train_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Train Data',\n",
    "                   filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae",
   "metadata": {
    "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae"
   },
   "source": [
    "##### Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c742c2-33f7-436e-bd50-aeb229afbf10",
   "metadata": {
    "id": "93c742c2-33f7-436e-bd50-aeb229afbf10"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=valid_classes_df, column_name='count', title='Percentage ratio between label classes (Validation dataset)',\n",
    "                  column_contains_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26",
   "metadata": {
    "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=valid_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Valid Data',\n",
    "                   filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2c56e-aac4-4403-a89c-177d7584ca76",
   "metadata": {
    "id": "50d2c56e-aac4-4403-a89c-177d7584ca76"
   },
   "source": [
    "##### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592",
   "metadata": {
    "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592"
   },
   "outputs": [],
   "source": [
    "display_pie_chart(df=test_classes_df, column_name='count', title='Percentage ratio between label classes (Test dataset)',\n",
    "                  column_contains_count=True, filename='graphs/test_piechart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a51dc2-dff2-408c-818d-9e9b052699a6",
   "metadata": {
    "id": "81a51dc2-dff2-408c-818d-9e9b052699a6"
   },
   "outputs": [],
   "source": [
    "display_pie_charts(first_df=classes_df, second_df=test_classes_df, column='count',\n",
    "                   column_contains_count=True,\n",
    "                   first_chart_title='Original Data', second_chart_title='Test Data',\n",
    "                   filename='graphs/original_vs_test_piecharts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mQE7_geHaYNI",
   "metadata": {
    "id": "mQE7_geHaYNI"
   },
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iF2NpBGwTgKy",
   "metadata": {
    "id": "iF2NpBGwTgKy"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2tXUGWXkTfKY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tXUGWXkTfKY",
    "outputId": "bd6a1c58-1dba-4f85-fc1a-40f1046c90fb"
   },
   "outputs": [],
   "source": [
    "image_classes_filepaths = [train_dir_path + 'cardboard', train_dir_path + 'glass',\n",
    "                           train_dir_path + 'metal', train_dir_path + 'paper',\n",
    "                           train_dir_path + 'plastic', train_dir_path + 'trash']\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "show_images = False\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "  image_filenames = os.listdir(image_filepath)\n",
    "\n",
    "  for image_name in image_filenames:\n",
    "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      garbage_class_images[garbage_class_name].append(img)\n",
    "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
    "\n",
    "      if show_images:\n",
    "          display_image(img, title=image_name)\n",
    "\n",
    "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3czvCJIWO6O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3czvCJIWO6O",
    "outputId": "728fe547-054b-4c31-a807-2cab74a44cd6"
   },
   "outputs": [],
   "source": [
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
    "target_size = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49lwYs7vW5X-",
   "metadata": {
    "id": "49lwYs7vW5X-"
   },
   "outputs": [],
   "source": [
    "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMRZMug1axTK",
   "metadata": {
    "id": "rMRZMug1axTK"
   },
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FIayHvfOLeZ1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIayHvfOLeZ1",
    "outputId": "eb18a61c-dad3-4525-e559-0742a40a35f4"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
    "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                  augm_images_dir_path=augmented_images_dir,\n",
    "                                  target_size=target_size,\n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SVoc99d2bFV6",
   "metadata": {
    "id": "SVoc99d2bFV6"
   },
   "source": [
    "### width_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dhGL15Ira2tr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhGL15Ira2tr",
    "outputId": "66e6da66-0e3c-4163-b020-d646aa7490dc"
   },
   "outputs": [],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9--uJ-PkbGH5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9--uJ-PkbGH5",
    "outputId": "e603ee55-d805-4447-d45b-d7bbcc78d3c7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "width_shift_fraction = 0.1\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cl36lkpgeR9X",
   "metadata": {
    "id": "cl36lkpgeR9X"
   },
   "source": [
    "#### Expacted output:\n",
    "cardboard before augmentation: len(images) = 2149;\n",
    "cardboard after augmentation: len(images) = 2149 + 307*2 = 2763\n",
    "\n",
    "glass before augmentation: len(images) = 2674;\n",
    "glass after augmentation: len(images) = 3438\n",
    "\n",
    "metal before augmentation: len(images) = 2191;\n",
    "metal after augmentation: len(images) = 2817\n",
    "\n",
    "paper before augmentation: len(images) = 3171;\n",
    "paper after augmentation: len(images) = 4077\n",
    "\n",
    "plastic before augmentation: len(images) = 2576;\n",
    "plastic after augmentation: len(images) = 3312\n",
    "\n",
    "trash before augmentation: len(images) = 728;\n",
    "trash after augmentation: len(images) = 936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r1oj75sjbMPq",
   "metadata": {
    "id": "r1oj75sjbMPq"
   },
   "source": [
    "### height_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wCysQhwUfG5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCysQhwUfG5f",
    "outputId": "c445f467-bbd2-495c-f705-b24fc1e8a696"
   },
   "outputs": [],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-jqPyxqofQVu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jqPyxqofQVu",
    "outputId": "f8aa356d-3b14-4dad-abc2-f5790cf8ab22"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "height_shift_fraction = 0.10\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nq6an5m7bYeU",
   "metadata": {
    "id": "Nq6an5m7bYeU"
   },
   "source": [
    "### horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Puc6cYtLf49y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Puc6cYtLf49y",
    "outputId": "1fbccabf-1adb-46db-b60b-d43bb026ba6e"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xN_CBfSMbsNy",
   "metadata": {
    "id": "xN_CBfSMbsNy"
   },
   "source": [
    "### vertical_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uk2dbTtnjXPr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk2dbTtnjXPr",
    "outputId": "fdc4ff65-73c7-4596-a1f5-ca4eb4835801"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wTLkX5eyb3ny",
   "metadata": {
    "id": "wTLkX5eyb3ny"
   },
   "source": [
    "### zoom = scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "URnp4hbnb_kD",
   "metadata": {
    "id": "URnp4hbnb_kD"
   },
   "source": [
    "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g127KTuBj3bC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g127KTuBj3bC",
    "outputId": "249d98ce-ce3f-4288-fe16-4f2a198f8c5a"
   },
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(0.8, 1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8QlRMm8cQHR",
   "metadata": {
    "id": "b8QlRMm8cQHR"
   },
   "source": [
    "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8koWMEdEmorg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8koWMEdEmorg",
    "outputId": "c1fbe2f7-7943-461a-a54e-3b7bf2c6eb26"
   },
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1, 1.2),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M6N_HmcbcdN6",
   "metadata": {
    "id": "M6N_HmcbcdN6"
   },
   "source": [
    "### brightness_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LRjIIZx-n-N7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRjIIZx-n-N7",
    "outputId": "84f1da34-9b0e-4053-8599-fd0ef902ad0b"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 0.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_darkBrightness_0.5', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aWSH_5Fioxi1",
   "metadata": {
    "id": "aWSH_5Fioxi1"
   },
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.25, 0.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                  augm_prefix='aug_blackBrightness_0.25', num_augm_images=num_augmented_images,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R-iJpKwQo_hH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-iJpKwQo_hH",
    "outputId": "42bea548-ca23-42c5-bcf6-434eee30d85c"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VLthfnuCpTKv",
   "metadata": {
    "id": "VLthfnuCpTKv"
   },
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.5, 1.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "target_size = (img_height, img_width)\n",
    "\n",
    "num_augmented_images = 1\n",
    "\n",
    "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
    "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                  augm_prefix='aug_ligthBrightness_1.5', num_augm_images=num_augmented_images,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvIN0bJrdWjL",
   "metadata": {
    "id": "OvIN0bJrdWjL"
   },
   "source": [
    "### contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p9iw6kVhpe4g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9iw6kVhpe4g",
    "outputId": "6511360e-7443-40db-835b-bfcf486b0f84"
   },
   "outputs": [],
   "source": [
    "contrast_factor = 2.0\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auf2c59BdgWR",
   "metadata": {
    "id": "auf2c59BdgWR"
   },
   "source": [
    "### color space transformations (HSV) augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgEIQcbTqPIa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgEIQcbTqPIa",
    "outputId": "83adec98-d81e-469d-900b-292ca0ac6082"
   },
   "outputs": [],
   "source": [
    "hue_shift=180\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
    "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkNIrE5i9yff",
   "metadata": {
    "id": "bkNIrE5i9yff"
   },
   "source": [
    "### noise addition augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q0yQQ7L091s1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0yQQ7L091s1",
    "outputId": "7b70dc8a-a0a2-4292-fa35-2a9e299eb2fa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_noisy_image(image=image)\n",
    "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5xs5E4lc92xt",
   "metadata": {
    "id": "5xs5E4lc92xt"
   },
   "source": [
    "### reduce garbage image + background augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpVxOJ_t-HH8",
   "metadata": {
    "id": "wpVxOJ_t-HH8"
   },
   "outputs": [],
   "source": [
    "background_image_filepath = '/content/backgrounds/'\n",
    "background_image_names = os.listdir(background_image_filepath)\n",
    "background_images = []\n",
    "show_images = True\n",
    "\n",
    "for background_image_name in background_image_names:\n",
    "    if '.ipynb' in background_image_name:\n",
    "      continue\n",
    "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
    "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
    "    background_images.append(background_image)\n",
    "\n",
    "    if show_images:\n",
    "        display_image(background_image, title=background_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506V4KEx-AqO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "506V4KEx-AqO",
    "outputId": "7ae6efd2-28d8-4e79-8877-c539a5baf0c8"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1.2, 1.5),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.1\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "    counter = 0\n",
    "    for background_image in background_images:\n",
    "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
    "                                                       image=image,\n",
    "                                                       background_image=background_image,\n",
    "                                                       source_path=image_class_filepath,\n",
    "                                                       image_name=image_name)\n",
    "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
    "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "      counter += 1\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rwEBRaCz-A13",
   "metadata": {
    "id": "rwEBRaCz-A13"
   },
   "source": [
    "### brightness_shift + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aMm3JU0z-P18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMm3JU0z-P18",
    "outputId": "e03e07c3-971a-4d10-a4f1-d05555baf3aa"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.35, 0.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][split_index:], garbage_class_image_names[garbage_class_name][split_index:]):\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QQTigweq-QHk",
   "metadata": {
    "id": "QQTigweq-QHk"
   },
   "source": [
    "### color space transformations (HSV) + brightness + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2lA2U8-j-Ztj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lA2U8-j-Ztj",
    "outputId": "3d2ca254-ea74-4e41-bb78-66eb1bdf0862"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "hue_shift=170\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
    "\n",
    "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hDpVqXyVqtoX",
   "metadata": {
    "id": "hDpVqXyVqtoX"
   },
   "source": [
    "### Save train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I2RYqgC7qsAe",
   "metadata": {
    "id": "I2RYqgC7qsAe"
   },
   "outputs": [],
   "source": [
    "#!zip -r /content/train.zip /content/garbage_classification_TrainValidTest/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vH1WzuiGl9J7",
   "metadata": {
    "id": "vH1WzuiGl9J7"
   },
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhEFaLTPm7sj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhEFaLTPm7sj",
    "outputId": "1088262f-c6ad-4cee-d985-e8fbed773cd1"
   },
   "outputs": [],
   "source": [
    "image_classes_filepaths = [valid_dir_path + 'cardboard', valid_dir_path + 'glass',\n",
    "                           valid_dir_path + 'metal', valid_dir_path + 'paper',\n",
    "                           valid_dir_path + 'plastic', valid_dir_path + 'trash']\n",
    "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
    "show_images = False\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "  image_filenames = os.listdir(image_filepath)\n",
    "\n",
    "  for image_name in image_filenames:\n",
    "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      garbage_class_images[garbage_class_name].append(img)\n",
    "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
    "\n",
    "      if show_images:\n",
    "          display_image(img, title=image_name)\n",
    "\n",
    "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GX3lA1zTrK-N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GX3lA1zTrK-N",
    "outputId": "ee2f1d3f-9025-4dfe-9fd5-cb7b2d4284f3"
   },
   "outputs": [],
   "source": [
    "img_height, img_width = img.shape[:2]\n",
    "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
    "target_size = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LhPjOZiNuN0O",
   "metadata": {
    "id": "LhPjOZiNuN0O"
   },
   "source": [
    "### View image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kW0x9NzFrLpk",
   "metadata": {
    "id": "kW0x9NzFrLpk"
   },
   "outputs": [],
   "source": [
    "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wm0HzUnim4GY",
   "metadata": {
    "id": "Wm0HzUnim4GY"
   },
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3n4ETjxl_px",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3n4ETjxl_px",
    "outputId": "fb8493eb-4408-4b89-b5ec-59c8e43ca905"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
    "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                  augm_images_dir_path=augmented_images_dir,\n",
    "                                  target_size=target_size,\n",
    "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
    "                                  save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S1YCpPVUryl2",
   "metadata": {
    "id": "S1YCpPVUryl2"
   },
   "source": [
    "### width_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QdCBVionsCIl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdCBVionsCIl",
    "outputId": "0e50fa7d-f1c9-44f9-827e-5106fb343675"
   },
   "outputs": [],
   "source": [
    "for garbage_class_name in garbage_class_names:\n",
    "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yps6lh8nsPcp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yps6lh8nsPcp",
    "outputId": "7a90f4bb-3240-4201-d121-8a9432692764"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "width_shift_fraction = 0.1\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
    "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iDPvcoMgseEW",
   "metadata": {
    "id": "iDPvcoMgseEW"
   },
   "source": [
    "### height_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2pfiHsBskgP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2pfiHsBskgP",
    "outputId": "276035a5-90c5-4cb6-90d1-937e907e5171"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "height_shift_fraction = 0.10\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
    "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NdonW8OusrtF",
   "metadata": {
    "id": "NdonW8OusrtF"
   },
   "source": [
    "### horizontal_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQ5EvjcJsxD8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQ5EvjcJsxD8",
    "outputId": "17dfabe6-a589-4692-e417-0acbf6d7db9a"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lxd7HGmlsyRc",
   "metadata": {
    "id": "Lxd7HGmlsyRc"
   },
   "source": [
    "### vertical_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k-TBIPuzs-K9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-TBIPuzs-K9",
    "outputId": "8475d327-b714-4a44-cb75-03e55a851ac6"
   },
   "outputs": [],
   "source": [
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  # Perform augmentation\n",
    "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
    "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
    "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
    "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
    "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
    "                                save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oZNmeaEis_M9",
   "metadata": {
    "id": "oZNmeaEis_M9"
   },
   "source": [
    "### zoom = scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PLEmuhGMtKR2",
   "metadata": {
    "id": "PLEmuhGMtKR2"
   },
   "source": [
    "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kFwoII_CSBLU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFwoII_CSBLU",
    "outputId": "13e4403d-4ebf-4faa-f9e2-5ca6c513f8b6"
   },
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(0.8, 1),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3CXocmX_tJRk",
   "metadata": {
    "id": "3CXocmX_tJRk"
   },
   "source": [
    "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V716jtPotgB1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V716jtPotgB1",
    "outputId": "4b17a2ad-e26c-41c3-ccb1-45ca9b15fb02"
   },
   "outputs": [],
   "source": [
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1, 1.2),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zLqDaHmgtgTd",
   "metadata": {
    "id": "zLqDaHmgtgTd"
   },
   "source": [
    "### brightness_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gec8GLoctvh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gec8GLoctvh1",
    "outputId": "2f89a275-2c4c-4b2a-89f4-81be173a4213"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 0.5),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][:split_index],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][:split_index],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_darkBrightness_0.5', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AbJMQn6lt-3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbJMQn6lt-3e",
    "outputId": "d25600ca-916e-4f25-d391-5cdcbeff507a"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.25),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "  # Perform augmentation\n",
    "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name][split_index:],\n",
    "                                    image_filenames=garbage_class_image_names[garbage_class_name][split_index:],\n",
    "                                    augm_images_dir_path=augmented_images_dir,\n",
    "                                    target_size=target_size,\n",
    "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
    "                                    save_augm_image=True, display_orig_augm_images=False)\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lADCJADjtvxU",
   "metadata": {
    "id": "lADCJADjtvxU"
   },
   "source": [
    "### contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2KyAabx-uLV0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KyAabx-uLV0",
    "outputId": "5862f69e-a716-46e2-98b4-f1594fefdbc1"
   },
   "outputs": [],
   "source": [
    "contrast_factor = 2.0\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xPP3kC0vuLgD",
   "metadata": {
    "id": "xPP3kC0vuLgD"
   },
   "source": [
    "### color space transformations (HSV) augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ypPMgGi6udIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypPMgGi6udIm",
    "outputId": "ad32e901-db9c-47f9-bc93-af1d31619369"
   },
   "outputs": [],
   "source": [
    "hue_shift=180\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
    "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y1qLJ2g506nN",
   "metadata": {
    "id": "Y1qLJ2g506nN"
   },
   "source": [
    "### noise addition augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGJnMe4Y1Pvz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGJnMe4Y1Pvz",
    "outputId": "9a295568-8a32-4b35-b6f0-e446dc06baa3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
    "    augmented_image = get_noisy_image(image=image)\n",
    "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5h2Ggtv72gdt",
   "metadata": {
    "id": "5h2Ggtv72gdt"
   },
   "source": [
    "### reduce garbage image + background augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ngXmJ2lNM",
   "metadata": {
    "id": "bc7ngXmJ2lNM"
   },
   "outputs": [],
   "source": [
    "background_image_filepath = '/content/backgrounds/'\n",
    "background_image_names = os.listdir(background_image_filepath)\n",
    "background_images = []\n",
    "show_images = True\n",
    "\n",
    "for background_image_name in background_image_names:\n",
    "    if '.ipynb' in background_image_name:\n",
    "      continue\n",
    "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
    "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
    "    background_images.append(background_image)\n",
    "\n",
    "    if show_images:\n",
    "        display_image(background_image, title=background_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SuzNh7AMS0no",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuzNh7AMS0no",
    "outputId": "701d3b8b-6818-48ca-b1b3-4c7cd3589d02"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=(1.2, 1.5),\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "split_decimal = 0.1\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "    counter = 0\n",
    "    for background_image in background_images:\n",
    "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
    "                                                       image=image,\n",
    "                                                       background_image=background_image,\n",
    "                                                       source_path=image_class_filepath,\n",
    "                                                       image_name=image_name)\n",
    "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
    "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "      counter += 1\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0g3W4Fr6lR2",
   "metadata": {
    "id": "m0g3W4Fr6lR2"
   },
   "source": [
    "### brightness_shift + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TBBS121o6x0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBBS121o6x0u",
    "outputId": "6fcf746f-ee2b-4b6e-af0c-10f20e605738"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.35, 0.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][split_index:], garbage_class_image_names[garbage_class_name][split_index:]):\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9uPP8ROm7bB9",
   "metadata": {
    "id": "9uPP8ROm7bB9"
   },
   "source": [
    "### color space transformations (HSV) + brightness + contrast augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0Kv50wZ7jK_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0Kv50wZ7jK_",
    "outputId": "e0c0996d-1a1a-4298-e0ef-7199ac93345b"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    brightness_range=(1.25, 1.50),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "contrast_factor=2.0\n",
    "hue_shift=170\n",
    "\n",
    "split_decimal = 0.5\n",
    "\n",
    "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
    "  image_filepath = image_class_filepath\n",
    "\n",
    "  image_names = os.listdir(image_filepath)\n",
    "  augmented_images_dir = image_class_filepath\n",
    "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
    "\n",
    "  split_index = int(split_decimal * len(garbage_class_images[garbage_class_name]))\n",
    "\n",
    "  for image, image_name in zip(garbage_class_images[garbage_class_name][:split_index], garbage_class_image_names[garbage_class_name][:split_index]):\n",
    "\n",
    "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
    "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
    "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
    "\n",
    "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
    "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  image_names = os.listdir(image_class_filepath)\n",
    "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHp2s0HkuwPs",
   "metadata": {
    "id": "HHp2s0HkuwPs"
   },
   "source": [
    "### Save valid directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rfgi2wPeuy0l",
   "metadata": {
    "id": "Rfgi2wPeuy0l"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/valid.zip /content/garbage_classification_TrainValidTest/valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YEiPqicE3SOv",
   "metadata": {
    "id": "YEiPqicE3SOv"
   },
   "source": [
    "## Save test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00TsaCNs3Vge",
   "metadata": {
    "id": "00TsaCNs3Vge"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/test.zip /content/garbage_classification_TrainValidTest/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c",
   "metadata": {
    "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c"
   },
   "source": [
    "# Train CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc62474-9df5-4c7d-95ab-f24e06263167",
   "metadata": {
    "id": "edc62474-9df5-4c7d-95ab-f24e06263167"
   },
   "source": [
    "## Create train and valid datagenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
    "outputId": "51195e1e-96d7-443e-8103-30eae0f224ed"
   },
   "outputs": [],
   "source": [
    "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
    "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(300, 300))\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir_path,\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1",
   "metadata": {
    "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VOeyt-j4AwnF",
   "metadata": {
    "id": "VOeyt-j4AwnF"
   },
   "source": [
    "### Take into account the imbalance of garbage classes of the studied dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ajuBi4RhH-6G",
   "metadata": {
    "id": "ajuBi4RhH-6G"
   },
   "source": [
    "https://stackoverflow.com/questions/69783897/compute-class-weight-function-issue-in-sklearn-library-when-used-in-keras-cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voXk2zc0A5sz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voXk2zc0A5sz",
    "outputId": "98c8c0b7-3e24-4ec3-9ddb-3fcf56744e52"
   },
   "outputs": [],
   "source": [
    "# Get the true labels for the test data\n",
    "true_labels = train_generator.classes\n",
    "\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     classes = np.unique(true_labels),\n",
    "                                     y = true_labels)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
    "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
    "\n",
    "# Print the class weights\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xtCi21DCJdPV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xtCi21DCJdPV",
    "outputId": "abb149bc-5110-4b80-e719-fbcc510ff810"
   },
   "outputs": [],
   "source": [
    "print(f\"len(true_labels) = {len(true_labels)}\")\n",
    "print(f\"true_labels = {true_labels}\")\n",
    "\n",
    "\"\"\"\n",
    "print(f\"len(class_labels) = {len(class_labels)}\")\n",
    "print(f\"class_labels = {class_labels}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jY64rbItA8lz",
   "metadata": {
    "id": "jY64rbItA8lz"
   },
   "source": [
    "### Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30815f75-7eb4-484e-bf11-9c03f9394b89",
   "metadata": {
    "id": "30815f75-7eb4-484e-bf11-9c03f9394b89"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
    "outputId": "e74334b5-5cae-4f92-9e12-977bb51a5164"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afca06-7431-4884-9c44-60d418f40731",
   "metadata": {
    "id": "b0afca06-7431-4884-9c44-60d418f40731"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\"\"\"\n",
    "model_checkpoint_callback = ModelCheckpoint('/content/models/new_augmented_model.h5', monitor='val_accuracy',\n",
    "                                            mode='max', verbose=1, save_best_only=True)\n",
    "\"\"\"\n",
    "my_callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1",
   "metadata": {
    "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
    "outputId": "7e997708-77fd-49f6-93df-1af9806d9bde"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=[early_stopping_callback, my_callback],\n",
    "                    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LUgm4rKtYRO-",
   "metadata": {
    "id": "LUgm4rKtYRO-"
   },
   "source": [
    "#### Display results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eF1vdtTGNFzK",
   "metadata": {
    "id": "eF1vdtTGNFzK"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UQ2V7808YaCu",
   "metadata": {
    "id": "UQ2V7808YaCu"
   },
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YlTY86axYgM4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlTY86axYgM4",
    "outputId": "24308e8d-7ee9-41e0-c85e-00462d6eba1a"
   },
   "outputs": [],
   "source": [
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
    "\n",
    "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=(1./255.))\n",
    "\n",
    "# Load and preprocess test data using the generator\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(300, 300),\n",
    "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
    "\n",
    "# Get the true labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the class labels for the test data\n",
    "class_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qulBKP_KYkl2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qulBKP_KYkl2",
    "outputId": "bda4d7d7-8b8d-4de1-c4e9-840086feac27"
   },
   "outputs": [],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PADFi4BpYprH",
   "metadata": {
    "id": "PADFi4BpYprH"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CNNe2YSdYtyN",
   "metadata": {
    "id": "CNNe2YSdYtyN"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "# sns.set(font_scale=1.2)  # Adjust font size for better visualization\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('/content/graphs/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PW2i3j4kYxQk",
   "metadata": {
    "id": "PW2i3j4kYxQk"
   },
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EbxZEQ_iYwsb",
   "metadata": {
    "id": "EbxZEQ_iYwsb"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/6_augmentation_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fFKojdI8Y7h9",
   "metadata": {
    "id": "fFKojdI8Y7h9"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/5_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fghIDHP3LUOB",
   "metadata": {
    "id": "fghIDHP3LUOB"
   },
   "source": [
    "### Train the CNN model using Transfer Learning (ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HtK1_C35Rcjy",
   "metadata": {
    "id": "HtK1_C35Rcjy"
   },
   "source": [
    "#### Example from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B2Rv64TmLZtY",
   "metadata": {
    "id": "B2Rv64TmLZtY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aTgy37lHRbwC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTgy37lHRbwC",
    "outputId": "8906f290-ed81-45f7-c702-8407aff0f384"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/garbage classification/Garbage classification'\n",
    "valid_path = '/content/garbage classification/Garbage classification'\n",
    "\n",
    "\n",
    "# extract images to training set by applying data preprocessing and data augmentation\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.1).flow_from_directory(\n",
    "    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
    "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n",
    "\n",
    "\n",
    "# extract images to validation set\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    validation_split=0.1).flow_from_directory(\n",
    "    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
    "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ao_b4zb-Pj20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ao_b4zb-Pj20",
    "outputId": "f94ea1a6-04b8-4193-b667-8f63519df217"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Load pre-trained ResNet50 model without the top classification layers\n",
    "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SHAPE))\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
    "# during training inorder to extract features\n",
    "base_model.trainable=False\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# add global average pooling layer\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# add densely-connected NN layer with 512 hidden units\n",
    "model.add(Dense(units=512, activation='relu'))  # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 6 hidden units\n",
    "model.add(Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htp1h_lJEYro",
   "metadata": {
    "id": "htp1h_lJEYro"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yrQZpYujSJKX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "yrQZpYujSJKX",
    "outputId": "7829ae9a-27dc-4f84-80f6-93619a0114c6"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "   train_batches,\n",
    "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
    "    epochs=20,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [es, mc],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrDhIooEWnck",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "UrDhIooEWnck",
    "outputId": "5dcfd583-ffc2-4b7d-d153-f88e36ef4c43"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDSd0Q5aWwrd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDSd0Q5aWwrd",
    "outputId": "0475487a-160b-4bdc-be15-7557d5a0573a"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/4_resnet152_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXM8zfJlW5eG",
   "metadata": {
    "id": "oXM8zfJlW5eG"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/4_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OX3lcwhlTuKn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX3lcwhlTuKn",
    "outputId": "ce764e3f-dfc8-4a65-810a-a8336fb08191"
   },
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "base_model.trainable=True\n",
    "history = model.fit_generator(\n",
    "   train_batches,\n",
    "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
    "    epochs=10,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [es, mc],)\n",
    "\n",
    "loss.extend(history.history['loss'])\n",
    "validation_loss.extend(history.history['val_loss'])\n",
    "accuracy.extend(history.history['accuracy'])\n",
    "validation_accuracy.extend(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GieDQ47P5iUP",
   "metadata": {
    "id": "GieDQ47P5iUP"
   },
   "source": [
    "#### Training by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-wulntQT5piR",
   "metadata": {
    "id": "-wulntQT5piR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dFsesqr76lpF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFsesqr76lpF",
    "outputId": "88d431f1-4236-4590-b856-548d0f1100f8"
   },
   "outputs": [],
   "source": [
    "target_size=(224, 224)\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = datagen.flow_from_directory(directory=train_dir_path,\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              target_size=target_size)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(directory=valid_dir_path,\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xJ7XI70_QAj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xJ7XI70_QAj",
    "outputId": "e565531e-fcd1-4f2f-f7d1-18b1d3756502"
   },
   "outputs": [],
   "source": [
    "print(f\"train_generator.samples/train_generator.batch_size = {train_generator.samples/train_generator.batch_size}\")\n",
    "print(f\"valid_generator.samples/valid_generator.batch_size = {valid_generator.samples/valid_generator.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UZmQv4t9JON4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZmQv4t9JON4",
    "outputId": "70e56b25-8f46-4133-9b8a-35607b12b350"
   },
   "outputs": [],
   "source": [
    "# Get the true labels for the test data\n",
    "true_labels = train_generator.classes\n",
    "\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     classes = np.unique(true_labels),\n",
    "                                     y = true_labels)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the class weights\n",
    "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
    "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
    "\n",
    "# Print the class weights\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n9RRgj8__Iig",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9RRgj8__Iig",
    "outputId": "d928c529-f793-4f73-ee45-e8eb5311bbd3"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# import the convolution base of the VGG16 model with pre-trained weights\n",
    "base_model = tf.keras.applications.resnet.ResNet152(input_shape=IMG_SHAPE,\n",
    "                                        include_top=False,\n",
    "                                        weights='imagenet')\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
    "# during training inorder to extract features\n",
    "base_model.trainable=False\n",
    "\n",
    "# add VGG16 convolution base to initialize sequential model\n",
    "model.add(base_model)\n",
    "\n",
    "# add global average pooling layer\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add densely-connected NN layer with 512 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))  # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 6 hidden units\n",
    "model.add(tf.keras.layers.Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CxDCpUZnPIEK",
   "metadata": {
    "id": "CxDCpUZnPIEK"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 98% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fgL8J-XD5x5Q",
   "metadata": {
    "id": "fgL8J-XD5x5Q"
   },
   "outputs": [],
   "source": [
    "my_callback = myCallback()\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "# model_checkpoint_callback = ModelCheckpoint('VGG152_Garbage_Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCD3JtLzGj9h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCD3JtLzGj9h",
    "outputId": "8445d4f2-67b1-47e2-ffed-fa60faade163"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "    epochs=30,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stopping_callback, my_callback],\n",
    "    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sgY_Z1HKZJrP",
   "metadata": {
    "id": "sgY_Z1HKZJrP"
   },
   "source": [
    "##### Display the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DS8ldXfkZOMG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "DS8ldXfkZOMG",
    "outputId": "0837cc60-e587-4f21-bd4a-6306a726ea1e"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2QKso6tIZVoc",
   "metadata": {
    "id": "2QKso6tIZVoc"
   },
   "source": [
    "##### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htnK0nJuZY9D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htnK0nJuZY9D",
    "outputId": "e6b64f7b-8919-4779-baaa-c59e9aeec83d"
   },
   "outputs": [],
   "source": [
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
    "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load and preprocess test data using the generator\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
    "\n",
    "# Get the true labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the class labels for the test data\n",
    "class_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kCsaptjeZve_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCsaptjeZve_",
    "outputId": "165c5ec7-5dd7-4a6c-c3b0-0ac73f6f09c6"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iufZXvZ_ZylX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "iufZXvZ_ZylX",
    "outputId": "dcc94880-6554-4afd-84ea-c16361c87507"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('/content/graphs/resnet152_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zY_YM7PFCHzk",
   "metadata": {
    "id": "zY_YM7PFCHzk"
   },
   "source": [
    "##### Try to train the model to 99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3g3nsvFlCVh1",
   "metadata": {
    "id": "3g3nsvFlCVh1"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gv0vnULhCbsM",
   "metadata": {
    "id": "gv0vnULhCbsM"
   },
   "outputs": [],
   "source": [
    "my_callback = myCallback()\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bxtGczJQCHO8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxtGczJQCHO8",
    "outputId": "7d298878-922e-47a7-ca32-d0bdeb09a903"
   },
   "outputs": [],
   "source": [
    "new_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "    epochs=30,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples/valid_generator.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stopping_callback, my_callback],\n",
    "    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OO0Tb3KBFv_Q",
   "metadata": {
    "id": "OO0Tb3KBFv_Q"
   },
   "source": [
    "##### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-5HU02dDFvVh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5HU02dDFvVh",
    "outputId": "8975e48e-7ac7-4a3e-e560-15bf5018e2b3"
   },
   "outputs": [],
   "source": [
    "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
    "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load and preprocess test data using the generator\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
    "\n",
    "# Get the true labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the class labels for the test data\n",
    "class_labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D4ZhN61qFyvn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4ZhN61qFyvn",
    "outputId": "8c92d907-c0e0-4f10-bc86-f2f74c4080aa"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lYPAVuPqHqRq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "lYPAVuPqHqRq",
    "outputId": "ac9e802d-3283-44d7-a202-96a0b1408e03"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('/content/graphs/resnet152_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53XyzpykIfa5",
   "metadata": {
    "id": "53XyzpykIfa5"
   },
   "source": [
    "##### Concatenate histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mP60l4q0Iidx",
   "metadata": {
    "id": "mP60l4q0Iidx"
   },
   "outputs": [],
   "source": [
    "# Combine training histories\n",
    "history.history['loss'].extend(new_history.history['loss'])\n",
    "history.history['accuracy'].extend(new_history.history['accuracy'])\n",
    "history.history['val_loss'].extend(new_history.history['val_loss'])\n",
    "history.history['val_accuracy'].extend(new_history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oCUx4IeVIjzp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "oCUx4IeVIjzp",
    "outputId": "c7625fbf-e519-4388-bb29-7c5477b70662"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5IsCw0xyI4vh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "5IsCw0xyI4vh",
    "outputId": "c140a6a6-a264-490c-e1be-82610a7e143b"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history=new_history, strings=['accuracy', 'loss'], filename='/content/graphs/new_training_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4IiDoxTmZ2D3",
   "metadata": {
    "id": "4IiDoxTmZ2D3"
   },
   "source": [
    "##### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2EPzdHJ6P8Lh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EPzdHJ6P8Lh",
    "outputId": "e45ae9f1-307e-40b9-d07f-5f71cb29059f"
   },
   "outputs": [],
   "source": [
    "model.save('/content/models/7_1_resnet152_garbage_classification_6_classes_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BtkE5HNuZ7aD",
   "metadata": {
    "id": "BtkE5HNuZ7aD"
   },
   "outputs": [],
   "source": [
    "with open('/content/models/histories/7_1_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "a19fa0e8-6098-41f8-9901-09e18d152bce",
    "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
    "QtwmTbl9PK5u",
    "ff87ed02-b353-41ff-a831-495238d0361b",
    "jH-5MYFlPiGG",
    "oewmXvvYPoS2",
    "cwXhFVwTUYPI",
    "a9d3365a-13fe-480a-b5a1-a73191acca39",
    "e59dd5b1-3054-4e06-a376-42362774907a",
    "158972c1-8c86-45a5-a767-c7b37b1b6608",
    "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
    "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
    "50d2c56e-aac4-4403-a89c-177d7584ca76",
    "SVoc99d2bFV6",
    "r1oj75sjbMPq",
    "Nq6an5m7bYeU",
    "xN_CBfSMbsNy",
    "wTLkX5eyb3ny",
    "M6N_HmcbcdN6",
    "OvIN0bJrdWjL",
    "bkNIrE5i9yff",
    "S1YCpPVUryl2",
    "iDPvcoMgseEW",
    "NdonW8OusrtF",
    "Lxd7HGmlsyRc",
    "oZNmeaEis_M9",
    "PLEmuhGMtKR2",
    "3CXocmX_tJRk",
    "zLqDaHmgtgTd",
    "lADCJADjtvxU",
    "xPP3kC0vuLgD",
    "Y1qLJ2g506nN",
    "5h2Ggtv72gdt",
    "m0g3W4Fr6lR2",
    "9uPP8ROm7bB9",
    "edc62474-9df5-4c7d-95ab-f24e06263167",
    "VOeyt-j4AwnF",
    "jY64rbItA8lz",
    "PW2i3j4kYxQk",
    "HtK1_C35Rcjy"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
