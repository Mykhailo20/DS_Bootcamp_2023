{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b",
      "metadata": {
        "id": "053753b4-a1c8-4c8c-bc03-dccc9843402b"
      },
      "source": [
        "### Link to the dataset: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the Kaggle API key file (kaggle.json) that you downloaded from Kaggle\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded API key to the required directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RKCaaWRKQye8",
        "outputId": "48aed107-e21c-46c2-9f57-acb514531815"
      },
      "id": "RKCaaWRKQye8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f427dad-454f-4811-8eff-4fbe4fcf357e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f427dad-454f-4811-8eff-4fbe4fcf357e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "143vln3rRExD"
      },
      "id": "143vln3rRExD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d asdasdasasdas/garbage-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRRvWPlURJXy",
        "outputId": "ef82d790-e5d2-4ed0-a78c-a682e9c37152"
      },
      "id": "CRRvWPlURJXy",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading garbage-classification.zip to /content\n",
            " 79% 65.0M/82.0M [00:00<00:00, 147MB/s]\n",
            "100% 82.0M/82.0M [00:00<00:00, 149MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip garbage-classification.zip"
      ],
      "metadata": {
        "id": "qFh2FFk3RQID"
      },
      "id": "qFh2FFk3RQID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rembg"
      ],
      "metadata": {
        "id": "qW8DMdNSxlEF"
      },
      "id": "qW8DMdNSxlEF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c",
      "metadata": {
        "id": "56b3d70c-d1d5-4cff-9af8-db7e2d405a9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "# from rembg import remove\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19fa0e8-6098-41f8-9901-09e18d152bce",
      "metadata": {
        "id": "a19fa0e8-6098-41f8-9901-09e18d152bce"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
      "metadata": {
        "id": "0cfe9557-7afc-43fe-ac84-46e7c3b26d47"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "979887c5-9518-4f9b-860a-9f6e586085fd",
      "metadata": {
        "id": "979887c5-9518-4f9b-860a-9f6e586085fd"
      },
      "outputs": [],
      "source": [
        "def create_train_valid_test_dirs(root_path, subdir_names, train_valid_test_names=['train', 'valid', 'test']):\n",
        "    \"\"\" Function for creating separate folders that contain data for training, validation and testing of the model\n",
        "    Args:\n",
        "        1) root_path - the path to the parent folder in which you want to create subfolders\n",
        "        2) subdir_names - a list of label class names (subfolders with the specified names will be created in each of the train, valid, and test folders)\n",
        "        3) train_valid_test_names - a list of names of training, validation and test samples\n",
        "    Returns:\n",
        "        None; but creates folders\n",
        "    \"\"\"\n",
        "    parent_directories = []\n",
        "    for dir_name in train_valid_test_names:\n",
        "        parent_directories.append(os.path.join(root_path, dir_name))\n",
        "\n",
        "    for directory in parent_directories:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "        for subdirectory in subdir_names:\n",
        "            subdir_name = os.path.join(directory + '/', subdirectory)\n",
        "            if not os.path.exists(subdir_name):\n",
        "                os.makedirs(subdir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d",
      "metadata": {
        "id": "5f80dbb7-bd2f-4f93-9f3c-0aa96fea158d"
      },
      "outputs": [],
      "source": [
        "def split_data(source_dir_path, train_dir_path, valid_dir_path, test_dir_path, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
        "    \"\"\" Function to split the files of the specified folder into training, validation and test samples by copying\n",
        "    the files from source_dir_path to the corresponding folders\n",
        "    Args:\n",
        "        1) source_dir_path - the path to the folder containing the original data to be split into train/valid/test\n",
        "        2) train_dir_path - the path to the folder that will contain the training data\n",
        "        3) valid_dir_path - the path to the folder that will contain the validation data\n",
        "        4) test_dir_path - the path to the folder that will contain the test data\n",
        "        5) train_test_split - the ratio between training and test samples ([0; 1])\n",
        "        6) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
        "        7) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
        "    Returns:\n",
        "        None, but split the files into training, validation and test samples\n",
        "    \"\"\"\n",
        "    fnames = os.listdir(source_dir_path)\n",
        "\n",
        "    processed_fnames = []\n",
        "    for file_name in fnames:\n",
        "        if os.path.getsize(os.path.join(source_dir_path, file_name)) > 0:\n",
        "            processed_fnames.append(file_name)\n",
        "        else:\n",
        "            print(f'{file_name} is zero length, so ignoring.')\n",
        "\n",
        "    if random_sample:\n",
        "        processed_fnames = random.sample(processed_fnames, len(processed_fnames))\n",
        "\n",
        "    split_index = int(train_test_split * len(processed_fnames))\n",
        "    train_valid_files = processed_fnames[:split_index]\n",
        "    test_files = processed_fnames[split_index:]\n",
        "\n",
        "    split_index = int(train_valid_split * len(train_valid_files))\n",
        "    train_files = train_valid_files[:split_index]\n",
        "    valid_files = train_valid_files[split_index:]\n",
        "\n",
        "    # Copy training files\n",
        "    for file in train_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(train_dir_path, file)\n",
        "        copyfile(source, destination)\n",
        "\n",
        "    # Copy validation files\n",
        "    for file in valid_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(valid_dir_path, file)\n",
        "        copyfile(source, destination)\n",
        "\n",
        "    # Copy test files\n",
        "    for file in test_files:\n",
        "        source = os.path.join(source_dir_path, file)\n",
        "        destination = os.path.join(test_dir_path, file)\n",
        "        copyfile(source, destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "da75baf0-c207-4220-bcb3-2f936d00049d",
      "metadata": {
        "id": "da75baf0-c207-4220-bcb3-2f936d00049d"
      },
      "outputs": [],
      "source": [
        "def split_class_data(source_dir_path, train_valid_test_paths, class_dir_name, train_test_split=0.8, train_valid_split=0.85, random_sample=True):\n",
        "    \"\"\" Function for dividing the data of one label class into train/valid/test\n",
        "    Args:\n",
        "        1) source_dir_path - the path to the folder containing the original data of all label classes which needs to be splitted into train/valid/test;\n",
        "        2) train_valid_test_paths - the list of paths to the folders of training, validation and test samples\n",
        "        (the paths are specified in this order: train, valid, test)\n",
        "        3) class_dir_name - the name of the folder that contains the label class data\n",
        "        4) train_test_split - the ratio between training and test samples ([0; 1])\n",
        "        5) train_valid_split - the ratio between training and validation samples ([0; 1])\n",
        "        6) random_sample - whether files need to be shuffled randomly before splitting into training, validation, and test samples\n",
        "    Returns:\n",
        "        None, but split the files of label class into training, validation and test samples\n",
        "    \"\"\"\n",
        "    train_dir_path_class = os.path.join(train_valid_test_paths[0], class_dir_name)\n",
        "    valid_dir_path_class = os.path.join(train_valid_test_paths[1], class_dir_name)\n",
        "    test_dir_path_class = os.path.join(train_valid_test_paths[2], class_dir_name)\n",
        "    source_dir_path_class = os.path.join(source_dir_path, class_dir_name)\n",
        "    split_data(source_dir_path=source_dir_path_class, train_dir_path=train_dir_path_class, valid_dir_path=valid_dir_path_class,\n",
        "               test_dir_path=test_dir_path_class,\n",
        "               train_test_split=train_test_split, train_valid_split=train_valid_split, random_sample=random_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display images"
      ],
      "metadata": {
        "id": "QtwmTbl9PK5u"
      },
      "id": "QtwmTbl9PK5u"
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(img, title=None):\n",
        "    \"\"\" Function to display an image\n",
        "    Args:\n",
        "        1) img - image object\n",
        "        2) title - the title that will be displayed above the image\n",
        "    Returns:\n",
        "        None; but displays an image\n",
        "    \"\"\"\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uDa_N5C5PKbQ"
      },
      "id": "uDa_N5C5PKbQ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_original_augmented_img(original_img, augmented_img, original_title=None, augmented_title=None):\n",
        "    \"\"\" Function to display the original and augmented image on the same graph\n",
        "    Args:\n",
        "        1) original_img - object of the original image\n",
        "        2) augmented_img - augmented image object\n",
        "        3) original_title - title for the original image\n",
        "        4) augmented_title - title for the augmented image\n",
        "    Returns:\n",
        "        None; but displays images\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title(original_title)\n",
        "\n",
        "    axes[1].imshow(augmented_img)\n",
        "    axes[1].set_title(augmented_title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GnJCHNEDPWLG"
      },
      "id": "GnJCHNEDPWLG",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff87ed02-b353-41ff-a831-495238d0361b",
      "metadata": {
        "tags": [],
        "id": "ff87ed02-b353-41ff-a831-495238d0361b"
      },
      "source": [
        "## Display data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_display_image(root_path, image_name, title=None):\n",
        "    \"\"\" Function to display an image\n",
        "    Args:\n",
        "        1) root_path - the path to the folder that contains the image\n",
        "        2) image_name - the name of the image\n",
        "        3) title - the title that will be displayed above the image\n",
        "    Returns:\n",
        "        None; but displays an image\n",
        "    \"\"\"\n",
        "    img = cv2.imread(os.path.join(root_path, image_name))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_cc_OjlNRHcM"
      },
      "id": "_cc_OjlNRHcM",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4",
      "metadata": {
        "id": "e8b3f412-e0cb-4a3e-a99f-88f30d0f90a4"
      },
      "outputs": [],
      "source": [
        "def display_pie_chart(df, column_name, title=None, column_contains_count=False, filename=None):\n",
        "    \"\"\" Function to display the percentage ratio of column (with the name column_name) content\n",
        "    Args:\n",
        "        1) df - the original dataframe that contains the required information\n",
        "        2) column_name - the name of the df dataframe column whose percentage values are to be found\n",
        "        3) title - the title of the graph\n",
        "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
        "        5) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    Returns:\n",
        "        None, but plots graph\n",
        "    \"\"\"\n",
        "    # Calculate the percentage of each activity in original_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_df = df[column_name] / sum(df[column_name])\n",
        "    else:\n",
        "        activity_percentages_df = df[column_name].value_counts(normalize=True) * 100\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot pie chart for df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    plt.pie(activity_percentages_df, labels=activity_percentages_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_pie_charts(first_df, second_df, column, column_contains_count=False, first_chart_title='First DataFrame', second_chart_title='Second DataFrame', filename=None):\n",
        "    \"\"\"Function for displaying the ratio of column content between two dataframes in the form of pie charts\n",
        "    Args:\n",
        "        1) first_df - the original dataframe that contains the required information\n",
        "        2) second_df - a dataframe that contains the results of windowing\n",
        "        3) column - the name of the dataframe column whose percentage values are to be found\n",
        "        4) column_contains_count - the dataframe column already contains the number of repetitions of the target values (target value count)\n",
        "        5) first_chart_title - the title for the first pie chart\n",
        "        6) second_chart_title - the title for the second pie chart\n",
        "        7) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    Returns:\n",
        "        None; just builds a pie chart to display the ratio of column contents between two dataframes\n",
        "    \"\"\"\n",
        "    # Calculate the percentage of each activity in first_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_first_df = first_df[column] / sum(first_df[column]) * 100\n",
        "    else:\n",
        "        activity_percentages_first_df = first_df[column].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Calculate the percentage of each activity in second_df\n",
        "    if column_contains_count:\n",
        "        activity_percentages_second_df = second_df[column] / sum(second_df[column]) * 100\n",
        "    else:\n",
        "        activity_percentages_second_df = second_df[column].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Create subplots for pie charts\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot pie chart for df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    axes[0].pie(activity_percentages_first_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    axes[0].set_title(first_chart_title)\n",
        "\n",
        "    # Plot pie chart for windowed_df\n",
        "    sns.set_palette(\"Set3\")\n",
        "    axes[1].pie(activity_percentages_second_df, labels=activity_percentages_first_df.index, autopct='%1.1f%%', startangle=140)\n",
        "    axes[1].set_title(second_chart_title)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        plt.savefig(f'{filename}.png', bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform image augmentation using ImageDataGenerator"
      ],
      "metadata": {
        "id": "jH-5MYFlPiGG"
      },
      "id": "jH-5MYFlPiGG"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ImageDataGen_image(imageDataGenerator, image):\n",
        "  \"\"\" Function that returns an image augmented with imageDataGenerator\n",
        "  Args:\n",
        "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
        "    2) image - an image passed as a numpy array\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  x = image.copy()\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  for batch in imageDataGenerator.flow(x, batch_size=1):\n",
        "      augmented_image=batch[0].copy().astype(np.uint8)\n",
        "      break\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "0iT7IBC51ely"
      },
      "id": "0iT7IBC51ely",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_ImageDataGen_augmentation(imageDataGenerator, images, image_filenames, target_size,\n",
        "                                      augm_prefix, num_augm_images=3, augm_images_dir_path=None,\n",
        "                                      save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) imageDataGenerator - ImageDataGenerator class object\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "    augmented_index = 0\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        x = img.copy()\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1):\n",
        "            i += 1\n",
        "            if i > num_augm_images:\n",
        "                augmented_index = 0\n",
        "                break\n",
        "\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "\n",
        "            augmented_index += 1\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "                # tf.keras.preprocessing.image.save_img(augmented_image_path, batch[0])\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(batch[0].copy().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=batch[0].copy().astype(np.uint8),\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "kdVdixQDPhmW"
      },
      "id": "kdVdixQDPhmW",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform image augmentation using CV2"
      ],
      "metadata": {
        "id": "oewmXvvYPoS2"
      },
      "id": "oewmXvvYPoS2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation functions"
      ],
      "metadata": {
        "id": "5PxQiefcUULF"
      },
      "id": "5PxQiefcUULF"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_width_shift_image(image, width_shift_fraction):\n",
        "    \"\"\" Function for performing width_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) width_shift_fraction - offset value ([-1; 1])\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Get the height and width of the image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Calculate the height shift value\n",
        "    width_shift = int(height * width_shift_fraction)\n",
        "\n",
        "    # Calculate the new y-coordinate for height shift\n",
        "    y_shifted = height // 2 + width_shift\n",
        "\n",
        "    # Calculate the rotation matrix for height shift\n",
        "    shift_matrix = np.float32([[1, 0, 0], [0, 1, width_shift]])\n",
        "\n",
        "    # Apply the height shift to the image using warpAffine\n",
        "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
        "    return changed_image"
      ],
      "metadata": {
        "id": "l42CveFAPquW"
      },
      "id": "l42CveFAPquW",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_height_shift_image(image, height_shift_fraction):\n",
        "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) height_shift_fraction - offset value ([-1; 1])\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Get the height and width of the image\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Calculate the height shift value\n",
        "    height_shift = int(width * height_shift_fraction)\n",
        "\n",
        "    # Calculate the new x-coordinate for height shift\n",
        "    x_shifted = width // 2 + height_shift\n",
        "\n",
        "    # Calculate the rotation matrix for height shift\n",
        "    shift_matrix = np.float32([[1, 0, height_shift], [0, 1, 0]])\n",
        "\n",
        "    # Apply the height shift to the image using warpAffine\n",
        "    changed_image = cv2.warpAffine(image, shift_matrix, (width, height))\n",
        "    return changed_image"
      ],
      "metadata": {
        "id": "yjmv3HHoPtqd"
      },
      "id": "yjmv3HHoPtqd",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_brightness_augmentation_image(image, brightness_range=(0.5, 1.5)):\n",
        "    # Convert the image to HSV color space\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Generate a random brightness factor within the specified range\n",
        "    brightness_factor = np.random.uniform(brightness_range[0], brightness_range[1])\n",
        "\n",
        "    # Adjust the brightness by scaling the V channel\n",
        "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)\n",
        "\n",
        "    # Convert the image back to the original color space (BGR)\n",
        "    augmented_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "eG8FTDtWPwGe"
      },
      "id": "eG8FTDtWPwGe",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_contrast_augmentation_image(image, contrast_factor):\n",
        "    \"\"\" Function for performing height_shift augmentation over the image 'image'\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) contrast_factor - adjusts the contrast of the image by applying CLAHE; possible values: [1.0; 4.0]\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Convert the image to LAB color space\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # Split the LAB image into L, A, and B channels\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=contrast_factor, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l)\n",
        "\n",
        "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
        "    limg = cv2.merge((cl, a, b))\n",
        "\n",
        "    # Convert the LAB image back to BGR color space\n",
        "    contrast_augmented_image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return contrast_augmented_image"
      ],
      "metadata": {
        "id": "2tYCvwyDPx3V"
      },
      "id": "2tYCvwyDPx3V",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hsv_image(image, hue_shift, saturation_scale=1, value_scale=1):\n",
        "    \"\"\" Function to change the color tone of the image when switching to the HSV model\n",
        "    Args:\n",
        "        1) image - image object\n",
        "        2) hue_shift - the value of the Hue parameter of the hsv model; possible values: [0; 179] (OpenCV)\n",
        "        3) saturation_scale - coefficient by which the Saturation parameter of the HSV model will be multiplied\n",
        "        4) value_scale - coefficient by which the Value parameter of the HSV model will be multiplied\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    # Convert the original image to the HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Apply the hue shift to the hue channel\n",
        "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
        "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_scale, 0, 255)\n",
        "    hsv_image[:, :, 2] = np.clip(hsv_image[:, :, 2] * value_scale, 0, 255)\n",
        "\n",
        "    # Convert the image back to the RGB color space\n",
        "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "KqcGVI2NP1j-"
      },
      "id": "KqcGVI2NP1j-",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_noisy_image(image, mean=1, std_dev=0.7):\n",
        "    \"\"\" Function for adding random noise to the image 'image'\n",
        "    Args:\n",
        "        1) image - an image passed as a numpy array\n",
        "        2) mean - the mean value of the noise\n",
        "        3) std_dev - the standard deviation of the noise (the larger the std_dev, the more intense the noise will be)\n",
        "    Returns:\n",
        "        augmented_image\n",
        "    \"\"\"\n",
        "    noise = np.random.normal(mean, std_dev, image.shape).astype('uint8')\n",
        "    augmented_image = cv2.add(image, noise)\n",
        "\n",
        "    return augmented_image"
      ],
      "metadata": {
        "id": "GYnBKRn51YfT"
      },
      "id": "GYnBKRn51YfT",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_background(input_path, output_path=None):\n",
        "    \"\"\" Function to remove the background from the image\n",
        "    Args:\n",
        "      1) input_path - the path to the image whose background should be removed\n",
        "      2) output_path - the path to save an image without a background\n",
        "    Returns:\n",
        "      Image without background\n",
        "    \"\"\"\n",
        "     # Processing the image\n",
        "    input_image = Image.open(input_path)\n",
        "\n",
        "    # Removing the background from the given Image\n",
        "    output_image = remove(input_image)\n",
        "\n",
        "    # Convert the output image to RGB mode (removing transparency)\n",
        "    output_image = output_image.convert(\"RGB\")\n",
        "\n",
        "    if output_path:\n",
        "      # Save the image with the background removed\n",
        "      output_image.save(output_path)\n",
        "    return output_image"
      ],
      "metadata": {
        "id": "mGnfBhhQ1jJI"
      },
      "id": "mGnfBhhQ1jJI",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_background_image(image, background_image, source_path, image_name, no_background_output_path=None):\n",
        "  \"\"\" Function to replace the background of the original image with the background image background_image\n",
        "  Args:\n",
        "    1) image - an image passed as a numpy array\n",
        "    2) background_image - a background image passed as a numpy array\n",
        "    3) source_path - path to image 'image'\n",
        "    4) image_name - name of the image 'image'\n",
        "    5) no_background_output_path - the path (along with the image name) to store the original image without the background\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  if no_background_output_path is not None:\n",
        "    pil_image = remove_background(input_path=os.path.join(source_path, image_name),\n",
        "                    output_path=os.path.join(no_background_output_path, image_name))\n",
        "  else:\n",
        "    pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
        "\n",
        "  augmented_image = background_image.copy()\n",
        "\n",
        "  # Convert PIL image to OpenCV format (NumPy array)\n",
        "  image_without_background = np.array(pil_image)\n",
        "\n",
        "  mask = cv2.cvtColor(image_without_background, cv2.COLOR_BGR2GRAY)\n",
        "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "  garbage_area = cv2.bitwise_and(image_without_background, image_without_background, mask=mask)\n",
        "  background_area = cv2.bitwise_and(augmented_image, augmented_image, mask=mask_inv)\n",
        "  augmented_image = cv2.add(garbage_area, background_area)\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "LEuXuDQ51nfo"
      },
      "id": "LEuXuDQ51nfo",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmented_background_image(imageDataGenerator, image, background_image, source_path, image_name):\n",
        "  \"\"\" Function that returns a new augmented image (eg reduced in size) with a new background\n",
        "  Args:\n",
        "    1) imageDataGenerator - an object of type ImageDataGenerator\n",
        "    2) image - an image passed as a numpy array\n",
        "    3) background_image - a background image passed as a numpy array\n",
        "    4) source_path -  path to image 'image'\n",
        "    5) image_name - name of the image 'image'\n",
        "  Returns:\n",
        "    augmented_image\n",
        "  \"\"\"\n",
        "  pil_image = remove_background(input_path=os.path.join(source_path, image_name))\n",
        "\n",
        "  # Convert PIL image to OpenCV format (NumPy array)\n",
        "  image_without_background = np.array(pil_image)\n",
        "\n",
        "  changed_image = get_ImageDataGen_image(imageDataGenerator=imageDataGenerator,\n",
        "                                         image=image_without_background)\n",
        "\n",
        "  mask = cv2.cvtColor(changed_image, cv2.COLOR_BGR2GRAY)\n",
        "  _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "  garbage_area = cv2.bitwise_and(changed_image, changed_image, mask=mask)\n",
        "  augmented_image = background_image.copy()\n",
        "  background_area = cv2.bitwise_and(augmented_image, augmented_image,\n",
        "                                  mask=mask_inv)\n",
        "  augmented_image = cv2.add(garbage_area, background_area)\n",
        "\n",
        "  return augmented_image"
      ],
      "metadata": {
        "id": "zwbR-nZX1rJl"
      },
      "id": "zwbR-nZX1rJl",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation algorithms"
      ],
      "metadata": {
        "id": "cwXhFVwTUYPI"
      },
      "id": "cwXhFVwTUYPI"
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cv2_rotation_augmentation(rotation_range, images, image_filenames,\n",
        "                                      target_size, augm_prefix,\n",
        "                                      num_augm_images=3, augm_images_dir_path=None,\n",
        "                                      save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) rotation_range - the range (a list of two elements: [range_min; range_max]) in which the angle value will change linearly (depending on num_augm_images)\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "    height = target_size[0]\n",
        "    width = target_size[1]\n",
        "    angle_increment = int((rotation_range[1] - rotation_range[0]) / num_augm_images)\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        augmented_index = 0\n",
        "        angle = rotation_range[0]\n",
        "        for i in range(num_augm_images):\n",
        "            # Calculate the rotation matrix\n",
        "            rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
        "\n",
        "            # Apply the rotation to the image using warpAffine\n",
        "            augmented_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "            augmented_index += 1\n",
        "            angle += angle_increment\n",
        "            if angle == 0:\n",
        "                angle += angle_increment\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augm_images_dir_path, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augm_images_dir_path, augmented_image_name)\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "OBXdj3gTUbgd"
      },
      "id": "OBXdj3gTUbgd",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cv2_flip_augmentation(flip_code, images, image_filenames,\n",
        "                                  target_size, augm_prefix,\n",
        "                                  num_augm_images=3, augm_images_dir_path=None,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False):\n",
        "    \"\"\" Function to create augmented images from images using imageDataGenerator\n",
        "    Args:\n",
        "        1) flip_code - the type of flip augmentation to perform on the image: 0 - vertical, 1 - horizontal\n",
        "        2) images - a list of images, each of which is stored as a numpy array\n",
        "        3) image_filenames - a list of image file names images (the names are used in the headers of the images that will be saved)\n",
        "        4) target_size - the size of the images\n",
        "        5) augm_prefix - prefix to be added to the beginning of the file name to indicate the augmentation technique\n",
        "        6) num_augm_images - the number of instances of augmented images for one original\n",
        "        7) augm_images_dir_path - the path to the folder where you want to save the augmented images (used if save_augm_image=True)\n",
        "        8) save_augm_image - whether to save the augmented image\n",
        "        9) display_orig_augm_images - whether to display the original and augmented image at the same time (original - left, augmented - right)\n",
        "    Returns:\n",
        "        None; but saves or displays augmented_images\n",
        "    \"\"\"\n",
        "\n",
        "    for (image_name, img) in zip(image_filenames, images):\n",
        "        augmented_index = 0\n",
        "        for i in range(num_augm_images):\n",
        "            augmented_image = cv2.flip(img.copy(), flip_code)\n",
        "\n",
        "            augmented_image_name = f\"{augm_prefix}_{image_name.split('.')[0]}_{augmented_index}.jpg\"\n",
        "            augmented_index += 1\n",
        "\n",
        "            if save_augm_image and (augm_images_dir_path is not None):\n",
        "                os.makedirs(augmented_images_dir, exist_ok=True)\n",
        "                augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "                cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "            if display_orig_augm_images:\n",
        "                display_original_augmented_img(original_img=img, augmented_img=augmented_image,\n",
        "                                               original_title=f\"Original_image: {image_name}\",\n",
        "                                               augmented_title=f\"{augm_prefix}: {image_name}\")"
      ],
      "metadata": {
        "id": "dAaU8XHhUeAG"
      },
      "id": "dAaU8XHhUeAG",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c",
      "metadata": {
        "id": "dbf37818-0dab-4224-a771-2ed14b1bb34c"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba",
      "metadata": {
        "id": "ed0c44e8-5a2a-41e0-8566-539bc6c81bba"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(history, strings, filename=None):\n",
        "    \"\"\"Function to plot graphs for two training history parameters (eg accuracy and loss)\n",
        "    Args:\n",
        "        1) history - model training history\n",
        "        2) strings - an array of names of history parameters (only the data of the first two history parameters specified in this array will be taken for graphing)\n",
        "        3) filename - the relative path where the file will be saved (with the file name, the file extension is not required) or just the filename\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].plot(history.history[strings[0]], label=strings[0])\n",
        "    axes[0].plot(history.history[f\"val_{strings[0]}\"], label=f\"val_{strings[0]}\")\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel(strings[0])\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(history.history[strings[1]], label=strings[1])\n",
        "    axes[1].plot(history.history[f\"val_{strings[1]}\"], label=f\"val_{strings[1]}\")\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel(strings[1])\n",
        "    axes[1].legend()\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(f\"{filename}.png\", bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099e9f3d-af53-4f7d-92ac-f6347091c448",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "099e9f3d-af53-4f7d-92ac-f6347091c448"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "089707ba-256c-4e27-9a65-c764999f41ac",
      "metadata": {
        "id": "089707ba-256c-4e27-9a65-c764999f41ac"
      },
      "outputs": [],
      "source": [
        "source_path = '/content/Garbage classification/Garbage classification'\n",
        "\n",
        "source_path_cardboard = os.path.join(source_path, 'cardboard')\n",
        "source_path_glass = os.path.join(source_path, 'glass')\n",
        "source_path_metal = os.path.join(source_path, 'metal')\n",
        "source_path_paper = os.path.join(source_path, 'paper')\n",
        "source_path_plastic = os.path.join(source_path, 'plastic')\n",
        "source_path_trash = os.path.join(source_path, 'trash')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6808b080-50b3-423d-aca4-60fc14129e79",
      "metadata": {
        "id": "6808b080-50b3-423d-aca4-60fc14129e79"
      },
      "outputs": [],
      "source": [
        "cardboard_image_names = os.listdir(source_path_cardboard)\n",
        "glass_image_names = os.listdir(source_path_glass)\n",
        "metal_image_names = os.listdir(source_path_metal)\n",
        "paper_image_names = os.listdir(source_path_paper)\n",
        "plastic_image_names = os.listdir(source_path_plastic)\n",
        "trash_image_names = os.listdir(source_path_trash)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8a4b24a-5a1b-4108-ba5a-70397d4e711a",
        "outputId": "39112097-b053-4d47-88fe-fe1ed27b5da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 403 images of cardboard.\n",
            "There are 501 images of glass.\n",
            "There are 410 images of metal.\n",
            "There are 594 images of paper.\n",
            "There are 482 images of plastic.\n",
            "There are 137 images of trash.\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {len(cardboard_image_names)} images of cardboard.\") # 403\n",
        "print(f\"There are {len(glass_image_names)} images of glass.\") # 501\n",
        "print(f\"There are {len(metal_image_names)} images of metal.\") # 410\n",
        "print(f\"There are {len(paper_image_names)} images of paper.\") # 594\n",
        "print(f\"There are {len(plastic_image_names)} images of plastic.\") # 482\n",
        "print(f\"There are {len(trash_image_names)} images of trash.\") # 137"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d3365a-13fe-480a-b5a1-a73191acca39",
      "metadata": {
        "id": "a9d3365a-13fe-480a-b5a1-a73191acca39"
      },
      "source": [
        "## Display classes distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7969d554-c740-45fe-800a-b886f9cbf94f",
        "outputId": "2ceb8fbf-79c3-4db2-f479-05cacc0c2e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 403 images of cardboard.\n",
            "There are 501 images of glass.\n",
            "There are 410 images of metal.\n",
            "There are 594 images of paper.\n",
            "There are 482 images of plastic.\n",
            "There are 137 images of trash.\n"
          ]
        }
      ],
      "source": [
        "classes_representatives = {'cardboard': len(cardboard_image_names),\n",
        "                           'glass': len(glass_image_names),\n",
        "                           'metal': len(metal_image_names),\n",
        "                           'paper': len(paper_image_names),\n",
        "                           'plastic': len(plastic_image_names),\n",
        "                           'trash': len(trash_image_names)\n",
        "                          }\n",
        "for label_class in classes_representatives.keys():\n",
        "    print(f\"There are {classes_representatives[label_class]} images of {label_class}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "a8925c56-c641-491b-8937-d069eddbe8a1",
        "outputId": "63c8e93a-abbc-4fea-97aa-c0016531e3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  count\n",
              "0  cardboard    403\n",
              "1      glass    501\n",
              "2      metal    410\n",
              "3      paper    594\n",
              "4    plastic    482\n",
              "5      trash    137"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ad7c433-b003-4330-933c-1422eac89b91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glass</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plastic</td>\n",
              "      <td>482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>trash</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad7c433-b003-4330-933c-1422eac89b91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ad7c433-b003-4330-933c-1422eac89b91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a17515aa-20cd-4bfe-99b6-2f1abdac09a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "classes_df = pd.DataFrame(list(classes_representatives.items()), columns=['class', 'count'])\n",
        "classes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95be70e4-b5f7-4d75-8f22-3523543856c1",
      "metadata": {
        "id": "95be70e4-b5f7-4d75-8f22-3523543856c1"
      },
      "outputs": [],
      "source": [
        "sns.set_style('whitegrid')\n",
        "plt.figure(figsize = (10, 5))\n",
        "sns.barplot(data=classes_df, x='class', y='count')\n",
        "plt.title('The number of representatives of the label class (Original dataset)')\n",
        "# plt.savefig('graphs/original_barplot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc",
      "metadata": {
        "id": "3fa744ad-2bad-4bb6-b941-880a0766cddc"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=classes_df, column_name='count', title='Percentage ratio between label classes (Original dataset)',\n",
        "                  column_contains_count=True) # filename='graphs/original_piechart'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e59dd5b1-3054-4e06-a376-42362774907a",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "e59dd5b1-3054-4e06-a376-42362774907a"
      },
      "source": [
        "## Display representatives of each class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "158972c1-8c86-45a5-a767-c7b37b1b6608",
      "metadata": {
        "tags": [],
        "id": "158972c1-8c86-45a5-a767-c7b37b1b6608"
      },
      "source": [
        "### Cardboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d",
      "metadata": {
        "id": "8c54f6cf-5e6e-4c6a-8aba-7e41a527606d"
      },
      "outputs": [],
      "source": [
        "for cardboard_image_name in cardboard_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_cardboard, image_name=cardboard_image_name, title=cardboard_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74",
      "metadata": {
        "tags": [],
        "id": "0e30e87b-01c4-4e6a-8f4e-7ef81fffec74"
      },
      "source": [
        "### Glass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f",
      "metadata": {
        "id": "146b058c-c8ae-4bd2-a99c-789900d0ed5f"
      },
      "outputs": [],
      "source": [
        "for glass_image_name in glass_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_glass, image_name=glass_image_name, title=glass_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b",
      "metadata": {
        "tags": [],
        "id": "a8c79431-99ee-48ee-9dc6-447e4a2db56b"
      },
      "source": [
        "### Metal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d111dde7-c214-4c69-aa42-58c907e167d8",
      "metadata": {
        "id": "d111dde7-c214-4c69-aa42-58c907e167d8"
      },
      "outputs": [],
      "source": [
        "for metal_image_name in metal_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_metal, image_name=metal_image_name, title=metal_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
      "metadata": {
        "tags": [],
        "id": "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac"
      },
      "source": [
        "### Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0095e9ea-86af-404e-969d-d077462c81b4",
      "metadata": {
        "id": "0095e9ea-86af-404e-969d-d077462c81b4"
      },
      "outputs": [],
      "source": [
        "for paper_image_name in paper_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_paper, image_name=paper_image_name, title=paper_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a",
      "metadata": {
        "tags": [],
        "id": "7b6c2703-d81c-49b1-b6f9-0e3d8329b81a"
      },
      "source": [
        "### Plastic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05",
      "metadata": {
        "id": "5828c49e-8871-4ff3-9dff-fd8a6759bb05"
      },
      "outputs": [],
      "source": [
        "for plastic_image_name in plastic_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_plastic, image_name=plastic_image_name, title=plastic_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452",
      "metadata": {
        "tags": [],
        "id": "c62d1f5f-2dea-40f9-bfb9-23ad3ff89452"
      },
      "source": [
        "### Trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6",
      "metadata": {
        "id": "1daeeab6-5043-47a2-b9bd-3b6b2eec38b6"
      },
      "outputs": [],
      "source": [
        "for trash_image_name in trash_image_names[:5]:\n",
        "    load_display_image(root_path=source_path_trash, image_name=trash_image_name, title=trash_image_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b8c9cb-0be9-44f4-9952-beb639920617",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "94b8c9cb-0be9-44f4-9952-beb639920617"
      },
      "source": [
        "# Split data into train, validation and test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39",
      "metadata": {
        "id": "816fa6b4-1a9c-4020-ab88-83e2fd228a39"
      },
      "source": [
        "## Create folders for train/valid/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0",
      "metadata": {
        "id": "38efe25e-64ce-4075-b6b4-dd251c0550c0"
      },
      "outputs": [],
      "source": [
        "destination_path = '/content/garbage_classification_TrainValidTest/'\n",
        "\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "create_train_valid_test_dirs(root_path=destination_path, subdir_names=garbage_class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ce8b08-d600-431e-9365-395f20cf0402",
      "metadata": {
        "id": "70ce8b08-d600-431e-9365-395f20cf0402"
      },
      "source": [
        "## Split the data and save it in the appropriate folders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "8036996f-3ff8-4839-8ace-d9c5e1fbc3e5"
      },
      "source": [
        "### Split classes data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c322c4aa-2a09-4a8d-8ecd-b1d599f2d2a3",
        "outputId": "b3b9d7ef-5ce2-49e1-805e-76743f8806e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: train = 307\n",
            "cardboard: valid = 55\n",
            "cardboard: test = 41\n",
            "\n",
            "glass: train = 382\n",
            "glass: valid = 68\n",
            "glass: test = 51\n",
            "\n",
            "metal: train = 313\n",
            "metal: valid = 56\n",
            "metal: test = 41\n",
            "\n",
            "paper: train = 453\n",
            "paper: valid = 81\n",
            "paper: test = 60\n",
            "\n",
            "plastic: train = 368\n",
            "plastic: valid = 65\n",
            "plastic: test = 49\n",
            "\n",
            "trash: train = 104\n",
            "trash: valid = 19\n",
            "trash: test = 14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
        "\n",
        "for class_name in garbage_class_names:\n",
        "    split_class_data(source_dir_path=source_path, train_valid_test_paths=train_valid_test_paths,\n",
        "                 class_dir_name=class_name, train_test_split=0.9, train_valid_split=0.85, random_sample=False)\n",
        "\n",
        "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
        "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
        "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
        "\n",
        "    print(f\"{class_name}: train = {len(class_train_images)}\")\n",
        "    print(f\"{class_name}: valid = {len(class_valid_images)}\")\n",
        "    print(f\"{class_name}: test = {len(class_test_images)}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
      "metadata": {
        "id": "6c48c3ae-6c6d-4887-8c22-649ebeb751ef"
      },
      "source": [
        "#### Check classes distribution after spliting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51",
      "metadata": {
        "id": "e92e3f70-8a46-41bc-93de-d80a10d04f51"
      },
      "outputs": [],
      "source": [
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "classes_train_dict = {}\n",
        "classes_valid_dict = {}\n",
        "classes_test_dict = {}\n",
        "for class_name in garbage_class_names:\n",
        "    classes_train_dict[class_name] = 0\n",
        "    classes_valid_dict[class_name] = 0\n",
        "    classes_test_dict[class_name] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae8b16fc-ad6a-4320-b11a-0b5b2c54e20d",
        "outputId": "87c457d8-c029-4738-bf57-f94a0c89f428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes_train_dict = {'cardboard': 307, 'glass': 382, 'metal': 313, 'paper': 453, 'plastic': 368, 'trash': 104}\n",
            "classes_valid_dict = {'cardboard': 55, 'glass': 68, 'metal': 56, 'paper': 81, 'plastic': 65, 'trash': 19}\n",
            "classes_test_dict = {'cardboard': 41, 'glass': 51, 'metal': 41, 'paper': 60, 'plastic': 49, 'trash': 14}\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "train_valid_test_paths = [train_dir_path, valid_dir_path, test_dir_path]\n",
        "\n",
        "for class_name in garbage_class_names:\n",
        "    class_train_images = os.listdir(os.path.join(train_dir_path, class_name))\n",
        "    class_valid_images = os.listdir(os.path.join(valid_dir_path, class_name))\n",
        "    class_test_images = os.listdir(os.path.join(test_dir_path, class_name))\n",
        "\n",
        "    classes_train_dict[class_name] = len(class_train_images)\n",
        "    classes_valid_dict[class_name] = len(class_valid_images)\n",
        "    classes_test_dict[class_name] = len(class_test_images)\n",
        "\n",
        "print(f\"classes_train_dict = {classes_train_dict}\")\n",
        "print(f\"classes_valid_dict = {classes_valid_dict}\")\n",
        "print(f\"classes_test_dict = {classes_test_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "bee2846c-8dcb-49fb-a204-df5acc35368c",
        "outputId": "886f2cdc-c551-468a-f9c8-9b5c8ba39a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class  count\n",
              "0  cardboard    307\n",
              "1      glass    382\n",
              "2      metal    313\n",
              "3      paper    453\n",
              "4    plastic    368\n",
              "5      trash    104"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33a0842b-d886-4732-a9d2-02312509c3f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glass</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metal</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plastic</td>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>trash</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a0842b-d886-4732-a9d2-02312509c3f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33a0842b-d886-4732-a9d2-02312509c3f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-137538ec-8be6-4d17-8c60-93217d09dfe2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-137538ec-8be6-4d17-8c60-93217d09dfe2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-137538ec-8be6-4d17-8c60-93217d09dfe2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_classes_df = pd.DataFrame(list(classes_train_dict.items()), columns=['class', 'count'])\n",
        "valid_classes_df = pd.DataFrame(list(classes_valid_dict.items()), columns=['class', 'count'])\n",
        "test_classes_df = pd.DataFrame(list(classes_test_dict.items()), columns=['class', 'count'])\n",
        "\n",
        "train_classes_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2",
      "metadata": {
        "id": "96b623c5-50cf-4d0e-ab37-f519dbbcd7d2"
      },
      "source": [
        "##### Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4",
      "metadata": {
        "id": "0004beb7-5dd5-4e02-85d7-a39db34272f4"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=train_classes_df, column_name='count', title='Percentage ratio between label classes (Train dataset)',\n",
        "                  column_contains_count=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3",
      "metadata": {
        "id": "9fa0a44f-f1d1-420c-942b-94e1762bc6c3"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=train_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Train Data',\n",
        "                   filename=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae",
      "metadata": {
        "id": "42c3bfa8-5df8-49c8-8afc-d4d6ddf853ae"
      },
      "source": [
        "##### Valid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c742c2-33f7-436e-bd50-aeb229afbf10",
      "metadata": {
        "id": "93c742c2-33f7-436e-bd50-aeb229afbf10"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=valid_classes_df, column_name='count', title='Percentage ratio between label classes (Validation dataset)',\n",
        "                  column_contains_count=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26",
      "metadata": {
        "id": "3b0ec777-b947-4d76-abe3-0bc2133c1f26"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=valid_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Valid Data',\n",
        "                   filename=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d2c56e-aac4-4403-a89c-177d7584ca76",
      "metadata": {
        "id": "50d2c56e-aac4-4403-a89c-177d7584ca76"
      },
      "source": [
        "##### Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592",
      "metadata": {
        "id": "ecb0e6d3-cad7-4d68-9ea1-2a50f7445592"
      },
      "outputs": [],
      "source": [
        "display_pie_chart(df=test_classes_df, column_name='count', title='Percentage ratio between label classes (Test dataset)',\n",
        "                  column_contains_count=True, filename='graphs/test_piechart')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a51dc2-dff2-408c-818d-9e9b052699a6",
      "metadata": {
        "id": "81a51dc2-dff2-408c-818d-9e9b052699a6"
      },
      "outputs": [],
      "source": [
        "display_pie_charts(first_df=classes_df, second_df=test_classes_df, column='count',\n",
        "                   column_contains_count=True,\n",
        "                   first_chart_title='Original Data', second_chart_title='Test Data',\n",
        "                   filename='graphs/original_vs_test_piecharts')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ],
      "metadata": {
        "id": "mQE7_geHaYNI"
      },
      "id": "mQE7_geHaYNI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "iF2NpBGwTgKy"
      },
      "id": "iF2NpBGwTgKy"
    },
    {
      "cell_type": "code",
      "source": [
        "image_classes_filepaths = [train_dir_path + 'cardboard', train_dir_path + 'glass',\n",
        "                           train_dir_path + 'metal', train_dir_path + 'paper',\n",
        "                           train_dir_path + 'plastic', train_dir_path + 'trash']\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "show_images = False\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "  image_filenames = os.listdir(image_filepath)\n",
        "\n",
        "  for image_name in image_filenames:\n",
        "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      garbage_class_images[garbage_class_name].append(img)\n",
        "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
        "\n",
        "      if show_images:\n",
        "          display_image(img, title=image_name)\n",
        "\n",
        "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tXUGWXkTfKY",
        "outputId": "4ff5854b-7d3d-4d5c-c82c-bcccaaa06f5e"
      },
      "id": "2tXUGWXkTfKY",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: len(images) = 307\n",
            "glass: len(images) = 382\n",
            "metal: len(images) = 313\n",
            "paper: len(images) = 453\n",
            "plastic: len(images) = 368\n",
            "trash: len(images) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = img.shape[:2]\n",
        "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
        "target_size = (img_height, img_width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3czvCJIWO6O",
        "outputId": "64f2094c-4ef7-47e1-8691-ed9f89b1548e"
      },
      "id": "g3czvCJIWO6O",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_height = 384, img_width = 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
      ],
      "metadata": {
        "id": "49lwYs7vW5X-"
      },
      "id": "49lwYs7vW5X-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation"
      ],
      "metadata": {
        "id": "rMRZMug1axTK"
      },
      "id": "rMRZMug1axTK"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
        "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                  augm_images_dir_path=augmented_images_dir,\n",
        "                                  target_size=target_size,\n",
        "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIayHvfOLeZ1",
        "outputId": "e16fb28a-1d53-4909-9798-75b122f54d7e"
      },
      "id": "FIayHvfOLeZ1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 307\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 2149\n",
            "glass before augmentation: len(images) = 382\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 2674\n",
            "metal before augmentation: len(images) = 313\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 2191\n",
            "paper before augmentation: len(images) = 453\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 3171\n",
            "plastic before augmentation: len(images) = 368\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 2576\n",
            "trash before augmentation: len(images) = 104\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expacted output:\n",
        "cardboard before augmentation: len(images) = 307;\n",
        "cardboard after augmentation: len(images) = 2149\n",
        "\n",
        "glass before augmentation: len(images) = 382;\n",
        "glass after augmentation: len(images) = 2674\n",
        "\n",
        "metal before augmentation: len(images) = 313;\n",
        "metal after augmentation: len(images) = 2191\n",
        "\n",
        "paper before augmentation: len(images) = 453;\n",
        "paper after augmentation: len(images) = 3171\n",
        "\n",
        "plastic before augmentation: len(images) = 368;\n",
        "plastic after augmentation: len(images) = 2576\n",
        "\n",
        "trash before augmentation: len(images) = 104;\n",
        "trash after augmentation: len(images) = 728"
      ],
      "metadata": {
        "id": "_TZ7u46SaVaN"
      },
      "id": "_TZ7u46SaVaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### width_shift"
      ],
      "metadata": {
        "id": "SVoc99d2bFV6"
      },
      "id": "SVoc99d2bFV6"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhGL15Ira2tr",
        "outputId": "c9367e7a-c0f2-47a5-a21f-a914158681cc"
      },
      "id": "dhGL15Ira2tr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 307\n",
            "len(garbage_class_images[glass]) = 382\n",
            "len(garbage_class_images[metal]) = 313\n",
            "len(garbage_class_images[paper]) = 453\n",
            "len(garbage_class_images[plastic]) = 368\n",
            "len(garbage_class_images[trash]) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "width_shift_fraction = 0.1\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9--uJ-PkbGH5",
        "outputId": "e603ee55-d805-4447-d45b-d7bbcc78d3c7"
      },
      "id": "9--uJ-PkbGH5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 2149\n",
            "cardboard after augmentation: len(images) = 2763\n",
            "\n",
            "glass before augmentation: len(images) = 2674\n",
            "glass after augmentation: len(images) = 3438\n",
            "\n",
            "metal before augmentation: len(images) = 2191\n",
            "metal after augmentation: len(images) = 2817\n",
            "\n",
            "paper before augmentation: len(images) = 3171\n",
            "paper after augmentation: len(images) = 4077\n",
            "\n",
            "plastic before augmentation: len(images) = 2576\n",
            "plastic after augmentation: len(images) = 3312\n",
            "\n",
            "trash before augmentation: len(images) = 728\n",
            "trash after augmentation: len(images) = 936\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expacted output:\n",
        "cardboard before augmentation: len(images) = 2149;\n",
        "cardboard after augmentation: len(images) = 2149 + 307*2 = 2763\n",
        "\n",
        "glass before augmentation: len(images) = 2674;\n",
        "glass after augmentation: len(images) = 3438\n",
        "\n",
        "metal before augmentation: len(images) = 2191;\n",
        "metal after augmentation: len(images) = 2817\n",
        "\n",
        "paper before augmentation: len(images) = 3171;\n",
        "paper after augmentation: len(images) = 4077\n",
        "\n",
        "plastic before augmentation: len(images) = 2576;\n",
        "plastic after augmentation: len(images) = 3312\n",
        "\n",
        "trash before augmentation: len(images) = 728;\n",
        "trash after augmentation: len(images) = 936"
      ],
      "metadata": {
        "id": "cl36lkpgeR9X"
      },
      "id": "cl36lkpgeR9X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### height_shift"
      ],
      "metadata": {
        "id": "r1oj75sjbMPq"
      },
      "id": "r1oj75sjbMPq"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCysQhwUfG5f",
        "outputId": "c445f467-bbd2-495c-f705-b24fc1e8a696"
      },
      "id": "wCysQhwUfG5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 307\n",
            "len(garbage_class_images[glass]) = 382\n",
            "len(garbage_class_images[metal]) = 313\n",
            "len(garbage_class_images[paper]) = 453\n",
            "len(garbage_class_images[plastic]) = 368\n",
            "len(garbage_class_images[trash]) = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "height_shift_fraction = 0.10\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jqPyxqofQVu",
        "outputId": "f8aa356d-3b14-4dad-abc2-f5790cf8ab22"
      },
      "id": "-jqPyxqofQVu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 2763\n",
            "cardboard after augmentation: len(images) = 3377\n",
            "\n",
            "glass before augmentation: len(images) = 3438\n",
            "glass after augmentation: len(images) = 4202\n",
            "\n",
            "metal before augmentation: len(images) = 2817\n",
            "metal after augmentation: len(images) = 3443\n",
            "\n",
            "paper before augmentation: len(images) = 4077\n",
            "paper after augmentation: len(images) = 4983\n",
            "\n",
            "plastic before augmentation: len(images) = 3312\n",
            "plastic after augmentation: len(images) = 4048\n",
            "\n",
            "trash before augmentation: len(images) = 936\n",
            "trash after augmentation: len(images) = 1144\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### horizontal_flip"
      ],
      "metadata": {
        "id": "Nq6an5m7bYeU"
      },
      "id": "Nq6an5m7bYeU"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puc6cYtLf49y",
        "outputId": "47398cb6-218d-4eee-af4a-76fe20ad873f"
      },
      "id": "Puc6cYtLf49y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3377\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 3684\n",
            "glass before augmentation: len(images) = 4202\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 4584\n",
            "metal before augmentation: len(images) = 3443\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 3756\n",
            "paper before augmentation: len(images) = 4983\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 5436\n",
            "plastic before augmentation: len(images) = 4048\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 4416\n",
            "trash before augmentation: len(images) = 1144\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vertical_flip"
      ],
      "metadata": {
        "id": "xN_CBfSMbsNy"
      },
      "id": "xN_CBfSMbsNy"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2dbTtnjXPr",
        "outputId": "3da644e4-0b84-4f5c-fddf-1de416174350"
      },
      "id": "Uk2dbTtnjXPr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3684\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/cardboard\n",
            "cardboard after augmentation: len(images) = 3991\n",
            "\n",
            "glass before augmentation: len(images) = 4584\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/glass\n",
            "glass after augmentation: len(images) = 4966\n",
            "\n",
            "metal before augmentation: len(images) = 3756\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/metal\n",
            "metal after augmentation: len(images) = 4069\n",
            "\n",
            "paper before augmentation: len(images) = 5436\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/paper\n",
            "paper after augmentation: len(images) = 5889\n",
            "\n",
            "plastic before augmentation: len(images) = 4416\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/plastic\n",
            "plastic after augmentation: len(images) = 4784\n",
            "\n",
            "trash before augmentation: len(images) = 1248\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/train/trash\n",
            "trash after augmentation: len(images) = 1352\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zoom = scaling"
      ],
      "metadata": {
        "id": "wTLkX5eyb3ny"
      },
      "id": "wTLkX5eyb3ny"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "URnp4hbnb_kD"
      },
      "id": "URnp4hbnb_kD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(0.8, 1),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g127KTuBj3bC",
        "outputId": "2bbe1d68-e504-4878-960a-3a51da3f23fa"
      },
      "id": "g127KTuBj3bC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 3991\n",
            "cardboard after augmentation: len(images) = 4298\n",
            "\n",
            "glass before augmentation: len(images) = 4966\n",
            "glass after augmentation: len(images) = 5348\n",
            "\n",
            "metal before augmentation: len(images) = 4069\n",
            "metal after augmentation: len(images) = 4382\n",
            "\n",
            "paper before augmentation: len(images) = 5889\n",
            "paper after augmentation: len(images) = 6342\n",
            "\n",
            "plastic before augmentation: len(images) = 4784\n",
            "plastic after augmentation: len(images) = 5152\n",
            "\n",
            "trash before augmentation: len(images) = 1352\n",
            "trash after augmentation: len(images) = 1456\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "b8QlRMm8cQHR"
      },
      "id": "b8QlRMm8cQHR"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1, 1.2),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8koWMEdEmorg",
        "outputId": "7da8d697-c5c5-43e6-a8ae-a98b5a24eac9"
      },
      "id": "8koWMEdEmorg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4298\n",
            "cardboard after augmentation: len(images) = 4605\n",
            "\n",
            "glass before augmentation: len(images) = 5348\n",
            "glass after augmentation: len(images) = 5730\n",
            "\n",
            "metal before augmentation: len(images) = 4382\n",
            "metal after augmentation: len(images) = 4695\n",
            "\n",
            "paper before augmentation: len(images) = 6342\n",
            "paper after augmentation: len(images) = 6795\n",
            "\n",
            "plastic before augmentation: len(images) = 5152\n",
            "plastic after augmentation: len(images) = 5520\n",
            "\n",
            "trash before augmentation: len(images) = 1456\n",
            "trash after augmentation: len(images) = 1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift"
      ],
      "metadata": {
        "id": "M6N_HmcbcdN6"
      },
      "id": "M6N_HmcbcdN6"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.5, 0.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjIIZx-n-N7",
        "outputId": "e0d5747a-a803-4aa1-c412-c502595286a6"
      },
      "id": "LRjIIZx-n-N7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4605\n",
            "cardboard after augmentation: len(images) = 4912\n",
            "\n",
            "glass before augmentation: len(images) = 5730\n",
            "glass after augmentation: len(images) = 6112\n",
            "\n",
            "metal before augmentation: len(images) = 4695\n",
            "metal after augmentation: len(images) = 5008\n",
            "\n",
            "paper before augmentation: len(images) = 6795\n",
            "paper after augmentation: len(images) = 7248\n",
            "\n",
            "plastic before augmentation: len(images) = 5520\n",
            "plastic after augmentation: len(images) = 5888\n",
            "\n",
            "trash before augmentation: len(images) = 1560\n",
            "trash after augmentation: len(images) = 1664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.25, 0.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "target_size = (img_height, img_width)\n",
        "\n",
        "num_augmented_images = 1\n",
        "\n",
        "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
        "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                  augm_prefix='aug_blackBrightness_0.25', num_augm_images=num_augmented_images,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)"
      ],
      "metadata": {
        "id": "aWSH_5Fioxi1"
      },
      "id": "aWSH_5Fioxi1"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-iJpKwQo_hH",
        "outputId": "a86bab0f-99b8-400c-c2a8-11bd3ac3d18d"
      },
      "id": "R-iJpKwQo_hH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 4912\n",
            "cardboard after augmentation: len(images) = 5219\n",
            "\n",
            "glass before augmentation: len(images) = 6112\n",
            "glass after augmentation: len(images) = 6494\n",
            "\n",
            "metal before augmentation: len(images) = 5008\n",
            "metal after augmentation: len(images) = 5321\n",
            "\n",
            "paper before augmentation: len(images) = 7248\n",
            "paper after augmentation: len(images) = 7701\n",
            "\n",
            "plastic before augmentation: len(images) = 5888\n",
            "plastic after augmentation: len(images) = 6256\n",
            "\n",
            "trash before augmentation: len(images) = 1664\n",
            "trash after augmentation: len(images) = 1768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.5, 1.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "target_size = (img_height, img_width)\n",
        "\n",
        "num_augmented_images = 1\n",
        "\n",
        "perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=images, image_filenames=image_filenames,\n",
        "                                  augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                  augm_prefix='aug_ligthBrightness_1.5', num_augm_images=num_augmented_images,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)"
      ],
      "metadata": {
        "id": "VLthfnuCpTKv"
      },
      "id": "VLthfnuCpTKv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### contrast augmentation"
      ],
      "metadata": {
        "id": "OvIN0bJrdWjL"
      },
      "id": "OvIN0bJrdWjL"
    },
    {
      "cell_type": "code",
      "source": [
        "contrast_factor = 2.0\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9iw6kVhpe4g",
        "outputId": "03599552-1b9c-42a3-9d3e-46eb7cc87c95"
      },
      "id": "p9iw6kVhpe4g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 5219\n",
            "cardboard after augmentation: len(images) = 5526\n",
            "\n",
            "glass before augmentation: len(images) = 6494\n",
            "glass after augmentation: len(images) = 6876\n",
            "\n",
            "metal before augmentation: len(images) = 5321\n",
            "metal after augmentation: len(images) = 5634\n",
            "\n",
            "paper before augmentation: len(images) = 7701\n",
            "paper after augmentation: len(images) = 8154\n",
            "\n",
            "plastic before augmentation: len(images) = 6256\n",
            "plastic after augmentation: len(images) = 6624\n",
            "\n",
            "trash before augmentation: len(images) = 1768\n",
            "trash after augmentation: len(images) = 1872\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) augmentation"
      ],
      "metadata": {
        "id": "auf2c59BdgWR"
      },
      "id": "auf2c59BdgWR"
    },
    {
      "cell_type": "code",
      "source": [
        "hue_shift=180\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
        "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgEIQcbTqPIa",
        "outputId": "5004533f-fe56-490f-fc2e-9e914dc81c34"
      },
      "id": "xgEIQcbTqPIa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 5526\n",
            "cardboard after augmentation: len(images) = 5833\n",
            "\n",
            "glass before augmentation: len(images) = 6876\n",
            "glass after augmentation: len(images) = 7258\n",
            "\n",
            "metal before augmentation: len(images) = 5634\n",
            "metal after augmentation: len(images) = 5947\n",
            "\n",
            "paper before augmentation: len(images) = 8154\n",
            "paper after augmentation: len(images) = 8607\n",
            "\n",
            "plastic before augmentation: len(images) = 6624\n",
            "plastic after augmentation: len(images) = 6992\n",
            "\n",
            "trash before augmentation: len(images) = 1872\n",
            "trash after augmentation: len(images) = 1976\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### noise addition augmentation"
      ],
      "metadata": {
        "id": "bkNIrE5i9yff"
      },
      "id": "bkNIrE5i9yff"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_noisy_image(image=image)\n",
        "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "Q0yQQ7L091s1"
      },
      "id": "Q0yQQ7L091s1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reduce garbage image + background augmentation"
      ],
      "metadata": {
        "id": "5xs5E4lc92xt"
      },
      "id": "5xs5E4lc92xt"
    },
    {
      "cell_type": "code",
      "source": [
        "background_image_filepath = '/content/backgrounds/'\n",
        "background_image_names = os.listdir(background_image_filepath)\n",
        "background_images = []\n",
        "show_images = True\n",
        "\n",
        "for background_image_name in background_image_names:\n",
        "    if '.ipynb' in background_image_name:\n",
        "      continue\n",
        "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
        "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
        "    background_images.append(background_image)\n",
        "\n",
        "    if show_images:\n",
        "        display_image(background_image, title=background_image_name)"
      ],
      "metadata": {
        "id": "wpVxOJ_t-HH8"
      },
      "id": "wpVxOJ_t-HH8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1.2, 1.5),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    counter = 0\n",
        "    for background_image in background_images:\n",
        "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
        "                                                       image=image,\n",
        "                                                       background_image=background_image,\n",
        "                                                       source_path=image_class_filepath,\n",
        "                                                       image_name=image_name)\n",
        "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
        "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "      counter += 1\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "506V4KEx-AqO"
      },
      "id": "506V4KEx-AqO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift + contrast augmentation"
      ],
      "metadata": {
        "id": "rwEBRaCz-A13"
      },
      "id": "rwEBRaCz-A13"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.35, 0.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "aMm3JU0z-P18"
      },
      "id": "aMm3JU0z-P18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) + brightness + contrast augmentation"
      ],
      "metadata": {
        "id": "QQTigweq-QHk"
      },
      "id": "QQTigweq-QHk"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "hue_shift=170\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
        "\n",
        "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "id": "2lA2U8-j-Ztj"
      },
      "id": "2lA2U8-j-Ztj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save train directory"
      ],
      "metadata": {
        "id": "hDpVqXyVqtoX"
      },
      "id": "hDpVqXyVqtoX"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/train.zip /content/garbage_classification_TrainValidTest/train"
      ],
      "metadata": {
        "id": "I2RYqgC7qsAe"
      },
      "id": "I2RYqgC7qsAe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valid"
      ],
      "metadata": {
        "id": "vH1WzuiGl9J7"
      },
      "id": "vH1WzuiGl9J7"
    },
    {
      "cell_type": "code",
      "source": [
        "image_classes_filepaths = [valid_dir_path + 'cardboard', valid_dir_path + 'glass',\n",
        "                           valid_dir_path + 'metal', valid_dir_path + 'paper',\n",
        "                           valid_dir_path + 'plastic', valid_dir_path + 'trash']\n",
        "garbage_class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "garbage_class_images = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "garbage_class_image_names = {'cardboard': [], 'glass': [], 'metal': [], 'paper': [], 'plastic': [], 'trash': []}\n",
        "show_images = False\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "  image_filenames = os.listdir(image_filepath)\n",
        "\n",
        "  for image_name in image_filenames:\n",
        "      img = cv2.imread(os.path.join(image_filepath, image_name))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      garbage_class_images[garbage_class_name].append(img)\n",
        "      garbage_class_image_names[garbage_class_name].append(image_name)\n",
        "\n",
        "      if show_images:\n",
        "          display_image(img, title=image_name)\n",
        "\n",
        "  print(f\"{garbage_class_name}: len(images) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhEFaLTPm7sj",
        "outputId": "657b6aad-d653-4e4d-9f52-aae0148c745b"
      },
      "id": "xhEFaLTPm7sj",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard: len(images) = 55\n",
            "glass: len(images) = 68\n",
            "metal: len(images) = 56\n",
            "paper: len(images) = 81\n",
            "plastic: len(images) = 65\n",
            "trash: len(images) = 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = img.shape[:2]\n",
        "print(f\"img_height = {img_height}, img_width = {img_width}\")\n",
        "target_size = (img_height, img_width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX3lA1zTrK-N",
        "outputId": "2107eaec-7141-4d3b-9143-18e76af0a64a"
      },
      "id": "GX3lA1zTrK-N",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_height = 384, img_width = 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View image example"
      ],
      "metadata": {
        "id": "LhPjOZiNuN0O"
      },
      "id": "LhPjOZiNuN0O"
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(img=garbage_class_images['cardboard'][1], title=garbage_class_image_names['cardboard'][1])"
      ],
      "metadata": {
        "id": "kW0x9NzFrLpk"
      },
      "id": "kW0x9NzFrLpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation"
      ],
      "metadata": {
        "id": "Wm0HzUnim4GY"
      },
      "id": "Wm0HzUnim4GY"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_rotation_augmentation(rotation_range=[-10, 10], images=garbage_class_images[garbage_class_name],\n",
        "                                  image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                  augm_images_dir_path=augmented_images_dir,\n",
        "                                  target_size=target_size,\n",
        "                                  augm_prefix='aug_Rotation', num_augm_images=2,\n",
        "                                  save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3n4ETjxl_px",
        "outputId": "b7d8ae91-da45-4656-b3d9-302817b0cb65"
      },
      "id": "s3n4ETjxl_px",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 55\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 385\n",
            "glass before augmentation: len(images) = 68\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 476\n",
            "metal before augmentation: len(images) = 56\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 392\n",
            "paper before augmentation: len(images) = 81\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 567\n",
            "plastic before augmentation: len(images) = 65\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 455\n",
            "trash before augmentation: len(images) = 19\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### width_shift"
      ],
      "metadata": {
        "id": "S1YCpPVUryl2"
      },
      "id": "S1YCpPVUryl2"
    },
    {
      "cell_type": "code",
      "source": [
        "for garbage_class_name in garbage_class_names:\n",
        "  print(f\"len(garbage_class_images[{garbage_class_name}]) = {len(garbage_class_images[garbage_class_name])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdCBVionsCIl",
        "outputId": "4d50c8d9-beb3-4da1-8278-3a78fa1eb747"
      },
      "id": "QdCBVionsCIl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(garbage_class_images[cardboard]) = 55\n",
            "len(garbage_class_images[glass]) = 68\n",
            "len(garbage_class_images[metal]) = 56\n",
            "len(garbage_class_images[paper]) = 81\n",
            "len(garbage_class_images[plastic]) = 65\n",
            "len(garbage_class_images[trash]) = 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "width_shift_fraction = 0.1\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=width_shift_fraction)\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_width_shift_image(image=image, width_shift_fraction=(-width_shift_fraction))\n",
        "    augmented_image_name = f\"aug_wShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yps6lh8nsPcp",
        "outputId": "7a90f4bb-3240-4201-d121-8a9432692764"
      },
      "id": "Yps6lh8nsPcp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 385\n",
            "cardboard after augmentation: len(images) = 495\n",
            "\n",
            "glass before augmentation: len(images) = 476\n",
            "glass after augmentation: len(images) = 612\n",
            "\n",
            "metal before augmentation: len(images) = 392\n",
            "metal after augmentation: len(images) = 504\n",
            "\n",
            "paper before augmentation: len(images) = 567\n",
            "paper after augmentation: len(images) = 729\n",
            "\n",
            "plastic before augmentation: len(images) = 455\n",
            "plastic after augmentation: len(images) = 585\n",
            "\n",
            "trash before augmentation: len(images) = 133\n",
            "trash after augmentation: len(images) = 171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### height_shift"
      ],
      "metadata": {
        "id": "iDPvcoMgseEW"
      },
      "id": "iDPvcoMgseEW"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "height_shift_fraction = 0.10\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=height_shift_fraction)\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    augmented_image = get_height_shift_image(image=image, height_shift_fraction=(-height_shift_fraction))\n",
        "    augmented_image_name = f\"aug_hShift_{image_name.split('.')[0]}_1.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2pfiHsBskgP",
        "outputId": "276035a5-90c5-4cb6-90d1-937e907e5171"
      },
      "id": "U2pfiHsBskgP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 495\n",
            "cardboard after augmentation: len(images) = 605\n",
            "\n",
            "glass before augmentation: len(images) = 612\n",
            "glass after augmentation: len(images) = 748\n",
            "\n",
            "metal before augmentation: len(images) = 504\n",
            "metal after augmentation: len(images) = 616\n",
            "\n",
            "paper before augmentation: len(images) = 729\n",
            "paper after augmentation: len(images) = 891\n",
            "\n",
            "plastic before augmentation: len(images) = 585\n",
            "plastic after augmentation: len(images) = 715\n",
            "\n",
            "trash before augmentation: len(images) = 171\n",
            "trash after augmentation: len(images) = 209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### horizontal_flip"
      ],
      "metadata": {
        "id": "NdonW8OusrtF"
      },
      "id": "NdonW8OusrtF"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=1, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_hFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5EvjcJsxD8",
        "outputId": "8affd288-5557-4295-977d-6629054cf8eb"
      },
      "id": "FQ5EvjcJsxD8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 605\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 660\n",
            "glass before augmentation: len(images) = 748\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 816\n",
            "metal before augmentation: len(images) = 616\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 672\n",
            "paper before augmentation: len(images) = 891\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 972\n",
            "plastic before augmentation: len(images) = 715\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 780\n",
            "trash before augmentation: len(images) = 209\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vertical_flip"
      ],
      "metadata": {
        "id": "Lxd7HGmlsyRc"
      },
      "id": "Lxd7HGmlsyRc"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  print(f\"augm_images_dir_path = {augmented_images_dir}\")\n",
        "  perform_cv2_flip_augmentation(flip_code=0, images=garbage_class_images[garbage_class_name],\n",
        "                                image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                augm_images_dir_path=augmented_images_dir, target_size=target_size,\n",
        "                                augm_prefix='aug_vFlip', num_augm_images=1,\n",
        "                                save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-TBIPuzs-K9",
        "outputId": "de8f8851-772e-45c5-e3a4-ab34c08953c4"
      },
      "id": "k-TBIPuzs-K9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 660\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/cardboard\n",
            "cardboard after augmentation: len(images) = 715\n",
            "\n",
            "glass before augmentation: len(images) = 816\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/glass\n",
            "glass after augmentation: len(images) = 884\n",
            "\n",
            "metal before augmentation: len(images) = 672\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/metal\n",
            "metal after augmentation: len(images) = 728\n",
            "\n",
            "paper before augmentation: len(images) = 972\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/paper\n",
            "paper after augmentation: len(images) = 1053\n",
            "\n",
            "plastic before augmentation: len(images) = 780\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/plastic\n",
            "plastic after augmentation: len(images) = 845\n",
            "\n",
            "trash before augmentation: len(images) = 228\n",
            "augm_images_dir_path = /content/garbage_classification_TrainValidTest/valid/trash\n",
            "trash after augmentation: len(images) = 247\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zoom = scaling"
      ],
      "metadata": {
        "id": "oZNmeaEis_M9"
      },
      "id": "oZNmeaEis_M9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Enlarge the image (bring it closer to the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "PLEmuhGMtKR2"
      },
      "id": "PLEmuhGMtKR2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(0.8, 1),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_iZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC_mli1ptJFM",
        "outputId": "20a2f789-b1a1-4c76-9f66-c6d0bc0b8d36"
      },
      "id": "oC_mli1ptJFM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 715\n",
            "cardboard after augmentation: len(images) = 770\n",
            "\n",
            "glass before augmentation: len(images) = 884\n",
            "glass after augmentation: len(images) = 952\n",
            "\n",
            "metal before augmentation: len(images) = 728\n",
            "metal after augmentation: len(images) = 784\n",
            "\n",
            "paper before augmentation: len(images) = 1053\n",
            "paper after augmentation: len(images) = 1134\n",
            "\n",
            "plastic before augmentation: len(images) = 845\n",
            "plastic after augmentation: len(images) = 910\n",
            "\n",
            "trash before augmentation: len(images) = 247\n",
            "trash after augmentation: len(images) = 266\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduce the image (move it away from the viewer) - ImageDataGenerator +"
      ],
      "metadata": {
        "id": "3CXocmX_tJRk"
      },
      "id": "3CXocmX_tJRk"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define your augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1, 1.2),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_dZoom', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V716jtPotgB1",
        "outputId": "08731f33-8fa6-4598-e015-6eb9fc159511"
      },
      "id": "V716jtPotgB1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 770\n",
            "cardboard after augmentation: len(images) = 825\n",
            "\n",
            "glass before augmentation: len(images) = 952\n",
            "glass after augmentation: len(images) = 1020\n",
            "\n",
            "metal before augmentation: len(images) = 784\n",
            "metal after augmentation: len(images) = 840\n",
            "\n",
            "paper before augmentation: len(images) = 1134\n",
            "paper after augmentation: len(images) = 1215\n",
            "\n",
            "plastic before augmentation: len(images) = 910\n",
            "plastic after augmentation: len(images) = 975\n",
            "\n",
            "trash before augmentation: len(images) = 266\n",
            "trash after augmentation: len(images) = 285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift"
      ],
      "metadata": {
        "id": "zLqDaHmgtgTd"
      },
      "id": "zLqDaHmgtgTd"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.5, 0.5),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_blackBrightness_0.5', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gec8GLoctvh1",
        "outputId": "fe2a9f65-82c5-47a6-9d5c-ae8480e01c1c"
      },
      "id": "Gec8GLoctvh1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 825\n",
            "cardboard after augmentation: len(images) = 880\n",
            "\n",
            "glass before augmentation: len(images) = 1020\n",
            "glass after augmentation: len(images) = 1088\n",
            "\n",
            "metal before augmentation: len(images) = 840\n",
            "metal after augmentation: len(images) = 896\n",
            "\n",
            "paper before augmentation: len(images) = 1215\n",
            "paper after augmentation: len(images) = 1296\n",
            "\n",
            "plastic before augmentation: len(images) = 975\n",
            "plastic after augmentation: len(images) = 1040\n",
            "\n",
            "trash before augmentation: len(images) = 285\n",
            "trash after augmentation: len(images) = 304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.25),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  # Perform augmentation\n",
        "  perform_ImageDataGen_augmentation(imageDataGenerator=datagen, images=garbage_class_images[garbage_class_name],\n",
        "                                    image_filenames=garbage_class_image_names[garbage_class_name],\n",
        "                                    augm_images_dir_path=augmented_images_dir,\n",
        "                                    target_size=target_size,\n",
        "                                    augm_prefix='aug_ligthBrightness_1.25', num_augm_images=1,\n",
        "                                    save_augm_image=True, display_orig_augm_images=False)\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbJMQn6lt-3e",
        "outputId": "399fae71-6896-40a7-fce3-379759377360"
      },
      "id": "AbJMQn6lt-3e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 880\n",
            "cardboard after augmentation: len(images) = 935\n",
            "\n",
            "glass before augmentation: len(images) = 1088\n",
            "glass after augmentation: len(images) = 1156\n",
            "\n",
            "metal before augmentation: len(images) = 896\n",
            "metal after augmentation: len(images) = 952\n",
            "\n",
            "paper before augmentation: len(images) = 1296\n",
            "paper after augmentation: len(images) = 1377\n",
            "\n",
            "plastic before augmentation: len(images) = 1040\n",
            "plastic after augmentation: len(images) = 1105\n",
            "\n",
            "trash before augmentation: len(images) = 304\n",
            "trash after augmentation: len(images) = 323\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### contrast augmentation"
      ],
      "metadata": {
        "id": "lADCJADjtvxU"
      },
      "id": "lADCJADjtvxU"
    },
    {
      "cell_type": "code",
      "source": [
        "contrast_factor = 2.0\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_contrast_augmentation_image(image=image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KyAabx-uLV0",
        "outputId": "09d52fe8-6667-45bb-9d22-52c495fa88fd"
      },
      "id": "2KyAabx-uLV0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 935\n",
            "cardboard after augmentation: len(images) = 990\n",
            "\n",
            "glass before augmentation: len(images) = 1156\n",
            "glass after augmentation: len(images) = 1224\n",
            "\n",
            "metal before augmentation: len(images) = 952\n",
            "metal after augmentation: len(images) = 1008\n",
            "\n",
            "paper before augmentation: len(images) = 1377\n",
            "paper after augmentation: len(images) = 1458\n",
            "\n",
            "plastic before augmentation: len(images) = 1105\n",
            "plastic after augmentation: len(images) = 1170\n",
            "\n",
            "trash before augmentation: len(images) = 323\n",
            "trash after augmentation: len(images) = 342\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) augmentation"
      ],
      "metadata": {
        "id": "xPP3kC0vuLgD"
      },
      "id": "xPP3kC0vuLgD"
    },
    {
      "cell_type": "code",
      "source": [
        "hue_shift=180\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_hsv_image(image=image, hue_shift=hue_shift)\n",
        "    augmented_image_name = f\"aug_hsv_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypPMgGi6udIm",
        "outputId": "1acc57ef-3593-4a56-b3f2-209ba3cdc8bf"
      },
      "id": "ypPMgGi6udIm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 990\n",
            "cardboard after augmentation: len(images) = 1045\n",
            "\n",
            "glass before augmentation: len(images) = 1224\n",
            "glass after augmentation: len(images) = 1292\n",
            "\n",
            "metal before augmentation: len(images) = 1008\n",
            "metal after augmentation: len(images) = 1064\n",
            "\n",
            "paper before augmentation: len(images) = 1458\n",
            "paper after augmentation: len(images) = 1539\n",
            "\n",
            "plastic before augmentation: len(images) = 1170\n",
            "plastic after augmentation: len(images) = 1235\n",
            "\n",
            "trash before augmentation: len(images) = 342\n",
            "trash after augmentation: len(images) = 361\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### noise addition augmentation"
      ],
      "metadata": {
        "id": "Y1qLJ2g506nN"
      },
      "id": "Y1qLJ2g506nN"
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_noisy_image(image=image)\n",
        "    augmented_image_name = f\"aug_Noise_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGJnMe4Y1Pvz",
        "outputId": "0f843702-4ce9-498d-aff6-374275727afb"
      },
      "id": "xGJnMe4Y1Pvz",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 55\n",
            "cardboard after augmentation: len(images) = 110\n",
            "\n",
            "glass before augmentation: len(images) = 68\n",
            "glass after augmentation: len(images) = 136\n",
            "\n",
            "metal before augmentation: len(images) = 56\n",
            "metal after augmentation: len(images) = 112\n",
            "\n",
            "paper before augmentation: len(images) = 81\n",
            "paper after augmentation: len(images) = 162\n",
            "\n",
            "plastic before augmentation: len(images) = 65\n",
            "plastic after augmentation: len(images) = 130\n",
            "\n",
            "trash before augmentation: len(images) = 19\n",
            "trash after augmentation: len(images) = 38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reduce garbage image + background augmentation"
      ],
      "metadata": {
        "id": "5h2Ggtv72gdt"
      },
      "id": "5h2Ggtv72gdt"
    },
    {
      "cell_type": "code",
      "source": [
        "background_image_filepath = '/content/backgrounds/'\n",
        "background_image_names = os.listdir(background_image_filepath)\n",
        "background_images = []\n",
        "show_images = True\n",
        "\n",
        "for background_image_name in background_image_names:\n",
        "    if '.ipynb' in background_image_name:\n",
        "      continue\n",
        "    background_image = cv2.imread(os.path.join(background_image_filepath, background_image_name))\n",
        "    background_image = cv2.cvtColor(background_image, cv2.COLOR_BGR2RGB)\n",
        "    background_images.append(background_image)\n",
        "\n",
        "    if show_images:\n",
        "        display_image(background_image, title=background_image_name)"
      ],
      "metadata": {
        "id": "bc7ngXmJ2lNM"
      },
      "id": "bc7ngXmJ2lNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    zoom_range=(1.2, 1.5),\n",
        "    fill_mode='constant'\n",
        ")\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    counter = 0\n",
        "    for background_image in background_images:\n",
        "      augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n",
        "                                                       image=image,\n",
        "                                                       background_image=background_image,\n",
        "                                                       source_path=image_class_filepath,\n",
        "                                                       image_name=image_name)\n",
        "      augmented_image_name = f\"aug_resizedBackground_{image_name.split('.')[0]}_{counter}.jpg\"\n",
        "      augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "      cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "      counter += 1\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "8Ep7abI-3JSQ",
        "outputId": "fa1f25da-6584-47da-84a5-afdd583483cb"
      },
      "id": "8Ep7abI-3JSQ",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 176M/176M [00:00<00:00, 109GB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard after augmentation: len(images) = 330\n",
            "\n",
            "glass before augmentation: len(images) = 136\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5e37bfbb25d2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbackground_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackground_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       augmented_image = get_augmented_background_image(imageDataGenerator=datagen,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                        \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                        \u001b[0mbackground_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackground_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-dae93a06895b>\u001b[0m in \u001b[0;36mget_augmented_background_image\u001b[0;34m(imageDataGenerator, image, background_image, source_path, image_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maugmented_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mpil_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Convert PIL image to OpenCV format (NumPy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-488e2f06e975>\u001b[0m in \u001b[0;36mremove_background\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Removing the background from the given Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Convert the output image to RGB mode (removing transparency)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/bg.py\u001b[0m in \u001b[0;36mremove\u001b[0;34m(data, alpha_matting, alpha_matting_foreground_threshold, alpha_matting_background_threshold, alpha_matting_erode_size, session, only_mask, post_process_mask, bgcolor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u2net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/session_factory.py\u001b[0m in \u001b[0;36mnew_session\u001b[0;34m(model_name, providers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msess_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter_op_num_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OMP_NUM_THREADS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_opts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/sessions/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, sess_opts, providers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         self.inner_session = ort.InferenceSession(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msess_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess_opts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rembg/sessions/u2net.py\u001b[0m in \u001b[0;36mdownload_models\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.name(*args, **kwargs)}.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         pooch.retrieve(\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;34m\"https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/core.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(url, known_hash, fname, path, processor, downloader, progressbar)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"download\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/core.py\u001b[0m in \u001b[0;36mdownload_action\u001b[0;34m(path, known_hash)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"download\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Downloading\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhash_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Updating\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/hashes.py\u001b[0m in \u001b[0;36mhash_matches\u001b[0;34m(fname, known_hash, strict, source)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mknown_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pooch/hashes.py\u001b[0m in \u001b[0;36mfile_hash\u001b[0;34m(fname, alg)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brightness_shift + contrast augmentation"
      ],
      "metadata": {
        "id": "m0g3W4Fr6lR2"
      },
      "id": "m0g3W4Fr6lR2"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(0.35, 0.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image_name = f\"aug_darkBrightness_Contrast_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBBS121o6x0u",
        "outputId": "86c4a56e-a743-4e1b-9853-66b9c7207217"
      },
      "id": "TBBS121o6x0u",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 330\n",
            "cardboard after augmentation: len(images) = 385\n",
            "\n",
            "glass before augmentation: len(images) = 212\n",
            "glass after augmentation: len(images) = 280\n",
            "\n",
            "metal before augmentation: len(images) = 112\n",
            "metal after augmentation: len(images) = 168\n",
            "\n",
            "paper before augmentation: len(images) = 162\n",
            "paper after augmentation: len(images) = 243\n",
            "\n",
            "plastic before augmentation: len(images) = 130\n",
            "plastic after augmentation: len(images) = 195\n",
            "\n",
            "trash before augmentation: len(images) = 38\n",
            "trash after augmentation: len(images) = 57\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### color space transformations (HSV) + brightness + contrast augmentation"
      ],
      "metadata": {
        "id": "9uPP8ROm7bB9"
      },
      "id": "9uPP8ROm7bB9"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    brightness_range=(1.25, 1.50),\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "contrast_factor=2.0\n",
        "hue_shift=170\n",
        "\n",
        "for image_class_filepath, garbage_class_name in zip(image_classes_filepaths, garbage_class_names):\n",
        "  image_filepath = image_class_filepath\n",
        "\n",
        "  image_names = os.listdir(image_filepath)\n",
        "  augmented_images_dir = image_class_filepath\n",
        "  print(f\"{garbage_class_name} before augmentation: len(images) = {len(image_names)}\")\n",
        "\n",
        "  for image, image_name in zip(garbage_class_images[garbage_class_name], garbage_class_image_names[garbage_class_name]):\n",
        "\n",
        "    augmented_image = get_ImageDataGen_image(imageDataGenerator=datagen, image=image)\n",
        "    augmented_image = get_contrast_augmentation_image(image=augmented_image, contrast_factor=contrast_factor)\n",
        "    augmented_image = get_hsv_image(image=augmented_image, hue_shift=hue_shift)\n",
        "\n",
        "    augmented_image_name = f\"aug_lightBrightness_Contrast_HSV_{image_name.split('.')[0]}_0.jpg\"\n",
        "    augmented_image_path = os.path.join(augmented_images_dir, augmented_image_name)\n",
        "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  image_names = os.listdir(image_class_filepath)\n",
        "  print(f\"{garbage_class_name} after augmentation: len(images) = {len(image_names)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Kv50wZ7jK_",
        "outputId": "9bc899ec-2993-4028-c3ea-b0f7b958f4ea"
      },
      "id": "a0Kv50wZ7jK_",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard before augmentation: len(images) = 385\n",
            "cardboard after augmentation: len(images) = 440\n",
            "\n",
            "glass before augmentation: len(images) = 280\n",
            "glass after augmentation: len(images) = 348\n",
            "\n",
            "metal before augmentation: len(images) = 168\n",
            "metal after augmentation: len(images) = 224\n",
            "\n",
            "paper before augmentation: len(images) = 243\n",
            "paper after augmentation: len(images) = 324\n",
            "\n",
            "plastic before augmentation: len(images) = 195\n",
            "plastic after augmentation: len(images) = 260\n",
            "\n",
            "trash before augmentation: len(images) = 57\n",
            "trash after augmentation: len(images) = 76\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save valid directory"
      ],
      "metadata": {
        "id": "HHp2s0HkuwPs"
      },
      "id": "HHp2s0HkuwPs"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/valid.zip /content/garbage_classification_TrainValidTest/valid"
      ],
      "metadata": {
        "id": "Rfgi2wPeuy0l"
      },
      "id": "Rfgi2wPeuy0l",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save test directory"
      ],
      "metadata": {
        "id": "YEiPqicE3SOv"
      },
      "id": "YEiPqicE3SOv"
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/test.zip /content/garbage_classification_TrainValidTest/test"
      ],
      "metadata": {
        "id": "00TsaCNs3Vge"
      },
      "id": "00TsaCNs3Vge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c",
      "metadata": {
        "id": "f3eb9d9a-0496-48a9-886d-09fa9887b70c"
      },
      "source": [
        "# Train CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc62474-9df5-4c7d-95ab-f24e06263167",
      "metadata": {
        "id": "edc62474-9df5-4c7d-95ab-f24e06263167"
      },
      "source": [
        "## Create train and valid datagenerators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ef1aa3-a7bc-4f2f-9628-6c3e46da1b7e",
        "outputId": "9d93a706-dc4c-402a-c2e6-1f4d2e1ca701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1927 images belonging to 6 classes.\n",
            "Found 1672 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir_path = '/content/garbage_classification_TrainValidTest/train/'\n",
        "valid_dir_path = '/content/garbage_classification_TrainValidTest/valid/'\n",
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir_path,\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(300, 300))\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir_path,\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(300, 300))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1",
      "metadata": {
        "id": "13283774-a7c5-4e2b-ae38-7f036153ccf1"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take into account the imbalance of garbage classes of the studied dataset"
      ],
      "metadata": {
        "id": "VOeyt-j4AwnF"
      },
      "id": "VOeyt-j4AwnF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/69783897/compute-class-weight-function-issue-in-sklearn-library-when-used-in-keras-cl"
      ],
      "metadata": {
        "id": "ajuBi4RhH-6G"
      },
      "id": "ajuBi4RhH-6G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the true labels for the test data\n",
        "true_labels = train_generator.classes\n",
        "\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes = np.unique(true_labels),\n",
        "                                     y = true_labels)\n",
        "\n",
        "\n",
        "# Create a dictionary to store the class weights\n",
        "# class_weight_dict = dict(zip(class_labels, class_weights)) - for better understanding\n",
        "class_weight_dict = dict(zip(np.unique(true_labels), class_weights))\n",
        "\n",
        "# Print the class weights\n",
        "print(\"Class Weights:\", class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXk2zc0A5sz",
        "outputId": "7d476ec7-e193-4a85-f0fe-b800d4bdae69"
      },
      "id": "voXk2zc0A5sz",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0461454940282302, 1: 0.8407504363001745, 2: 1.0260915867944622, 3: 0.7089771891096395, 4: 0.8727355072463768, 5: 3.0881410256410255}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"len(true_labels) = {len(true_labels)}\")\n",
        "print(f\"true_labels = {true_labels}\")\n",
        "\n",
        "print(f\"len(class_labels) = {len(class_labels)}\")\n",
        "print(f\"class_labels = {class_labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtCi21DCJdPV",
        "outputId": "fc32524c-0238-4852-e55d-c21d2adf090f"
      },
      "id": "xtCi21DCJdPV",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(true_labels) = 1927\n",
            "true_labels = [0 0 0 ... 5 5 5]\n",
            "len(class_labels) = 6\n",
            "class_labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the CNN model"
      ],
      "metadata": {
        "id": "jY64rbItA8lz"
      },
      "id": "jY64rbItA8lz"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "30815f75-7eb4-484e-bf11-9c03f9394b89",
      "metadata": {
        "id": "30815f75-7eb4-484e-bf11-9c03f9394b89"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.95):\n",
        "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1d2ef1f-e109-424e-b0f8-5bcf08d34c4d",
        "outputId": "05e189f8-5caa-4dd1-f1b6-5dff24fedfda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 149, 149, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 128)       73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 645248)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               82591872  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82685894 (315.42 MB)\n",
            "Trainable params: 82685894 (315.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential(layers=[\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "b0afca06-7431-4884-9c44-60d418f40731",
      "metadata": {
        "id": "b0afca06-7431-4884-9c44-60d418f40731"
      },
      "outputs": [],
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "my_callback = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1",
      "metadata": {
        "id": "7b0a1c58-2a7b-4429-802e-4a53cf225ea1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df2b073-47f0-48ea-991d-9914b1682f86",
      "metadata": {
        "id": "0df2b073-47f0-48ea-991d-9914b1682f86"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=valid_generator,\n",
        "                    callbacks=[early_stopping_callback, my_callback],\n",
        "                    class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the CNN model using Transfer Learning (ResNet50)"
      ],
      "metadata": {
        "id": "fghIDHP3LUOB"
      },
      "id": "fghIDHP3LUOB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example from Kaggle"
      ],
      "metadata": {
        "id": "HtK1_C35Rcjy"
      },
      "id": "HtK1_C35Rcjy"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "B2Rv64TmLZtY"
      },
      "id": "B2Rv64TmLZtY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/garbage classification/Garbage classification'\n",
        "valid_path = '/content/garbage classification/Garbage classification'\n",
        "\n",
        "\n",
        "# extract images to training set by applying data preprocessing and data augmentation\n",
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.1).flow_from_directory(\n",
        "    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
        "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')\n",
        "\n",
        "\n",
        "# extract images to validation set\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    validation_split=0.1).flow_from_directory(\n",
        "    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal',\n",
        "                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTgy37lHRbwC",
        "outputId": "8906f290-ed81-45f7-c702-8407aff0f384"
      },
      "id": "aTgy37lHRbwC",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2276 images belonging to 6 classes.\n",
            "Found 251 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Load pre-trained ResNet50 model without the top classification layers\n",
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SHAPE))\n",
        "\n",
        "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated\n",
        "# during training inorder to extract features\n",
        "base_model.trainable=False\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "# add global average pooling layer\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# add densely-connected NN layer with 512 hidden units\n",
        "model.add(Dense(units=512, activation='relu'))  # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                 # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 128 hidden units\n",
        "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
        "model.add(tf.keras.layers.BatchNormalization())                # normalize and scale inputs or activations\n",
        "model.add(tf.keras.layers.Dropout(0.2))                        # applies dopout to the input which will randomly disable 20% of hidden units\n",
        "\n",
        "# add densely-connected NN layer with 6 hidden units\n",
        "model.add(Dense(units=6, activation='softmax')) # use Softmax activation function to do final predictions\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao_b4zb-Pj20",
        "outputId": "f94ea1a6-04b8-4193-b667-8f63519df217"
      },
      "id": "ao_b4zb-Pj20",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234698864/234698864 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59489030 (226.93 MB)\n",
            "Trainable params: 1116806 (4.26 MB)\n",
            "Non-trainable params: 58372224 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "WWj53UGwSFPn"
      },
      "id": "WWj53UGwSFPn",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "   train_batches,\n",
        "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
        "    epochs=20,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [es, mc],)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQZpYujSJKX",
        "outputId": "252b4a7a-1a2a-44d9-efff-863bf5428ec9"
      },
      "id": "yrQZpYujSJKX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-8270e9ae3426>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 1.2042 - accuracy: 0.5804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 62s 298ms/step - loss: 1.2042 - accuracy: 0.5804 - val_loss: 0.5920 - val_accuracy: 0.7649\n",
            "Epoch 2/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.7645"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 39s 274ms/step - loss: 0.6552 - accuracy: 0.7645 - val_loss: 0.4078 - val_accuracy: 0.8406\n",
            "Epoch 3/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.8212"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 267ms/step - loss: 0.5240 - accuracy: 0.8212 - val_loss: 0.3442 - val_accuracy: 0.8845\n",
            "Epoch 4/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 48s 339ms/step - loss: 0.4281 - accuracy: 0.8603 - val_loss: 0.3210 - val_accuracy: 0.9004\n",
            "Epoch 5/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 267ms/step - loss: 0.3777 - accuracy: 0.8691 - val_loss: 0.3370 - val_accuracy: 0.9004\n",
            "Epoch 6/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8818"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 269ms/step - loss: 0.3514 - accuracy: 0.8818 - val_loss: 0.2729 - val_accuracy: 0.9084\n",
            "Epoch 7/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 270ms/step - loss: 0.3032 - accuracy: 0.8924 - val_loss: 0.2614 - val_accuracy: 0.9004\n",
            "Epoch 8/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 39s 272ms/step - loss: 0.2707 - accuracy: 0.9130 - val_loss: 0.3013 - val_accuracy: 0.8964\n",
            "Epoch 9/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 39s 270ms/step - loss: 0.2534 - accuracy: 0.9091 - val_loss: 0.2735 - val_accuracy: 0.9124\n",
            "Epoch 10/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 268ms/step - loss: 0.2430 - accuracy: 0.9152 - val_loss: 0.2486 - val_accuracy: 0.9243\n",
            "Epoch 11/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9271"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 39s 270ms/step - loss: 0.2146 - accuracy: 0.9271 - val_loss: 0.2619 - val_accuracy: 0.9163\n",
            "Epoch 12/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 39s 273ms/step - loss: 0.1948 - accuracy: 0.9350 - val_loss: 0.2574 - val_accuracy: 0.9163\n",
            "Epoch 13/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9446"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 266ms/step - loss: 0.1699 - accuracy: 0.9446 - val_loss: 0.2568 - val_accuracy: 0.9084\n",
            "Epoch 14/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 268ms/step - loss: 0.1728 - accuracy: 0.9477 - val_loss: 0.2468 - val_accuracy: 0.9163\n",
            "Epoch 15/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9442"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 268ms/step - loss: 0.1817 - accuracy: 0.9442 - val_loss: 0.2760 - val_accuracy: 0.9124\n",
            "Epoch 16/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 268ms/step - loss: 0.1550 - accuracy: 0.9486 - val_loss: 0.2462 - val_accuracy: 0.9203\n",
            "Epoch 17/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9591"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 269ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.2269 - val_accuracy: 0.9283\n",
            "Epoch 18/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9583"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 268ms/step - loss: 0.1271 - accuracy: 0.9583 - val_loss: 0.2114 - val_accuracy: 0.9442\n",
            "Epoch 19/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9657"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 48s 335ms/step - loss: 0.1175 - accuracy: 0.9657 - val_loss: 0.2361 - val_accuracy: 0.9243\n",
            "Epoch 20/20\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/142 [==============================] - 38s 270ms/step - loss: 0.1220 - accuracy: 0.9622 - val_loss: 0.2256 - val_accuracy: 0.9323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "UrDhIooEWnck",
        "outputId": "5dcfd583-ffc2-4b7d-d153-f88e36ef4c43"
      },
      "id": "UrDhIooEWnck",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/models/4_resnet152_garbage_classification_6_classes_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDSd0Q5aWwrd",
        "outputId": "0475487a-160b-4bdc-be15-7557d5a0573a"
      },
      "id": "YDSd0Q5aWwrd",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/models/histories/4_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "metadata": {
        "id": "oXM8zfJlW5eG"
      },
      "id": "oXM8zfJlW5eG",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint('VGG152 Garbage Classifier.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "\n",
        "base_model.trainable=True\n",
        "history = model.fit_generator(\n",
        "   train_batches,\n",
        "    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
        "    epochs=10,\n",
        "    validation_data=valid_batches,\n",
        "    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks = [es, mc],)\n",
        "\n",
        "loss.extend(history.history['loss'])\n",
        "validation_loss.extend(history.history['val_loss'])\n",
        "accuracy.extend(history.history['accuracy'])\n",
        "validation_accuracy.extend(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3lcwhlTuKn",
        "outputId": "ce764e3f-dfc8-4a65-810a-a8336fb08191"
      },
      "id": "OX3lcwhlTuKn",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-687fe0966ab3>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9649\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94024, saving model to VGG152 Garbage Classifier.h5\n",
            "142/142 [==============================] - 42s 293ms/step - loss: 0.1121 - accuracy: 0.9649 - val_loss: 0.2055 - val_accuracy: 0.9402\n",
            "Epoch 2/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9657\n",
            "Epoch 2: val_accuracy improved from 0.94024 to 0.94821, saving model to VGG152 Garbage Classifier.h5\n",
            "142/142 [==============================] - 41s 286ms/step - loss: 0.1118 - accuracy: 0.9657 - val_loss: 0.1786 - val_accuracy: 0.9482\n",
            "Epoch 3/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9587\n",
            "Epoch 3: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 40s 281ms/step - loss: 0.1250 - accuracy: 0.9587 - val_loss: 0.1911 - val_accuracy: 0.9402\n",
            "Epoch 4/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9706\n",
            "Epoch 4: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 39s 276ms/step - loss: 0.1003 - accuracy: 0.9706 - val_loss: 0.1809 - val_accuracy: 0.9363\n",
            "Epoch 5/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9719\n",
            "Epoch 5: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 266ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.2059 - val_accuracy: 0.9203\n",
            "Epoch 6/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9701\n",
            "Epoch 6: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 264ms/step - loss: 0.0918 - accuracy: 0.9701 - val_loss: 0.2014 - val_accuracy: 0.9402\n",
            "Epoch 7/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9714\n",
            "Epoch 7: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 37s 263ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 0.1817 - val_accuracy: 0.9363\n",
            "Epoch 8/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9789\n",
            "Epoch 8: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 267ms/step - loss: 0.0848 - accuracy: 0.9789 - val_loss: 0.2457 - val_accuracy: 0.9203\n",
            "Epoch 9/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9745\n",
            "Epoch 9: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 266ms/step - loss: 0.0815 - accuracy: 0.9745 - val_loss: 0.2427 - val_accuracy: 0.9084\n",
            "Epoch 10/10\n",
            "143/142 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9763\n",
            "Epoch 10: val_accuracy did not improve from 0.94821\n",
            "142/142 [==============================] - 38s 267ms/step - loss: 0.0831 - accuracy: 0.9763 - val_loss: 0.2710 - val_accuracy: 0.9044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37eb6e6-b6fe-4c30-b916-d94c4cc7f5e2",
      "metadata": {
        "id": "b37eb6e6-b6fe-4c30-b916-d94c4cc7f5e2"
      },
      "source": [
        "## Display results of training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0ba51-1985-4045-a9de-c5a927e24cd4",
      "metadata": {
        "id": "72b0ba51-1985-4045-a9de-c5a927e24cd4"
      },
      "source": [
        "### Display the training history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['loss'] = loss\n",
        "history.history['val_loss'] = validation_loss\n",
        "history.history['accuracy'] = accuracy\n",
        "history.history['val_accuracy'] = validation_accuracy"
      ],
      "metadata": {
        "id": "05HCYa2lZFGj"
      },
      "id": "05HCYa2lZFGj",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f6a14c8b-f797-4d4a-8eae-f6caa4a65caa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "f6a14c8b-f797-4d4a-8eae-f6caa4a65caa",
        "outputId": "b59737e7-5d54-4f66-97aa-d170472f7d3d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_graphs(history=history, strings=['accuracy', 'loss'], filename='/content/graphs/training_history') # , filename='graphs/training_history'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "1mW5WqerU6xH"
      },
      "id": "1mW5WqerU6xH"
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir_path = '/content/garbage_classification_TrainValidTest/test'\n",
        "\n",
        "# Create an ImageDataGenerator for test data (no augmentation, just rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=(1./255.))\n",
        "\n",
        "# Load and preprocess test data using the generator\n",
        "test_generator = test_datagen.flow_from_directory(directory=test_dir_path,\n",
        "                                                  batch_size=64,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  target_size=(300, 300),\n",
        "                                                  shuffle=False)  # Set shuffle to False to maintain order\n",
        "\n",
        "# Get the true labels for the test data\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Get the class labels for the test data\n",
        "class_labels = list(test_generator.class_indices.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJHYpwabU_Te",
        "outputId": "9928eb70-dff8-42a5-81f3-3df61daa2497"
      },
      "id": "WJHYpwabU_Te",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mHQ3I2GEQGI",
        "outputId": "783a0bb8-244d-4c88-f682-12a44289d91d"
      },
      "id": "6mHQ3I2GEQGI",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "# Generate classification report\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
      ],
      "metadata": {
        "id": "2QCjzR5zWBBq"
      },
      "id": "2QCjzR5zWBBq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "# sns.set(font_scale=1.2)  # Adjust font size for better visualization\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('/content/graphs/confusion_matrix.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4V1M4739ViQf"
      },
      "id": "4V1M4739ViQf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e9b698d-9a7e-4a43-bbe6-ddf7edc6b05c",
      "metadata": {
        "id": "2e9b698d-9a7e-4a43-bbe6-ddf7edc6b05c"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fdf75ef6-e7f3-4e5e-aa4c-88a93cbc6d87",
      "metadata": {
        "id": "fdf75ef6-e7f3-4e5e-aa4c-88a93cbc6d87",
        "outputId": "b0680cd3-d422-49f6-abb3-23f1af972202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/models/4_1_resnet152_garbage_classification_6_classes_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0024dba9-a088-412c-b01c-87e7da4ddc7d",
      "metadata": {
        "id": "0024dba9-a088-412c-b01c-87e7da4ddc7d"
      },
      "outputs": [],
      "source": [
        "with open('/content/models/histories/4_1_resnet152_garbage_classification_6_classes_model_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0cfe9557-7afc-43fe-ac84-46e7c3b26d47",
        "QtwmTbl9PK5u",
        "ff87ed02-b353-41ff-a831-495238d0361b",
        "jH-5MYFlPiGG",
        "oewmXvvYPoS2",
        "cwXhFVwTUYPI",
        "a9d3365a-13fe-480a-b5a1-a73191acca39",
        "e59dd5b1-3054-4e06-a376-42362774907a",
        "158972c1-8c86-45a5-a767-c7b37b1b6608",
        "3f09ee41-db3b-4db9-825c-ae22aaa2f0ac",
        "6c48c3ae-6c6d-4887-8c22-649ebeb751ef",
        "50d2c56e-aac4-4403-a89c-177d7584ca76",
        "rMRZMug1axTK",
        "SVoc99d2bFV6",
        "r1oj75sjbMPq",
        "Nq6an5m7bYeU",
        "xN_CBfSMbsNy",
        "wTLkX5eyb3ny",
        "URnp4hbnb_kD",
        "b8QlRMm8cQHR",
        "M6N_HmcbcdN6",
        "OvIN0bJrdWjL",
        "auf2c59BdgWR",
        "bkNIrE5i9yff",
        "5xs5E4lc92xt",
        "rwEBRaCz-A13",
        "QQTigweq-QHk",
        "LhPjOZiNuN0O",
        "Wm0HzUnim4GY",
        "S1YCpPVUryl2",
        "iDPvcoMgseEW",
        "NdonW8OusrtF",
        "Lxd7HGmlsyRc",
        "oZNmeaEis_M9",
        "PLEmuhGMtKR2",
        "3CXocmX_tJRk",
        "zLqDaHmgtgTd",
        "lADCJADjtvxU",
        "xPP3kC0vuLgD",
        "Y1qLJ2g506nN",
        "5h2Ggtv72gdt",
        "m0g3W4Fr6lR2",
        "9uPP8ROm7bB9",
        "YEiPqicE3SOv",
        "VOeyt-j4AwnF",
        "jY64rbItA8lz"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}