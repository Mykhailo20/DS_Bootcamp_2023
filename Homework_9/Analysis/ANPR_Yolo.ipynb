{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922df586-51ce-4fc4-ad91-eae3130768b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "import imutils\n",
    "import easyocr\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5e1d5-cac3-4618-b9e4-7f005db8f1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b9b7b4-29de-475c-9b22-b87c305977e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a957d94-7420-48e3-aa77-53bbb5193c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    #    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s: %s' % (classes[classId], label)\n",
    "\n",
    "    # Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv.getTextSize(\n",
    "        label, cv.FONT_HERSHEY_SIMPLEX, 1, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    #cv.rectangle(frame, (left, top - round(1.7*labelSize[1])), (left + round(\n",
    "    #   1.3*labelSize[0]), top + baseLine), (255, 0, 255), cv.FILLED)\n",
    "    # cv.putText(frame, label, (left, top),\n",
    "    #           cv.FONT_HERSHEY_SIMPLEX, 1.3, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaadf5a6-cebf-431b-9b04-2db8a5e2da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        print(\"out.shape : \", out.shape)\n",
    "        for detection in out:\n",
    "            # if detection[4]>0.001:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            # if scores[classId]>confThreshold:\n",
    "            confidence = scores[classId]\n",
    "            if detection[4] > confThreshold:\n",
    "                print(detection[4], \" - \", scores[classId],\n",
    "                      \" - th : \", confThreshold)\n",
    "                print(f\"detection: {detection}\")\n",
    "            if confidence > confThreshold:\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    return indices, boxes, classIds, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dc51ebd-ee89-4887-9b85-73e580e1c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_license_plates_localization(file_path, reader):\n",
    "    \n",
    "    # Extract the filename\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    img = cv.imread(file_path)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # Make the image gray\n",
    "    \n",
    "    bfilter = cv.bilateralFilter(gray, 11, 17, 17) # Noise reduction\n",
    "    edged = cv.Canny(bfilter, 30, 200) # Edge detection\n",
    "    \n",
    "    keypoints = cv.findContours(edged.copy(), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE) # Find keypoints\n",
    "    contours = imutils.grab_contours(keypoints) # Grab contours\n",
    "    contours = sorted(contours, key=cv.contourArea, reverse=True)[:30] # Select the 10 largest contours \n",
    "    \n",
    "    # Find the position of the license plate (rectangle search)\n",
    "    location = None\n",
    "    for contour in contours:\n",
    "        approx = cv.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            break\n",
    "    \n",
    "    if location is None:\n",
    "        print(\"\\nLOCATION IS NONE!!!\")\n",
    "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "        plt.title(file_name)\n",
    "        plt.show()\n",
    "        return None\n",
    "        \n",
    "    # Extract the license plate from the original image\n",
    "    mask = np.zeros(gray.shape, np.uint8) # create a blank mask\n",
    "    new_image = cv.drawContours(mask, [location], 0, 255, -1) # draw contours inside the mask image with location coordinates\n",
    "    new_image = cv.bitwise_and(img, img, mask=mask) # Applying masks on top of the original image\n",
    "    (x, y) = np.where(mask==255)\n",
    "    (x1, y1) = (np.min(x), np.min(y))\n",
    "    (x2, y2) = (np.max(x), np.max(y))\n",
    "    cropped_image = gray[x1:x2 + 1, y1:y2 + 1]\n",
    "    result = reader.readtext(cropped_image)\n",
    "    if result != []:\n",
    "        text = result[0][-2]\n",
    "        (x, y, w, h) = cv.boundingRect(location)\n",
    "        # Create a sign image using (x, y, w, h) information\n",
    "        sign_image = img[y:y+h, x:x+w]\n",
    "\n",
    "        #output_file_path = os.path.join(output_folder_path, f'{file_name}_plate')\n",
    "        #cv.imwrite(output_file_path, sign_image)\n",
    "        \n",
    "        # Create a figure with two subplots: one for the car image and one for the license plate image\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "        \n",
    "        # Display the car image on the left subplot\n",
    "        axes[0].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "        axes[0].set_title(file_name)\n",
    "\n",
    "        # Display the license plate image in the middle subplot\n",
    "        axes[1].imshow(cv.cvtColor(cropped_image, cv.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(file_name)\n",
    "\n",
    "        # Display the sign image on the right subplot\n",
    "        axes[2].imshow(cv.cvtColor(sign_image, cv.COLOR_BGR2RGB))\n",
    "        axes[2].set_title(text)\n",
    "\n",
    "        plt.show()  # Display the current image\n",
    "            \n",
    "        if text != '':\n",
    "            return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48fa21-a9c9-47bd-ab05-1c663f4aeb76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987910f3-3839-4306-a256-099ee183a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters\n",
    "confThreshold = 0.5  # Confidence threshold\n",
    "nmsThreshold = 0.4  # Non-maximum suppression threshold\n",
    "\n",
    "inpWidth = 416  # 608     # Width of network's input image\n",
    "inpHeight = 416  # 608     # Height of network's input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fad774-77a6-4102-b654-f84f11abc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load names of classes\n",
    "classesFile = \"yolo-license-plate-detection/model/classes.names\"\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "modelConfiguration = \"yolo-license-plate-detection/model/config/darknet-yolov3.cfg\"\n",
    "modelWeights = \"yolo-license-plate-detection/model/weights/model.weights\"\n",
    "\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d807c-ade4-4412-9ee6-8358d6fabbcb",
   "metadata": {},
   "source": [
    "# Use Yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7d663-aef9-4c0c-878b-f8d7646bb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data/images/one_car/0-99'\n",
    "\n",
    "if not os.path.isdir(image_dir):\n",
    "    print(\"Input image dir \", image_dir, \" doesn't exist\")\n",
    "    \n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "license_plates_dict = {'image_name': [], 'x': [], 'y': [], 'width': [], 'height': [] }\n",
    "for image_name in [k for k in os.listdir(image_dir) if 'out_py' not in k]:\n",
    "    # os.system('python object_detection_yolo.py --image={}'.format(os.path.join(image_dir, image_path)))\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    print(f\"Image_path = {image_path}\")\n",
    "    image = cv.imread(image_path)\n",
    "    frame = image.copy()\n",
    "    # Create a 4D blob from the frame\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0, 0, 0], 1, crop=False)\n",
    "    \n",
    "    # Set input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run forward pass and get output\n",
    "    outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "    # Remove bounding boxes with low confidence and draw predictions\n",
    "    indices, boxes, classIds, confidences = postprocess(frame, outs)\n",
    "    if len(indices) != 0:\n",
    "        # Loop through detected boxes and find the license plate\n",
    "        for i in indices:\n",
    "            box = boxes[i]\n",
    "            left, top, width, height = box[0], box[1], box[2], box[3]\n",
    "            classId = classIds[i]\n",
    "\n",
    "            # Check if the detected object is a license plate\n",
    "            if classes[classId] == 'License Plate':\n",
    "                print(f\"left, top, width, height = {left, top, width, height}\")\n",
    "                # Extract the license plate region\n",
    "                license_plate = frame[top:top+height, left:left+width]\n",
    "                result = reader.readtext(license_plate)\n",
    "                if result != []:\n",
    "                    text = result[0][-2]\n",
    "                    \n",
    "                    if text != '':\n",
    "                        license_plates_dict['image_name'].append(image_name)\n",
    "                        license_plates_dict['x'].append(left)\n",
    "                        license_plates_dict['y'].append(top)\n",
    "                        license_plates_dict['width'].append(width)\n",
    "                        license_plates_dict['height'].append(height)\n",
    "                        \n",
    "                    # Display the original image, license plate, and license plate on the original image\n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "                    axes[0].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "                    axes[0].set_title('Original Image')\n",
    "        \n",
    "                    axes[1].imshow(cv.cvtColor(license_plate, cv.COLOR_BGR2RGB))\n",
    "                    axes[1].set_title('License Plate')\n",
    "                \n",
    "                    drawPred(classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "                    axes[2].imshow(cv.cvtColor(frame, cv.COLOR_BGR2RGB))\n",
    "                    axes[2].set_title(text)\n",
    "        \n",
    "                    plt.show()\n",
    "            \n",
    "                else:\n",
    "                    print(f\"\\nNO TEXT WAS DETECTED ON THE SELECTED PART OF THE IMAGE: {image_name}!!!\\n\")\n",
    "\n",
    "    else:\n",
    "        result = opencv_license_plates_localization(file_path=image_path, reader=reader)\n",
    "        if result is None:\n",
    "            print(f\"\\nNO LICENSE PLATE DETECTED IN THIS IMAGE: {image_name}!!!\\n\")\n",
    "        else:\n",
    "            left, top, width, height = result[0], result[1], result[2], result[3]\n",
    "            license_plates_dict['image_name'].append(image_name)\n",
    "            license_plates_dict['x'].append(left)\n",
    "            license_plates_dict['y'].append(top)\n",
    "            license_plates_dict['width'].append(width)\n",
    "            license_plates_dict['height'].append(height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
